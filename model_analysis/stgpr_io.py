#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ—¶ç©ºé«˜æ–¯è¿‡ç¨‹å›å½’æ¨¡å‹ (ST-GPR) - è¾“å…¥è¾“å‡ºæ¨¡å—

æœ¬æ¨¡å—åŒ…å«ST-GPRæ¨¡å‹çš„è¾“å…¥è¾“å‡ºç›¸å…³åŠŸèƒ½ï¼š
1. æ¨¡å‹åŠ è½½ (load_st_gpr_model)
2. æ¨¡å‹ä¿å­˜ (save_stgpr_model)
3. æ¨¡å‹é¢„æµ‹ (predict_with_st_gpr)
"""

import os
import numpy as np
import pandas as pd
import torch
import traceback

# æ£€æŸ¥GPyTorchä¾èµ–
HAS_GPYTORCH = False
try:
    import gpytorch
    HAS_GPYTORCH = True
except ImportError:
    pass

# ä»coreæ¨¡å—å¯¼å…¥ensure_dir_existså‡½æ•°
from .core import ensure_dir_exists
from .stgpr_config import get_config


def load_st_gpr_model(model_path, device=None):
    """
    ä»ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ä¸­åŠ è½½ST-GPRæ¨¡å‹
    
    å‚æ•°:
    model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
    device: è®¡ç®—è®¾å¤‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
    
    è¿”å›:
    dict: åŒ…å«åŠ è½½çš„æ¨¡å‹å’Œç›¸å…³å…ƒæ•°æ®çš„å­—å…¸
    """
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
    
    # ç¡®å®šè®¾å¤‡
    if device is None:
        device = torch.device('cpu')
    
    # åŠ è½½æ¨¡å‹æ•°æ®
    checkpoint = torch.load(model_path, map_location=device)
    
    # æå–æ¨¡å‹å…ƒæ•°æ®
    feature_names = checkpoint.get('feature_names', None)
    scaler = checkpoint.get('scaler', None)
    metrics = checkpoint.get('metrics', {})
    
    # å¦‚æœæ²¡æœ‰ç‰¹å¾åç§°åˆ—è¡¨ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
    if feature_names is None:
        # å°è¯•æ¨æ–­ç‰¹å¾ç»´åº¦
        for name, param in checkpoint['model_state_dict'].items():
            if 'lengthscale' in name and len(param.shape) > 0:
                n_features = param.shape[0]
                feature_names = [f'feature_{i}' for i in range(n_features)]
                break
    
    # ç¡®å®šè¾“å…¥ç»´åº¦
    input_dim = len(feature_names) if feature_names else 19  # é»˜è®¤å€¼ï¼šlat, lon, 16ä¸ªç‰¹å¾, year
    
    # å¯¼å…¥STGPRModel
    from .stgpr_model import STGPRModel
    
    # åˆ›å»ºè¯±å¯¼ç‚¹
    inducing_points = None
    for name, param in checkpoint['model_state_dict'].items():
        if 'inducing_points' in name:
            inducing_points = param
            break
    
    config = get_config()
    if inducing_points is None:
        num_inducing = config['model']['num_inducing_points']
        inducing_points = torch.randn(num_inducing, input_dim, device=device)
    
    # ç¡®å®šç©ºé—´ã€æ—¶é—´å’Œç‰¹å¾çš„ç´¢å¼•
    spatial_dims = list(range(2))
    temporal_dims = [input_dim - 1]
    feature_dims = list(set(range(input_dim)) - set(spatial_dims) - set(temporal_dims))
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = STGPRModel(
        inducing_points=inducing_points,
        input_dim=input_dim,
        spatial_dims=spatial_dims,
        temporal_dims=temporal_dims,
        feature_dims=feature_dims
    )
    
    # åˆ›å»ºä¼¼ç„¶å‡½æ•°
    likelihood = gpytorch.likelihoods.GaussianLikelihood()
    
    # åŠ è½½å‚æ•°
    model.load_state_dict(checkpoint['model_state_dict'])
    likelihood.load_state_dict(checkpoint['likelihood_state_dict'])
    
    # ç§»åŠ¨åˆ°è®¾å¤‡
    model = model.to(device)
    likelihood = likelihood.to(device)
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    likelihood.eval()
    
    return {
        'model': model,
        'likelihood': likelihood,
        'feature_names': feature_names,
        'scaler': scaler,
        'metrics': metrics,
        'device': device
    }


def predict_with_st_gpr(model_dict, X, return_variance=False, batch_size=None):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„ST-GPRæ¨¡å‹è¿›è¡Œé¢„æµ‹
    
    å‚æ•°:
    model_dict: åŒ…å«æ¨¡å‹ã€ä¼¼ç„¶ã€scalerç­‰çš„å­—å…¸
    X: è¾“å…¥ç‰¹å¾ (DataFrameæˆ–numpyæ•°ç»„)
    return_variance: æ˜¯å¦è¿”å›é¢„æµ‹æ–¹å·®
    batch_size: æ‰¹å¤„ç†å¤§å°ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç¡®å®š
    
    è¿”å›:
    predictions: é¢„æµ‹å€¼ (å¦‚æœreturn_variance=Trueï¼Œåˆ™è¿”å›(mean, variance))
    """
    import torch
    import gpytorch
    
    # è·å–æ¨¡å‹ç»„ä»¶
    model = model_dict['model']
    likelihood = model_dict['likelihood']
    scaler = model_dict.get('scaler')
    
    # ğŸ”§ æ™ºèƒ½è®¾å¤‡ç®¡ç†ï¼šæ£€æµ‹æ¨¡å‹å½“å‰è®¾å¤‡å¹¶ä¿æŒä¸€è‡´
    model_device = next(model.parameters()).device
    target_device = 'cpu'  # ä¸ºäº†GeoShapleyå…¼å®¹æ€§ï¼Œç»Ÿä¸€ä½¿ç”¨CPU
    
    # ğŸ”§ é™é»˜æ¨¡å¼ï¼šé¿å…GeoShapleyè®¡ç®—æ—¶çš„é‡å¤æ—¥å¿—
    verbose = batch_size is None or batch_size > 1000  # åªåœ¨å¤§æ‰¹é‡æˆ–æ‰‹åŠ¨è°ƒç”¨æ—¶æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    
    # ğŸ›¡ï¸ ç¡®ä¿æ¨¡å‹åŠå…¶æ‰€æœ‰ç»„ä»¶éƒ½åœ¨ç›®æ ‡è®¾å¤‡ä¸Š
    if model_device != torch.device(target_device):
        if verbose:
            print(f"  ğŸ”§ å°†æ¨¡å‹ä» {model_device} è¿ç§»åˆ° {target_device}")
        
        # æ·±åº¦è®¾å¤‡è¿ç§»ï¼šç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½åœ¨ç›®æ ‡è®¾å¤‡ä¸Š
        model = model.to(target_device)
        likelihood = likelihood.to(target_device)
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è¿ç§»æ‰€æœ‰å†…éƒ¨çŠ¶æ€
        # é€’å½’æ£€æŸ¥å¹¶è¿ç§»æ‰€æœ‰å­æ¨¡å—çš„å‚æ•°å’Œç¼“å†²åŒº
        for name, module in model.named_modules():
            for param_name, param in module.named_parameters(recurse=False):
                if param.device != torch.device(target_device):
                    param.data = param.data.to(target_device)
                    if param.grad is not None:
                        param.grad = param.grad.to(target_device)
            
            for buffer_name, buffer in module.named_buffers(recurse=False):
                if buffer.device != torch.device(target_device):
                    buffer.data = buffer.data.to(target_device)
        
        # ğŸ”¥ ç‰¹åˆ«å¤„ç†å˜åˆ†æ¨ç†ç»„ä»¶
        if hasattr(model, 'variational_strategy'):
            vs = model.variational_strategy
            # è¿ç§»è¯±å¯¼ç‚¹
            if hasattr(vs, 'inducing_points'):
                vs.inducing_points = vs.inducing_points.to(target_device)
            # è¿ç§»å˜åˆ†å‚æ•°
            if hasattr(vs, '_variational_distribution'):
                if hasattr(vs._variational_distribution, 'variational_mean'):
                    vs._variational_distribution.variational_mean = vs._variational_distribution.variational_mean.to(target_device)
                if hasattr(vs._variational_distribution, 'chol_variational_covar'):
                    vs._variational_distribution.chol_variational_covar = vs._variational_distribution.chol_variational_covar.to(target_device)
        
        if verbose:
            print(f"  âœ… æ¨¡å‹åŠæ‰€æœ‰ç»„ä»¶å·²è¿ç§»åˆ° {target_device}")
    
    # ğŸ”‡ ç®€åŒ–è®¾å¤‡éªŒè¯ï¼šé™é»˜æ‰§è¡Œï¼Œåªåœ¨çœŸæ­£éœ€è¦æ—¶è­¦å‘Š
    devices = set()
    for param in model.parameters():
        devices.add(param.device)
    for buffer in model.buffers():
        devices.add(buffer.device)
    
    # åªåœ¨æœ‰çœŸæ­£çš„è®¾å¤‡ä¸ä¸€è‡´é—®é¢˜æ—¶æ‰è¾“å‡ºè­¦å‘Š
    if len(devices) > 1 and verbose:
        print(f"  âš ï¸ è­¦å‘Šï¼šæ¨¡å‹ä»æœ‰ç»„ä»¶åœ¨ä¸åŒè®¾å¤‡ä¸Š: {devices}")
    # ç§»é™¤å†—ä½™çš„æˆåŠŸæ¶ˆæ¯ - è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥åº”è¯¥æ˜¯é™é»˜çš„
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    model.eval()
    likelihood.eval()
    
    # å‡†å¤‡è¾“å…¥æ•°æ®
    if isinstance(X, pd.DataFrame):
        X_array = X.values
    else:
        X_array = X
    
    # æ ‡å‡†åŒ–
    if scaler is not None:
        X_array = scaler.transform(X_array)
    
    # ç¡®å®šæ‰¹å¤„ç†å¤§å°
    if batch_size is None:
        # æ ¹æ®è¯±å¯¼ç‚¹æ•°é‡è‡ªåŠ¨ç¡®å®šæ‰¹å¤„ç†å¤§å°
        if hasattr(model, 'variational_strategy') and hasattr(model.variational_strategy, 'inducing_points'):
            num_inducing = model.variational_strategy.inducing_points.shape[0]
            if num_inducing >= 300:  # å¯¹äºå¤§å‹æ¨¡å‹ä½¿ç”¨æ›´å°çš„æ‰¹æ¬¡
                batch_size = 50
            else:
                batch_size = 200
        else:
            batch_size = 200
    
    # ğŸ¯ è½¬æ¢ä¸ºå¼ é‡å¹¶ç¡®ä¿åœ¨æ­£ç¡®è®¾å¤‡ä¸Š
    X_tensor = torch.tensor(X_array, dtype=torch.float32).to(target_device)
    
    # å¦‚æœæ•°æ®é‡å°äºæ‰¹å¤„ç†å¤§å°ï¼Œç›´æ¥é¢„æµ‹
    if X_tensor.shape[0] <= batch_size:
        with torch.no_grad(), gpytorch.settings.fast_pred_var():
            output = model(X_tensor)
            predictions = likelihood(output)
        
        if return_variance:
            return predictions.mean.cpu().numpy(), predictions.variance.cpu().numpy()
        else:
            return predictions.mean.cpu().numpy()
    
    # æ‰¹å¤„ç†é¢„æµ‹ - è¿›ä¸€æ­¥ç®€åŒ–è¾“å‡º
    if verbose and X_tensor.shape[0] <= 1000:  # åªåœ¨verboseæ¨¡å¼ä¸‹å¯¹å°æ‰¹é‡æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        print(f"  ğŸ“¦ æ‰¹å¤„ç†é¢„æµ‹: {X_tensor.shape[0]}æ ·æœ¬ï¼Œæ‰¹æ¬¡={batch_size}")
    
    all_means = []
    all_variances = [] if return_variance else None
    
    total_batches = (X_tensor.shape[0] + batch_size - 1) // batch_size
    processed_batches = 0
    
    for i in range(0, X_tensor.shape[0], batch_size):
        batch_end = min(i + batch_size, X_tensor.shape[0])
        X_batch = X_tensor[i:batch_end]
        
        with torch.no_grad(), gpytorch.settings.fast_pred_var():
            output = model(X_batch)
            batch_predictions = likelihood(output)
        
        all_means.append(batch_predictions.mean.cpu().numpy())
        if return_variance:
            all_variances.append(batch_predictions.variance.cpu().numpy())
        
        processed_batches += 1
    
    # åˆå¹¶ç»“æœ
    final_means = np.concatenate(all_means)
    
    if return_variance:
        final_variances = np.concatenate(all_variances)
        return final_means, final_variances
    else:
        return final_means


def save_stgpr_model(model_dict, model_path):
    """
    ä¿å­˜ST-GPRæ¨¡å‹åŠå…¶ç›¸å…³æ•°æ®
    
    å‚æ•°:
    model_dict: åŒ…å«æ¨¡å‹åŠç›¸å…³æ•°æ®çš„å­—å…¸
    model_path: ä¿å­˜è·¯å¾„
    
    è¿”å›:
    bool: æ˜¯å¦æˆåŠŸä¿å­˜
    """
    try:
        directory = os.path.dirname(model_path)
        if directory:
            ensure_dir_exists(directory)
        
        # æå–éœ€è¦ä¿å­˜çš„æ•°æ®
        model = model_dict.get('model')
        likelihood = model_dict.get('likelihood')
        feature_names = model_dict.get('feature_names')
        scaler = model_dict.get('scaler')
        metrics = model_dict.get('metrics', {})
        
        if model is None or likelihood is None:
            return False
        
        # å°†æ¨¡å‹ç§»åŠ¨åˆ°CPU
        model = model.cpu()
        likelihood = likelihood.cpu()
        
        # ä¿å­˜çŠ¶æ€å­—å…¸
        state_dict = {
            'model_state_dict': model.state_dict(),
            'likelihood_state_dict': likelihood.state_dict(),
            'feature_names': feature_names,
            'scaler': scaler,
            'metrics': metrics
        }
        
        torch.save(state_dict, model_path)
        return True
    except Exception as e:
        print(f"ä¿å­˜æ¨¡å‹æ—¶å‡ºé”™: {e}")
        print(traceback.format_exc())
        return False 