#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Feature importance analysis module for ST-GPR models

This module contains functions for analyzing feature importance
and feature categories for ST-GPR models.
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
import json
import torch

# å¯¼å…¥æ ¸å¿ƒåŠŸèƒ½
from .core import ensure_dir_exists, color_map, categorize_feature, enhance_plot_style, save_plot_for_publication

def analyze_feature_importance(model_dict, X_train=None, X_test=None, y_train=None, y_test=None, feature_categories=None, result_dict=None):
    """
    åˆ†æST-GPRæ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§
    
    å‚æ•°:
    model_dict: ST-GPRæ¨¡å‹å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹ã€ç‰¹å¾åç§°ç­‰
    X_train: è®­ç»ƒç‰¹å¾ï¼ˆå¯é€‰ï¼‰
    X_test: æµ‹è¯•ç‰¹å¾ï¼ˆå¯é€‰ï¼‰
    y_train: è®­ç»ƒæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
    y_test: æµ‹è¯•æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
    feature_categories: ç‰¹å¾ç±»åˆ«å­—å…¸
    result_dict: ç”¨äºå­˜å‚¨ç»“æœçš„å­—å…¸
    
    è¿”å›:
    feature_importance_dict: åŒ…å«feature_importanceå’Œå…¶ä»–ä¿¡æ¯çš„å­—å…¸
    """
    from collections import defaultdict
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    if result_dict is None:
        result_dict = {}
    
    print("\nåˆ†æç‰¹å¾é‡è¦æ€§ä¸è´¡çŒ®...")
    feature_importance_dict = {}
    
    # ä»æ¨¡å‹å­—å…¸ä¸­è·å–ç‰¹å¾é‡è¦æ€§
    model = model_dict.get('model')
    if model is None:
        print("é”™è¯¯: æ¨¡å‹ä¸ºNoneï¼Œæ— æ³•è®¡ç®—ç‰¹å¾é‡è¦æ€§")
        return None
    
    # è·å–ç‰¹å¾åç§°
    feature_names = model_dict.get('feature_names', [])
    if not feature_names and hasattr(X_train, 'columns'):
        feature_names = X_train.columns.tolist()
    
    if not feature_names:
        print("è­¦å‘Š: æ— æ³•è·å–ç‰¹å¾åç§°åˆ—è¡¨")
        # å°è¯•ä»æ¨¡å‹ä¸­è·å–ç‰¹å¾ç»´åº¦
        if hasattr(model, 'feature_dims') and model.feature_dims:
            feature_names = [f"feature_{i}" for i in model.feature_dims]
        else:
            print("é”™è¯¯: æ— æ³•ç¡®å®šç‰¹å¾ç»´åº¦å’Œåç§°")
            return None
    
    # ä½¿ç”¨æ¨¡å‹çš„get_feature_importanceæ–¹æ³•è·å–ç‰¹å¾é‡è¦æ€§
    importance_list = model.get_feature_importance(feature_names)
    
    # åˆ›å»ºç‰¹å¾é‡è¦æ€§æ•°æ®æ¡†
    feature_names_list = [name for name, _ in importance_list]
    importance_values = [imp for _, imp in importance_list]
    
    # åˆ›å»ºç‰¹å¾é‡è¦æ€§æ•°æ®æ¡†
    importance_df = pd.DataFrame({'feature': feature_names_list, 'importance': importance_values})
    importance_df = importance_df.sort_values('importance', ascending=False)
    
    # ä¿å­˜æœ‰åºçš„ç‰¹å¾é‡è¦æ€§
    feature_importance = list(zip(importance_df['feature'], importance_df['importance']))
    feature_importance_dict['feature_importance'] = feature_importance
    
    # åŒæ—¶ä¿å­˜æ’åºåçš„ç‰ˆæœ¬ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨
    feature_importance_dict['sorted'] = feature_importance
    
    # ä¿å­˜åˆ°ç»“æœå­—å…¸
    result_dict['feature_importance'] = feature_importance
    
    # åŸå§‹æ¤è¢«æŒ‡æ ‡åˆ—è¡¨ - è¿™äº›æŒ‡æ ‡ä¸åº”è¢«åˆ†æ
    excluded_indicators = ['evi', 'lai', 'fpar', 'gpp', 'EVI', 'LAI', 'FPAR', 'GPP', 'ndvi', 'vci', 'tci', 'NDVI', 'VCI', 'TCI']
    filtered_feature_names = []
    filtered_feature_indices = []
    
    for i, feature in enumerate(feature_names_list):
        # æ£€æŸ¥ç‰¹å¾åç§°æ˜¯å¦åŒ…å«ä»»ä½•è¢«æ’é™¤çš„æŒ‡æ ‡
        if not any(indicator.lower() in feature.lower() for indicator in excluded_indicators):
            filtered_feature_names.append(feature)
            filtered_feature_indices.append(i)
    
    # æŠ¥å‘Šè¢«è¿‡æ»¤æ‰çš„ç‰¹å¾
    if len(filtered_feature_names) < len(feature_names_list):
        filtered_out = [f for f in feature_names_list if f not in filtered_feature_names]
        print(f"Warning: {len(filtered_out)} features containing original vegetation indicators were removed from feature importance analysis:")
        print(f"   For example: {', '.join(filtered_out[:5])}" + ("..." if len(filtered_out) > 5 else ""))
    
    # ä½¿ç”¨è¿‡æ»¤åçš„ç‰¹å¾åç§°å’Œé‡è¦æ€§å€¼
    filtered_importance = []
    for i, idx in enumerate(filtered_feature_indices):
        if idx < len(importance_values):
            filtered_importance.append(importance_values[idx])
    
    # ç¡®ä¿filtered_feature_nameså’Œfiltered_importanceé•¿åº¦ç›¸åŒ
    n = min(len(filtered_feature_names), len(filtered_importance))
    filtered_feature_names = filtered_feature_names[:n]
    filtered_importance = filtered_importance[:n]
    
    # åˆ›å»ºç‰¹å¾é‡è¦æ€§å­—å…¸
    feature_importances = {filtered_feature_names[i]: filtered_importance[i] for i in range(n)}
    
    # æŒ‰é‡è¦æ€§æ’åº
    sorted_feature_importances = dict(sorted(feature_importances.items(), key=lambda x: x[1], reverse=True))
    # æ—¢ç„¶ç¦ç”¨äº†ç‰¹å¾é¢„ç­›é€‰ï¼Œæ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾ï¼ˆST-GPRæ¨¡å‹æœ‰19ä¸ªç‰¹å¾ï¼‰
    top_n = len(sorted_feature_importances)  # æ˜¾ç¤ºæ‰€æœ‰ç‰¹å¾ï¼Œä¸å†é™åˆ¶æ•°é‡
    top_features = list(sorted_feature_importances.keys())[:top_n]
    top_importances = list(sorted_feature_importances.values())[:top_n]
    
    # å¯¹ç‰¹å¾è¿›è¡Œåˆ†ç±»
    categories = [categorize_feature(feature) for feature in top_features]
    category_colors = [color_map.get(cat, '#888888') for cat in categories]
    
    # åˆ›å»ºæ ¼å¼åŒ–ç‰¹å¾åç§°çš„å‡½æ•°
    def format_feature_name(feature_name):
        """
        æ ¼å¼åŒ–ç‰¹å¾åç§°ï¼Œä½¿å…¶æ›´æ˜“è¯»
        """
        # ä»coreå¯¼å…¥æ ‡å‡†åŒ–å‡½æ•°
        from model_analysis.core import standardize_feature_name
        
        # é¦–å…ˆæ ‡å‡†åŒ–ç‰¹å¾åç§°
        feature_name = standardize_feature_name(feature_name)
        
        # å¤„ç†æ»åç‰¹å¾
        if '_t_lag' in feature_name:
            parts = feature_name.split('_t_lag')
            if len(parts) == 2:
                return f"{parts[0]} (t-{parts[1]})"
        elif '_lag' in feature_name:
            parts = feature_name.split('_lag')
            if len(parts) == 2:
                return f"{parts[0]} (lag {parts[1]})"
        elif '_s_lag' in feature_name:
            parts = feature_name.split('_s_lag')
            if len(parts) == 2:
                return f"{parts[0]} (spatial lag {parts[1]})"
        
        # å¤„ç†ç©ºé—´æ»åç‰¹å¾
        feature_name = feature_name.replace('_s_lag1', ' (spatial lag)')
        
        # å¤„ç†äº¤äº’ç‰¹å¾
        feature_name = feature_name.replace('_interaction', ' interaction')
        
        # å¸¸è§ç¼©å†™æ‰©å±•
        feature_name = feature_name.replace('temp', 'temperature')
        feature_name = feature_name.replace('precipitation', 'precipitation')
        feature_name = feature_name.replace('precip', 'precipitation')
        feature_name = feature_name.replace('pet', 'potential evapotranspiration')
        feature_name = feature_name.replace('elevation', 'elevation')
        feature_name = feature_name.replace('slope', 'slope')
        feature_name = feature_name.replace('aspect', 'aspect')
        feature_name = feature_name.replace('nightlight', 'nightlight')
        feature_name = feature_name.replace('population_density', 'population density')
        feature_name = feature_name.replace('popdens', 'population density')
        
        # ä¿®æ”¹ï¼šå°†forest_area_percentæ›¿æ¢ä¸ºforest coverageï¼ˆæ˜ç¡®æ˜¯è¦†ç›–ç‡ï¼‰ï¼Œè€Œä¸æ˜¯forest area
        feature_name = feature_name.replace('forest_area_percent', 'forest coverage (%)')
        # ç¡®ä¿å…ˆå‰å¯èƒ½æœªå¤„ç†çš„forest_areaä¹Ÿè¢«æ˜¾ç¤ºä¸ºä¸€è‡´æ ¼å¼
        feature_name = feature_name.replace('forest_area', 'forest coverage (%)')
        
        # ç»Ÿä¸€å…¶ä»–åœŸåœ°è¦†ç›–ç±»å‹çš„æ ¼å¼ä¸º"coverage (%)"
        feature_name = feature_name.replace('cropland_area_percent', 'cropland coverage (%)')
        feature_name = feature_name.replace('crop_area', 'cropland coverage (%)')
        feature_name = feature_name.replace('grassland_area_percent', 'grassland coverage (%)')
        feature_name = feature_name.replace('grass_area', 'grassland coverage (%)')
        feature_name = feature_name.replace('shrubland_area_percent', 'shrubland coverage (%)')
        feature_name = feature_name.replace('shrub_area', 'shrubland coverage (%)')
        feature_name = feature_name.replace('impervious_area_percent', 'impervious coverage (%)')
        feature_name = feature_name.replace('imperv_area', 'impervious coverage (%)')
        feature_name = feature_name.replace('bare_area_percent', 'bare coverage (%)')
        feature_name = feature_name.replace('bare_area', 'bare coverage (%)')
        
        return feature_name
    
    # åˆ›å»ºç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
    plt.figure(figsize=(12, 8))
    y_pos = np.arange(len(top_features))
    
    # åˆ›å»ºåè½¬çš„æ•°æ®å’Œä½ç½®ï¼Œä½¿æœ€é‡è¦çš„ç‰¹å¾åœ¨é¡¶éƒ¨
    top_features_rev = [format_feature_name(f) for f in top_features[::-1]]
    top_importances_rev = top_importances[::-1]
    category_colors_rev = category_colors[::-1]
    
    # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
    bars = plt.barh(y_pos, top_importances_rev, color=category_colors_rev, alpha=0.8)
    
    # åˆ›å»ºå›¾ä¾‹ - ä½¿ç”¨åˆ†ç±»è¿›è¡Œåˆ†ç»„
    unique_categories = list(set(categories))
    legend_elements = [Patch(facecolor=color_map.get(cat, '#888888'), edgecolor='black', label=cat) 
                       for cat in unique_categories]
    plt.legend(handles=legend_elements, loc='lower right')
    
    # æ·»åŠ ç½‘æ ¼çº¿ä½œä¸ºè§†è§‰è¾…åŠ©
    plt.grid(axis='x', linestyle='--', alpha=0.7)
    
    # æ·»åŠ ç‰¹å¾åç§°æ ‡ç­¾
    plt.yticks(y_pos, top_features_rev)
    plt.xlabel('Feature Importance')
    plt.title('STGPR Feature Importance (All Features)', fontsize=14, fontweight='bold')
    
    # å¢å¼ºå›¾è¡¨æ ·å¼
    enhance_plot_style(plt.gca())
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    ensure_dir_exists('output/feature_importance')
    
    # ä¿å­˜å›¾è¡¨
    importance_plot_path = os.path.join('output/feature_importance', 'feature_importance.png')
    save_plot_for_publication(importance_plot_path)
    
    # è¾“å‡ºåˆ†æç»“æœ
    feature_importance_results = {
        'feature_importances': sorted_feature_importances,
        'top_features': top_features,
        'top_importances': top_importances,
        'categories': categories,
        'filtered_feature_names': filtered_feature_names
    }
    
    # ä¿å­˜ç‰¹å¾é‡è¦æ€§ç»“æœ
    feature_importance_file = os.path.join('output/feature_importance', 'feature_importance.json')
    try:
        with open(feature_importance_file, 'w') as f:
            json.dump({
                'feature_importances': {k: float(v) for k, v in sorted_feature_importances.items()},
                'top_features': top_features,
                'top_importances': [float(i) for i in top_importances],
                'categories': categories
            }, f, indent=2)
        print(f"Feature importance results saved to: {feature_importance_file}")
    except Exception as e:
        print(f"Error saving feature importance results: {e}")
    
    print(f"Feature importance analysis completed, saved to: output/feature_importance")
    return feature_importance_results 

def merge_geo_features(feature_importance, feature_values=None):
    """
    å°†ç»çº¬åº¦(longitudeå’Œlatitude)åˆå¹¶ä¸ºä¸€ä¸ªåœ°ç†ä½ç½®ç‰¹å¾(GEO)
    
    è¿™æ˜¯GeoShapleyåˆ†æä¸­çš„å¸¸ç”¨åšæ³•ï¼Œå› ä¸ºï¼š
    1. ç»çº¬åº¦æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªå¤åˆçš„åœ°ç†ä½ç½®ç‰¹å¾
    2. å•ç‹¬åˆ†æç»çº¬åº¦å¯èƒ½ä¼šä½ä¼°åœ°ç†ä½ç½®çš„æ•´ä½“é‡è¦æ€§
    3. åˆå¹¶åçš„GEOç‰¹å¾æ›´å¥½åœ°åæ˜ äº†ç©ºé—´ä½ç½®å¯¹ç›®æ ‡å˜é‡çš„å½±å“
    
    å‚æ•°:
    feature_importance: ç‰¹å¾é‡è¦æ€§åˆ—è¡¨ï¼Œæ ¼å¼ä¸º[(feature_name, importance), ...]
    feature_values: å¯é€‰ï¼Œç‰¹å¾SHAPå€¼å­—å…¸ {feature_name: shap_values}
    
    è¿”å›:
    merged_importance: åˆå¹¶åçš„ç‰¹å¾é‡è¦æ€§åˆ—è¡¨
    merged_values: åˆå¹¶åçš„ç‰¹å¾SHAPå€¼å­—å…¸(å¦‚æœfeature_valuesä¸ä¸ºNone)
    """
    import numpy as np
    
    geo_features = ['latitude', 'longitude']
    
    # åˆå§‹åŒ–ç»“æœ
    merged_importance = []
    merged_values = {} if feature_values is not None else None
    
    # æŸ¥æ‰¾ç»çº¬åº¦ç‰¹å¾çš„ç´¢å¼•å’Œå€¼
    geo_indices = []
    geo_importance_values = []
    found_geo_features = []
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰GEOç‰¹å¾
    has_existing_geo = any(feat.upper() == 'GEO' for feat, _ in feature_importance)
    
    if has_existing_geo:
        print(f"    ğŸ“ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„GEOç‰¹å¾")
        print(f"    â€¢ è¿™è¡¨æ˜GeoShapleyå·²ç»è‡ªåŠ¨åˆå¹¶äº†ç»çº¬åº¦")
        print(f"    â€¢ å°†ä¿æŒç°æœ‰ç‰¹å¾ä¸å˜ï¼ˆé˜²å¾¡æ€§æ£€æŸ¥é€šè¿‡ï¼‰")
        
        # ç›´æ¥è¿”å›åŸå§‹æ•°æ®
        if feature_values is not None:
            return feature_importance, feature_values
        else:
            return feature_importance
    
    print(f"    ğŸ” æŸ¥æ‰¾ç‹¬ç«‹çš„ç»çº¬åº¦ç‰¹å¾...")
    
    for i, (feature, importance) in enumerate(feature_importance):
        if feature.lower() in [g.lower() for g in geo_features]:
            geo_indices.append(i)
            geo_importance_values.append(importance)
            found_geo_features.append(feature)
            print(f"      â€¢ æ‰¾åˆ°åœ°ç†ç‰¹å¾: {feature} (é‡è¦æ€§: {importance:.6f})")
        else:
            merged_importance.append((feature, importance))
    
    # æ·»åŠ åˆå¹¶åçš„GEOç‰¹å¾
    if geo_indices:
        # ä½¿ç”¨æ›´ç§‘å­¦çš„åˆå¹¶ç­–ç•¥ï¼š
        # 1. å¦‚æœä¸¤ä¸ªç‰¹å¾éƒ½å­˜åœ¨ï¼Œä½¿ç”¨å®ƒä»¬çš„å¹³æ–¹å’Œçš„å¹³æ–¹æ ¹ï¼ˆæ¬§å‡ é‡Œå¾—è·ç¦»çš„æ¦‚å¿µï¼‰
        # 2. è¿™æ›´å¥½åœ°åæ˜ äº†åœ°ç†ä½ç½®ä½œä¸ºäºŒç»´å‘é‡çš„æœ¬è´¨
        if len(geo_importance_values) == 2:
            # ä¸¤ä¸ªåœ°ç†ç‰¹å¾éƒ½å­˜åœ¨ï¼Œä½¿ç”¨å‘é‡é•¿åº¦
            geo_combined_importance = np.sqrt(sum(imp**2 for imp in geo_importance_values))
            print(f"      â€¢ ä½¿ç”¨å‘é‡é•¿åº¦åˆå¹¶: sqrt({geo_importance_values[0]:.6f}Â² + {geo_importance_values[1]:.6f}Â²) = {geo_combined_importance:.6f}")
        else:
            # åªæœ‰ä¸€ä¸ªåœ°ç†ç‰¹å¾ï¼Œç›´æ¥ä½¿ç”¨å…¶å€¼
            geo_combined_importance = geo_importance_values[0]
            print(f"      â€¢ åªæ‰¾åˆ°ä¸€ä¸ªåœ°ç†ç‰¹å¾ï¼Œç›´æ¥ä½¿ç”¨å…¶é‡è¦æ€§: {geo_combined_importance:.6f}")
        
        merged_importance.append(('GEO', geo_combined_importance))
        print(f"    âœ… æˆåŠŸåˆ›å»ºGEOç‰¹å¾ï¼Œé‡è¦æ€§: {geo_combined_importance:.6f}")
    else:
        print(f"    â„¹ï¸ æœªæ‰¾åˆ°ç‹¬ç«‹çš„ç»çº¬åº¦ç‰¹å¾")
        print(f"    â€¢ å¯èƒ½æ•°æ®ä¸­ä¸åŒ…å«åœ°ç†ä¿¡æ¯")
        print(f"    â€¢ æˆ–åœ°ç†ç‰¹å¾ä½¿ç”¨äº†ä¸åŒçš„å‘½å")
    
    # æŒ‰é‡è¦æ€§æ’åº
    merged_importance.sort(key=lambda x: x[1], reverse=True)
    
    # å¦‚æœæä¾›äº†ç‰¹å¾SHAPå€¼ï¼Œä¹Ÿè¿›è¡Œåˆå¹¶
    if feature_values is not None:
        print(f"    ğŸ”— åŒæ­¥åˆå¹¶SHAPå€¼...")
        
        # å¤åˆ¶éåœ°ç†ç‰¹å¾çš„å€¼
        for feature in feature_values:
            if feature.lower() not in [g.lower() for g in geo_features]:
                merged_values[feature] = feature_values[feature]
        
        # åˆå¹¶åœ°ç†ç‰¹å¾çš„SHAPå€¼
        geo_shap_values = []
        geo_features_found = []
        
        for feature in geo_features:
            if feature in feature_values:
                geo_shap_values.append(np.array(feature_values[feature]))
                geo_features_found.append(feature)
        
        if geo_shap_values:
            if len(geo_shap_values) == 2:
                # ä¸¤ä¸ªåœ°ç†ç‰¹å¾éƒ½å­˜åœ¨ï¼Œä½¿ç”¨å‘é‡é•¿åº¦åˆå¹¶SHAPå€¼
                # å¯¹äºæ¯ä¸ªæ ·æœ¬ï¼Œè®¡ç®—å…¶ç»çº¬åº¦SHAPå€¼çš„å‘é‡é•¿åº¦
                lat_shap, lon_shap = geo_shap_values[0], geo_shap_values[1]
                geo_combined_shap = np.sqrt(lat_shap**2 + lon_shap**2)
                print(f"      â€¢ SHAPå€¼åˆå¹¶å®Œæˆï¼Œå½¢çŠ¶: {geo_combined_shap.shape}")
            else:
                # åªæœ‰ä¸€ä¸ªåœ°ç†ç‰¹å¾
                geo_combined_shap = geo_shap_values[0]
                print(f"      â€¢ ä½¿ç”¨å•ä¸ªåœ°ç†ç‰¹å¾çš„SHAPå€¼")
            
            merged_values['GEO'] = geo_combined_shap
    
    # æ€»ç»“
    if geo_indices:
        print(f"    ğŸ“Š åˆå¹¶æ€»ç»“: {len(found_geo_features)}ä¸ªåœ°ç†ç‰¹å¾ â†’ 1ä¸ªGEOç‰¹å¾")
    else:
        print(f"    ğŸ“Š æ— éœ€åˆå¹¶: ä¿æŒåŸæœ‰{len(feature_importance)}ä¸ªç‰¹å¾")
    
    return (merged_importance, merged_values) if feature_values is not None else merged_importance

def analyze_geoshapley_importance(model_results, feature_categories=None, merge_geo=True):
    """
    åˆ†æGeoShapleyå€¼å¹¶ç”Ÿæˆç‰¹å¾é‡è¦æ€§ç»“æœï¼Œä¸åŸå§‹analyze_feature_importanceå…¼å®¹
    
    å‚æ•°:
    model_results: ST-GPRæ¨¡å‹è®­ç»ƒäº§ç”Ÿçš„ç»“æœå­—å…¸
    feature_categories: ç‰¹å¾ç±»åˆ«å­—å…¸
    merge_geo: æ˜¯å¦åˆå¹¶ç»çº¬åº¦ç‰¹å¾ä¸ºGEO
    
    è¿”å›:
    feature_importance_dict: åŒ…å«feature_importance, shap_valueså’Œfeature_contributionçš„å­—å…¸
    """
    from collections import defaultdict
    import numpy as np
    
    print("\nåˆ†æGeoShapleyç‰¹å¾é‡è¦æ€§ä¸è´¡çŒ®...")
    feature_importance_dict = {}
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨'explanations'é”®ä¿å­˜äº†å±€éƒ¨è§£é‡Š
    if 'explanations' in model_results and model_results['explanations'] is not None:
        local_explanations = model_results['explanations'].get('local_explanations')
        if local_explanations is not None:
            # æ–°ç‰ˆæœ¬çš„GeoShapleyè§£é‡Šæ ¼å¼
            shap_values = local_explanations.get('shapley_values')
            feature_names = local_explanations.get('feature_names')
        else:
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨global_importanceä¿å­˜äº†ç‰¹å¾é‡è¦æ€§
            global_importance = model_results['explanations'].get('global_importance')
            if global_importance:
                # ç›´æ¥ä½¿ç”¨å…¨å±€é‡è¦æ€§
                feature_importance = global_importance
                if merge_geo:
                    feature_importance = merge_geo_features(feature_importance)
                feature_importance_dict['feature_importance'] = feature_importance
                return feature_importance_dict
            else:
                print("è­¦å‘Š: åœ¨model_results['explanations']ä¸­æ‰¾ä¸åˆ°å±€éƒ¨è§£é‡Š")
                return None
    # æ—§çš„æ–¹å¼ç›´æ¥æ£€æŸ¥shap_valuesé”®
    elif 'shap_values' in model_results and model_results['shap_values'] is not None:
        shap_values = model_results['shap_values']
        feature_names = model_results.get('feature_names', [])
    else:
        # æ£€æŸ¥æ¨¡å‹çš„feature_importance
        if 'feature_importance' in model_results:
            feature_importance = model_results['feature_importance']
            if merge_geo:
                feature_importance = merge_geo_features(feature_importance)
            feature_importance_dict['feature_importance'] = feature_importance
            return feature_importance_dict
        else:
            print("è­¦å‘Š: åœ¨model_resultsä¸­æ‰¾ä¸åˆ°ä»»ä½•ç‰¹å¾é‡è¦æ€§ä¿¡æ¯")
            return None
    
    # å¦‚æœæ²¡æœ‰ç‰¹å¾åç§°åˆ—è¡¨
    if not feature_names:
        print("è­¦å‘Š: æ— æ³•è·å–ç‰¹å¾åç§°")
        return None
    
    # è·å–SHAPå€¼ï¼Œç¡®ä¿æ˜¯äºŒç»´æ•°ç»„
    if isinstance(shap_values, np.ndarray):
        if shap_values.ndim == 1 and len(feature_names) > 1:
            # å¦‚æœæ˜¯ä¸€ç»´æ•°ç»„ä½†æœ‰å¤šä¸ªç‰¹å¾ï¼Œå¯èƒ½éœ€è¦é‡å¡‘
            shap_values = shap_values.reshape(-1, len(feature_names))
        elif shap_values.ndim > 2:
            # å¦‚æœæ˜¯é«˜ç»´æ•°ç»„ï¼Œå°è¯•è½¬æ¢ä¸ºäºŒç»´
            shap_values = shap_values.reshape(-1, len(feature_names))
    
    # ç¡®ä¿shap_valuesæ˜¯äºŒç»´æ•°ç»„
    if not isinstance(shap_values, np.ndarray) or shap_values.ndim != 2:
        print(f"è­¦å‘Š: SHAPå€¼æ ¼å¼ä¸æ­£ç¡®")
        return None
    
    # æ£€æŸ¥SHAPå€¼çš„åˆ—æ•°æ˜¯å¦ä¸ç‰¹å¾æ•°é‡åŒ¹é…
    if shap_values.shape[1] != len(feature_names):
        print(f"è­¦å‘Š: SHAPå€¼åˆ—æ•° ({shap_values.shape[1]}) ä¸åŒ¹é…ç‰¹å¾æ•°é‡ ({len(feature_names)})")
        return None
    
    # ä¿®æ”¹ç‰¹å¾é‡è¦æ€§è®¡ç®—éƒ¨åˆ†
    feature_importance = []
    
    # å°†SHAPå€¼æŒ‰ç‰¹å¾åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡é‡è¦æ€§
    shap_values_by_feature = {}
    for j, feature in enumerate(feature_names):
        if j < shap_values.shape[1]:
            feature_shap = shap_values[:, j]
            # ä½¿ç”¨å¹³å‡ç»å¯¹SHAPå€¼ä½œä¸ºç‰¹å¾é‡è¦æ€§
            importance = np.abs(feature_shap).mean()
            feature_importance.append((feature, importance))
            shap_values_by_feature[feature] = feature_shap
    
    # å½’ä¸€åŒ–ç‰¹å¾é‡è¦æ€§
    if feature_importance:
        max_importance = max([importance for _, importance in feature_importance])
        if max_importance > 0:
            feature_importance = [(feature, importance / max_importance) 
                                for feature, importance in feature_importance]
    
    # å¯¹ç‰¹å¾é‡è¦æ€§è¿›è¡Œæ’åº
    feature_importance.sort(key=lambda x: x[1], reverse=True)
    
    # åˆå¹¶ç»çº¬åº¦ç‰¹å¾
    if merge_geo:
        feature_importance, shap_values_by_feature = merge_geo_features(
            feature_importance, shap_values_by_feature)
    
    # ä¿å­˜ç‰¹å¾é‡è¦æ€§
    feature_importance_dict['feature_importance'] = feature_importance
    feature_importance_dict['shap_values_by_feature'] = shap_values_by_feature
    
    # æŒ‰ç±»åˆ«ç»„ç»‡ç‰¹å¾
    if feature_categories is None:
        # åˆ›å»ºè‡ªåŠ¨åˆ†ç±»
        feature_categories = {}
        for feature in feature_names:
            feature_categories[feature] = categorize_feature(feature)
    
    # æŒ‰ç±»åˆ«åˆ†ç»„ç‰¹å¾é‡è¦æ€§
    category_importance = defaultdict(list)
    for feature, importance in feature_importance:
        category = feature_categories.get(feature, 'Spatial')
        category_importance[category].append((feature, importance))
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å¹³å‡é‡è¦æ€§
    category_avg_importance = {}
    for category, features in category_importance.items():
        if features:
            avg_importance = sum(imp for _, imp in features) / len(features)
            category_avg_importance[category] = avg_importance
    
    # å°†ç±»åˆ«é‡è¦æ€§æŒ‰ä»é«˜åˆ°ä½æ’åº
    sorted_categories = sorted(category_avg_importance.items(), key=lambda x: x[1], reverse=True)
    
    # ä¿å­˜ç±»åˆ«é‡è¦æ€§
    feature_importance_dict['category_importance'] = sorted_categories
    
    # ä¿å­˜æŒ‰ç±»åˆ«åˆ†ç»„çš„ç‰¹å¾é‡è¦æ€§
    feature_importance_dict['features_by_category'] = dict(category_importance)
    
    # è®¡ç®—ç‰¹å¾è´¡çŒ®
    feature_contribution = defaultdict(list)
    
    # å¯¹æ¯ä¸ªæ ·æœ¬
    for i in range(shap_values.shape[0]):
        # è®¡ç®—è¯¥æ ·æœ¬çš„æ€»SHAPå€¼ï¼ˆæ‰€æœ‰ç‰¹å¾SHAPå€¼çš„æ€»å’Œï¼‰
        total_shap = np.sum(shap_values[i, :])
        
        # å¯¹æ¯ä¸ªç‰¹å¾ï¼Œè®¡ç®—å…¶ç›¸å¯¹è´¡çŒ®ï¼ˆè¯¥ç‰¹å¾çš„SHAPå€¼é™¤ä»¥æ€»SHAPå€¼çš„ç»å¯¹å€¼ï¼‰
        for j, feature in enumerate(feature_names):
            if np.abs(total_shap) > 1e-10:  # é¿å…é™¤ä»¥æ¥è¿‘é›¶çš„å€¼
                contribution = shap_values[i, j] / np.abs(total_shap)
            else:
                contribution = 0
            
            feature_contribution[feature].append(contribution)
    
    # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡è´¡çŒ®
    avg_contribution = {}
    for feature, contributions in feature_contribution.items():
        avg_contribution[feature] = np.mean(contributions)
    
    # ä¿å­˜ç‰¹å¾è´¡çŒ®
    feature_importance_dict['feature_contribution'] = avg_contribution
    
    # æ‰“å°å‰10ä¸ªé‡è¦ç‰¹å¾çš„ä¿¡æ¯
    print("\nGeoShapleyç‰¹å¾é‡è¦æ€§æ’åå‰10:")
    for i, (feature, importance) in enumerate(feature_importance[:10]):
        print(f"{i+1}. {feature}: {importance:.6f}")
    
    return feature_importance_dict 

def compute_feature_importance(model_results, method='model'):
    """
    è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼Œæ”¯æŒä¸åŒçš„æ–¹æ³•
    
    å‚æ•°:
    model_results: æ¨¡å‹è®­ç»ƒç»“æœå­—å…¸
    method: ä½¿ç”¨çš„ç‰¹å¾é‡è¦æ€§è®¡ç®—æ–¹æ³•ï¼Œå¯ä»¥æ˜¯'model'(ä½¿ç”¨æ¨¡å‹çš„get_feature_importanceæ–¹æ³•)æˆ–'geoshapley'
    
    è¿”å›:
    dict: ç‰¹å¾é‡è¦æ€§å­—å…¸ï¼Œæ ¼å¼ä¸º{feature_name: importance_score}
    """
    if model_results is None:
        print("è­¦å‘Š: æ¨¡å‹ç»“æœä¸ºNoneï¼Œæ— æ³•è®¡ç®—ç‰¹å¾é‡è¦æ€§")
        return {}
    
    # é¦–å…ˆæ£€æŸ¥model_resultsä¸­çš„feature_importanceæ˜¯å¦å·²ç»å­˜åœ¨
    if 'feature_importance' in model_results and model_results['feature_importance']:
        # æ£€æŸ¥ç±»å‹æ˜¯å¦ä¸ºåˆ—è¡¨ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è½¬æ¢ä¸ºå­—å…¸
        if isinstance(model_results['feature_importance'], list):
            # è½¬æ¢ä¸ºå­—å…¸ [(name, value)] -> {name: value}
            return {name: value for name, value in model_results['feature_importance']}
        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç›´æ¥è¿”å›
        if isinstance(model_results['feature_importance'], dict):
            return model_results['feature_importance']
    
    # å¦‚æœæ˜¯ST-GPRæ¨¡å‹ï¼Œå°è¯•ä½¿ç”¨æ¨¡å‹çš„get_feature_importanceæ–¹æ³•
    if method == 'model':
        model = model_results.get('model')
        feature_names = model_results.get('feature_names')
        
        if model is not None and hasattr(model, 'get_feature_importance') and feature_names:
            # ä½¿ç”¨æ¨¡å‹çš„ç‰¹å¾é‡è¦æ€§è®¡ç®—æ–¹æ³•
            importance_list = model.get_feature_importance(feature_names)
            return {name: importance for name, importance in importance_list}
    
    # å¦‚æœæ˜¯GeoShapleyæ–¹æ³•
    elif method == 'geoshapley':
        # æ£€æŸ¥æ˜¯å¦æœ‰GeoShapleyè§£é‡Šç»“æœ
        if 'explanations' in model_results and model_results['explanations']:
            # æå–å…¨å±€ç‰¹å¾é‡è¦æ€§
            global_importance = model_results['explanations'].get('global_importance')
            if global_importance:
                return {name: importance for name, importance in global_importance}
            
            # å¦‚æœæ²¡æœ‰å…¨å±€é‡è¦æ€§ï¼Œå°è¯•ä»å±€éƒ¨è§£é‡Šä¸­è®¡ç®—
            local_explanations = model_results['explanations'].get('local_explanations')
            if local_explanations and 'shapley_values' in local_explanations:
                shapley_values = local_explanations['shapley_values']
                feature_names = local_explanations.get('feature_names', [])
                
                if len(feature_names) > 0 and isinstance(shapley_values, np.ndarray):
                    # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡ç»å¯¹SHAPå€¼
                    mean_abs_shap = np.mean(np.abs(shapley_values), axis=0)
                    return {feature_names[i]: float(mean_abs_shap[i]) for i in range(len(feature_names))}
    
    # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥äº†ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨æ ¸å‡½æ•°å‚æ•°ä¸­çš„ç‰¹å¾æƒé‡
    if 'best_params' in model_results:
        best_params = model_results['best_params']
        feature_weights = None
        feature_names = model_results.get('feature_names', [])
        
        # æ£€æŸ¥ä¸åŒå¯èƒ½çš„å‚æ•°é”®
        for key in ['feature_weights', 'feature_lengthscales', 'p_function']:
            if key in best_params and best_params[key] is not None:
                feature_weights = best_params[key]
                break
        
        if feature_weights is not None and len(feature_names) == len(feature_weights):
            return {feature_names[i]: float(feature_weights[i]) for i in range(len(feature_weights))}
    
    # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œåˆ™è¿”å›ç©ºå­—å…¸
    print("è­¦å‘Š: æ— æ³•è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼Œè¿”å›ç©ºç»“æœ")
    return {}


def get_feature_classification(features):
    """
    å°†ç‰¹å¾åˆ—è¡¨æŒ‰ç…§ç±»åˆ«è¿›è¡Œåˆ†ç±»
    
    å‚æ•°:
    features: ç‰¹å¾åç§°åˆ—è¡¨
    
    è¿”å›:
    dict: åˆ†ç±»åçš„ç‰¹å¾å­—å…¸ï¼Œæ ¼å¼ä¸º{category: [feature1, feature2, ...]}
    """
    if not features:
        return {}
    
    # åˆå§‹åŒ–åˆ†ç±»å­—å…¸
    classification = {
        'Climate': [],
        'Human Activity': [],
        'Terrain': [],
        'Land Cover': [],
        'Time': [],
        'Spatial': []
    }
    
    # å¯¹æ¯ä¸ªç‰¹å¾è¿›è¡Œåˆ†ç±»
    for feature in features:
        # æ—¶é—´ç‰¹å¾
        if feature.lower() == 'year' or 't_lag' in feature.lower():
            classification['Time'].append(feature)
        # ç©ºé—´ç‰¹å¾
        elif feature.lower() in ['latitude', 'longitude', 'h3_index'] or 's_lag' in feature.lower():
            classification['Spatial'].append(feature)
        # å…¶ä»–ç‰¹å¾ä½¿ç”¨categorize_featureå‡½æ•°åˆ†ç±»
        else:
            category = categorize_feature(feature)
            classification[category].append(feature)
    
    # ç§»é™¤ç©ºç±»åˆ«
    return {k: v for k, v in classification.items() if v} 