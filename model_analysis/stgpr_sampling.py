#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ—¶ç©ºé«˜æ–¯è¿‡ç¨‹å›å½’æ¨¡å‹ (ST-GPR) - é‡‡æ ·æ¨¡å—

æœ¬æ¨¡å—åŒ…å«ST-GPRæ¨¡å‹çš„é‡‡æ ·ç›¸å…³åŠŸèƒ½ï¼š
1. æ—¶ç©ºåˆ†å±‚é‡‡æ · (perform_spatiotemporal_sampling)
2. æµ‹è¯•æ•°æ®é‡‡æ · (sample_data_for_testing)
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import StratifiedShuffleSplit


def perform_spatiotemporal_sampling(X_samples_df, sample_size, h3_col='h3_index', year_col='year', spatial_coverage=None, random_state=42):
    """
    æ‰§è¡Œä¸¤é˜¶æ®µæ—¶ç©ºåˆ†å±‚é‡‡æ ·ç­–ç•¥
    
    ç¬¬ä¸€é˜¶æ®µï¼šé€‰æ‹©ä¸€éƒ¨åˆ†H3ç½‘æ ¼ï¼Œå¹¶ä¿ç•™è¿™äº›ç½‘æ ¼çš„æ‰€æœ‰æ—¶é—´ç‚¹æ•°æ®
    ç¬¬äºŒé˜¶æ®µï¼šé€‰æ‹©ä¸€éƒ¨åˆ†æ—¶é—´æˆªé¢(å¹´ä»½)ï¼Œå¹¶ä¿ç•™è¿™äº›å¹´ä»½çš„æ‰€æœ‰ç½‘æ ¼æ•°æ®
    æœ€ç»ˆç»“æœï¼šè·å¾—é€‰ä¸­ç½‘æ ¼Ã—é€‰ä¸­å¹´ä»½çš„äº¤é›†æ ·æœ¬
    
    å‚æ•°:
    X_samples_df: DataFrameæ ¼å¼çš„æ ·æœ¬æ•°æ®
    sample_size: ç›®æ ‡æ ·æœ¬æ•°é‡
    h3_col: H3ç´¢å¼•åˆ—å
    year_col: å¹´ä»½åˆ—å
    spatial_coverage: ç©ºé—´è¦†ç›–ç‡å‚æ•°ï¼ˆå¯é€‰ï¼‰
    random_state: éšæœºç§å­
    
    è¿”å›:
    DataFrame: é‡‡æ ·åçš„æ•°æ®
    """
    # æ£€æŸ¥æ˜¯å¦åŒæ—¶å­˜åœ¨ç©ºé—´å’Œæ—¶é—´åˆ—
    has_h3 = h3_col in X_samples_df.columns
    has_year = year_col in X_samples_df.columns
    
    if has_h3 and has_year:
        # ä½¿ç”¨ä¸¤é˜¶æ®µåˆ†å±‚é‡‡æ ·ç­–ç•¥ï¼ˆå…ˆç©ºé—´åæ—¶é—´ï¼‰
        print("ä½¿ç”¨ä¸¤é˜¶æ®µæ—¶ç©ºåˆ†å±‚é‡‡æ ·...")
        
        # è·å–åŸºæœ¬ä¿¡æ¯
        unique_h3 = X_samples_df[h3_col].unique()
        unique_years = X_samples_df[year_col].unique()
        n_h3 = len(unique_h3)
        n_years = len(unique_years)
        
        # âš¡ ä½¿ç”¨ä¼ å…¥çš„ç©ºé—´è¦†ç›–ç‡å‚æ•°ï¼Œä¼˜å…ˆçº§æœ€é«˜
        if spatial_coverage is not None:
            target_spatial_coverage = spatial_coverage
            print(f"ä½¿ç”¨æŒ‡å®šçš„ç©ºé—´è¦†ç›–ç‡: {target_spatial_coverage*100:.1f}%")
        else:
            # é»˜è®¤ç­–ç•¥ï¼ˆå¦‚æœæ²¡æœ‰æŒ‡å®šè¦†ç›–ç‡ï¼‰
            if sample_size >= 10000:  # å¤§æ•°æ®é›†ï¼ˆå¦‚res7ï¼‰
                target_spatial_coverage = 0.25  # 25%ç©ºé—´è¦†ç›–ç‡
            elif sample_size >= 2000:  # ä¸­ç­‰æ•°æ®é›†ï¼ˆå¦‚res6ï¼‰
                target_spatial_coverage = 0.35  # 35%ç©ºé—´è¦†ç›–ç‡
            else:  # å°æ•°æ®é›†ï¼ˆå¦‚res5ï¼‰
                target_spatial_coverage = 0.50  # 50%ç©ºé—´è¦†ç›–ç‡
            print(f"ä½¿ç”¨é»˜è®¤ç©ºé—´è¦†ç›–ç‡: {target_spatial_coverage*100:.1f}%")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šé€‰æ‹©H3ç½‘æ ¼æ•°é‡ï¼ˆåŸºäºç©ºé—´è¦†ç›–ç‡ï¼‰
        target_h3_count = int(n_h3 * target_spatial_coverage)
        selected_h3_count = min(max(target_h3_count, 10), n_h3)  # è‡³å°‘10ä¸ªï¼Œæœ€å¤šå…¨éƒ¨
        
        # ç¬¬äºŒé˜¶æ®µï¼šä¿æŒå…¨éƒ¨å¹´ä»½è¦†ç›–ï¼ˆ25å¹´ï¼Œ2000-2024ï¼‰
        selected_years_count = n_years  # ä½¿ç”¨å…¨éƒ¨å¹´ä»½ï¼Œä¿æŒå®Œæ•´æ—¶é—´è¦†ç›–
        
        print(f"é€‰æ‹©ç­–ç•¥: {selected_h3_count}ç½‘æ ¼ Ã— {selected_years_count}å¹´ä»½ = {selected_h3_count * selected_years_count}æ ·æœ¬")
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šéšæœºé€‰æ‹©H3ç½‘æ ¼
            np.random.seed(random_state)
            selected_h3_values = np.random.choice(unique_h3, size=selected_h3_count, replace=False)
            
            # ç¬¬äºŒé˜¶æ®µï¼šéšæœºé€‰æ‹©å¹´ä»½
            np.random.seed(random_state + 1)  # ä¸åŒçš„éšæœºç§å­
            selected_years = np.random.choice(unique_years, size=selected_years_count, replace=False)
            
            # è·å–äº¤é›†æ ·æœ¬ï¼šé€‰ä¸­ç½‘æ ¼ AND é€‰ä¸­å¹´ä»½
            mask_h3 = X_samples_df[h3_col].isin(selected_h3_values)
            mask_year = X_samples_df[year_col].isin(selected_years)
            sampled_df = X_samples_df[mask_h3 & mask_year].copy()
            
            # ğŸ”¥ ä¸å†è¿›è¡Œå­é‡‡æ ·é™åˆ¶ï¼Œè®©å®é™…æ ·æœ¬é‡è‡ªç„¶äº§ç”Ÿ
            # å®é™…æ ·æœ¬é‡ = é€‰ä¸­ç½‘æ ¼æ•° Ã— 25å¹´ï¼ˆ2000-2024ï¼‰ Ã— æ¯ä¸ªç½‘æ ¼æ¯å¹´çš„å¹³å‡è®°å½•æ•°
                
        except Exception as e:
            print(f"æ—¶ç©ºåˆ†å±‚é‡‡æ ·å¤±è´¥: {str(e)}")
            print("å›é€€åˆ°éšæœºé‡‡æ ·...")
            # éšæœºé‡‡æ ·
            indices = np.random.RandomState(random_state).choice(len(X_samples_df), size=min(sample_size, len(X_samples_df)), replace=False)
            sampled_df = X_samples_df.iloc[indices]
    
    elif has_h3:
        # ä»…ç©ºé—´åˆ†å±‚é‡‡æ ·
        print("ä½¿ç”¨ç©ºé—´åˆ†å±‚é‡‡æ ·...")
        n_spatial_classes = X_samples_df[h3_col].nunique()
        
        # è®¡ç®—éœ€è¦é€‰æ‹©çš„ç½‘æ ¼æ•°é‡
        samples_per_h3 = len(X_samples_df) // n_spatial_classes
        selected_h3_count = min(max(sample_size // samples_per_h3, 1), n_spatial_classes)
        
        try:
            # éšæœºé€‰æ‹©H3ç½‘æ ¼
            selected_h3_values = np.random.RandomState(random_state).choice(
                X_samples_df[h3_col].unique(), 
                size=selected_h3_count, 
                replace=False
            )
            sampled_df = X_samples_df[X_samples_df[h3_col].isin(selected_h3_values)].copy()
            
            # å¦‚æœæ ·æœ¬é‡è¶…è¿‡ç›®æ ‡ï¼Œè¿›è¡Œéšæœºå­é‡‡æ ·
            if len(sampled_df) > sample_size:
                indices = np.random.RandomState(random_state + 1).choice(
                    len(sampled_df), size=sample_size, replace=False
                )
                sampled_df = sampled_df.iloc[indices].copy()
            
        except Exception as e:
            print(f"ç©ºé—´åˆ†å±‚é‡‡æ ·å¤±è´¥: {str(e)}")
            print("å›é€€åˆ°éšæœºé‡‡æ ·...")
            # å›é€€åˆ°éšæœºé‡‡æ ·
            sampled_df = X_samples_df.sample(n=sample_size, random_state=random_state)
    
    elif has_year:
        # ä»…æ—¶é—´åˆ†å±‚é‡‡æ ·
        print("ä½¿ç”¨æ—¶é—´åˆ†å±‚é‡‡æ ·...")
        try:
            # è·å–å¹´ä»½ä¿¡æ¯
            years = X_samples_df[year_col].round().astype(int).unique()
            n_years = len(years)
            
            # è®¡ç®—éœ€è¦é€‰æ‹©çš„å¹´ä»½æ•°é‡
            samples_per_year = len(X_samples_df) // n_years
            selected_years_count = min(max(sample_size // samples_per_year, 1), n_years)
            
            # éšæœºé€‰æ‹©å¹´ä»½
            selected_years = np.random.RandomState(random_state).choice(
                years, 
                size=selected_years_count, 
                replace=False
            )
            sampled_df = X_samples_df[X_samples_df[year_col].round().astype(int).isin(selected_years)].copy()
            
            # å¦‚æœæ ·æœ¬é‡è¶…è¿‡ç›®æ ‡ï¼Œè¿›è¡Œéšæœºå­é‡‡æ ·
            if len(sampled_df) > sample_size:
                indices = np.random.RandomState(random_state + 1).choice(
                    len(sampled_df), size=sample_size, replace=False
                )
                sampled_df = sampled_df.iloc[indices].copy()
            
        except Exception as e:
            print(f"æ—¶é—´åˆ†å±‚é‡‡æ ·å¤±è´¥: {str(e)}")
            print("å›é€€åˆ°éšæœºé‡‡æ ·...")
            # å›é€€åˆ°éšæœºé‡‡æ ·
            sampled_df = X_samples_df.sample(n=sample_size, random_state=random_state)
    else:
        # æ²¡æœ‰åˆé€‚çš„åˆ†å±‚æ ‡ç­¾ï¼Œä½¿ç”¨éšæœºé‡‡æ ·
        print("ä½¿ç”¨éšæœºé‡‡æ ·...")
        sampled_df = X_samples_df.sample(n=sample_size, random_state=random_state)
    
    return sampled_df


def sample_data_for_testing(df, sample_rate=0.1, h3_col='h3_index', year_col='year', min_samples_per_h3=2, res_level=None, seed=42):
    """
    å¯¹æ•°æ®é›†è¿›è¡Œä¸¤é˜¶æ®µæ—¶ç©ºåˆ†å±‚é‡‡æ ·ï¼Œä¿ç•™ç©ºé—´å’Œæ—¶é—´åˆ†å¸ƒç‰¹æ€§
    ä½¿ç”¨ä¸GeoShapleyåˆ†æç›¸åŒçš„åˆ†å±‚é‡‡æ ·ç­–ç•¥
    
    å‚æ•°:
    df (DataFrame): åŸå§‹æ•°æ®é›†
    sample_rate (float): é‡‡æ ·æ¯”ä¾‹ï¼Œé»˜è®¤0.1è¡¨ç¤ºä¿ç•™10%çš„æ•°æ®
    h3_col (str): H3ç½‘æ ¼ç´¢å¼•åˆ—å
    year_col (str): å¹´ä»½åˆ—å
    min_samples_per_h3 (int): æ¯ä¸ªH3ç½‘æ ¼è‡³å°‘ä¿ç•™çš„æ ·æœ¬æ•°
    res_level (str): åˆ†è¾¨ç‡çº§åˆ«, ä¾‹å¦‚'res5'
    seed (int): éšæœºç§å­
    
    è¿”å›:
    DataFrame: é‡‡æ ·åçš„æ•°æ®é›†
    """
    # è®¾ç½®éšæœºç§å­
    np.random.seed(seed)
    
    # è®¡ç®—åˆå§‹ç›®æ ‡æ ·æœ¬é‡
    raw_sample_size = int(len(df) * sample_rate)
    
    # æ ¹æ®åˆ†è¾¨ç‡è‡ªåŠ¨è°ƒæ•´æ ·æœ¬å¤§å° - é‡‡ç”¨ä¸GeoShapleyç›¸åŒçš„ç­–ç•¥
    sample_size = raw_sample_size
    if res_level is not None:
        if res_level == 'res7':
            # res7åˆ†è¾¨ç‡ï¼šæœ€å¤§300è¡Œ
            sample_size = min(raw_sample_size, 300)
        elif res_level == 'res6':
            # res6åˆ†è¾¨ç‡ï¼šæœ€å¤§150è¡Œ
            sample_size = min(raw_sample_size, 150)
        elif res_level == 'res5':
            # res5åˆ†è¾¨ç‡ï¼šæœ€å¤§80è¡Œ
            sample_size = min(raw_sample_size, 80)
        
        if sample_size != raw_sample_size:
            print(f"{res_level}åˆ†è¾¨ç‡: è‡ªåŠ¨è®¾ç½®é‡‡æ ·ç›®æ ‡ä¸º{sample_size}è¡Œ (ä¼˜åŒ–å)")
    
    # è®°å½•åŸå§‹æ•°æ®ä¿¡æ¯
    orig_size = len(df)
    orig_h3_count = df[h3_col].nunique() if h3_col in df.columns else 0
    orig_year_count = df[year_col].nunique() if year_col in df.columns else 0
    
    print(f"åŸå§‹æ•°æ®: {orig_size:,}è¡Œ ({orig_h3_count}ç½‘æ ¼ Ã— {orig_year_count}å¹´ä»½)")
    print(f"ç›®æ ‡é‡‡æ ·: {sample_size}è¡Œ (çº¦{sample_size/orig_size*100:.1f}%)")
    
    # æ‰§è¡Œæ—¶ç©ºåˆ†å±‚é‡‡æ ·
    sampled_df = perform_spatiotemporal_sampling(
        df, sample_size, h3_col=h3_col, year_col=year_col, 
        spatial_coverage=None,  # ä½¿ç”¨é»˜è®¤ç­–ç•¥
        random_state=seed
    )
    
    # è®°å½•é‡‡æ ·åä¿¡æ¯
    sampled_size = len(sampled_df)
    sampled_h3_count = sampled_df[h3_col].nunique() if h3_col in sampled_df.columns else 0
    sampled_year_count = sampled_df[year_col].nunique() if year_col in sampled_df.columns else 0
    
    print(f"é‡‡æ ·ç»“æœ: {sampled_size}è¡Œ ({sampled_h3_count}ç½‘æ ¼ Ã— {sampled_year_count}å¹´ä»½) - å®é™…é‡‡æ ·ç‡{sampled_size/orig_size*100:.1f}%")
    
    return sampled_df 