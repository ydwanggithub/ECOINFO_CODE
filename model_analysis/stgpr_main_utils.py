#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æ—¶ç©ºé«˜æ–¯è¿‡ç¨‹å›å½’æ¨¡å‹ (ST-GPR) - ä¸»ç¨‹åºå·¥å…·å‡½æ•°

æœ¬æ¨¡å—åŒ…å«main.pyä¸­ä½¿ç”¨çš„å·¥å…·å‡½æ•°ï¼Œç”¨äºä¿æŒä¸»ç¨‹åºçš„ç®€æ´æ€§ï¼š
1. æ¸…ç†ç¼“å­˜åŠŸèƒ½
2. æ¨¡å—æ£€æŸ¥åŠŸèƒ½  
3. æ•°æ®åŠ è½½å’Œé‡‡æ ·ç­–ç•¥
4. æ¨¡å‹è®­ç»ƒåŒ…è£…å‡½æ•°
"""

import os
import sys
import shutil
import warnings
import numpy as np
import pandas as pd
import time

# æŠ‘åˆ¶tqdmçš„Jupyterç¯å¢ƒæ£€æµ‹è­¦å‘Š
warnings.filterwarnings("ignore", message="IProgress not found. Please update jupyter and ipywidgets.*")

# ç¦æ­¢ç”Ÿæˆ__pycache__ç›®å½•å’Œ.pycæ–‡ä»¶
sys.dont_write_bytecode = True

def clean_pycache():
    """
    æ¸…ç†é¡¹ç›®ä¸­æ‰€æœ‰çš„__pycache__ç›®å½•å’Œ.pycæ–‡ä»¶
    """
    print("ğŸ§¹ æ¸…ç†__pycache__ç›®å½•...")
    current_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # é¡¹ç›®æ ¹ç›®å½•
    cleaned_count = 0
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for root, dirs, files in os.walk(current_dir):
        # è·³è¿‡.gitç›®å½•å’Œå…¶ä»–éšè—ç›®å½•
        if '/.git' in root or '\\.git' in root:
            continue
            
        # åˆ é™¤__pycache__ç›®å½•
        if '__pycache__' in dirs:
            pycache_path = os.path.join(root, '__pycache__')
            try:
                shutil.rmtree(pycache_path)
                cleaned_count += 1
                print(f"  âœ“ å·²åˆ é™¤: {os.path.relpath(pycache_path, current_dir)}")
            except Exception as e:
                print(f"  âš ï¸ åˆ é™¤å¤±è´¥: {os.path.relpath(pycache_path, current_dir)} - {e}")
        
        # åˆ é™¤.pycæ–‡ä»¶
        for file in files:
            if file.endswith('.pyc'):
                pyc_path = os.path.join(root, file)
                try:
                    os.remove(pyc_path)
                    cleaned_count += 1
                    print(f"  âœ“ å·²åˆ é™¤: {os.path.relpath(pyc_path, current_dir)}")
                except Exception as e:
                    print(f"  âš ï¸ åˆ é™¤å¤±è´¥: {os.path.relpath(pyc_path, current_dir)} - {e}")
    
    if cleaned_count > 0:
        print(f"  ğŸ‰ æ¸…ç†å®Œæˆï¼Œå…±åˆ é™¤ {cleaned_count} ä¸ª__pycache__ç›®å½•æˆ–.pycæ–‡ä»¶\n")
    else:
        print(f"  âœ¨ é¡¹ç›®å·²æ¸…æ´ï¼Œæ²¡æœ‰æ‰¾åˆ°__pycache__ç›®å½•æˆ–.pycæ–‡ä»¶\n")

def check_module_availability():
    """
    æ£€æŸ¥å¿…è¦æ¨¡å—çš„å¯ç”¨æ€§
    
    è¿”å›:
    dict: åŒ…å«å„æ¨¡å—å¯ç”¨æ€§çŠ¶æ€çš„å­—å…¸
    """
    modules_status = {
        'HAS_STGPR': False,
        'HAS_GPYTORCH': False,
        'HAS_GEOSHAPLEY': False,
        'HAS_HYPEROPT': False,
        'MODELS_AVAILABLE': []
    }
    
    # æ£€æŸ¥PyTorchå’ŒGPyTorchå¯ç”¨æ€§ï¼ˆç”¨äºSTGPRï¼‰
    try:
        import torch
        import gpytorch
        modules_status['HAS_GPYTORCH'] = True
        print(f"âœ“ PyTorch {torch.__version__} å’Œ GPyTorch å¯ç”¨")
        print(f"âœ“ ä½¿ç”¨CPUè®¡ç®—")
    except ImportError:
        print("Ã— PyTorchæˆ–GPyTorchä¸å¯ç”¨ï¼Œæ— æ³•è®­ç»ƒST-GPRæ¨¡å‹")
    
    # æ£€æŸ¥STGPRæ¨¡å‹æ¨¡å—
    try:
        from model_analysis import stgpr
        modules_status['HAS_STGPR'] = True
        modules_status['MODELS_AVAILABLE'].append('ST-GPR')
        print("âœ“ STGPRæ¨¡å‹æ¨¡å—å¯ç”¨")
    except ImportError:
        print("Ã— STGPRæ¨¡å‹æ¨¡å—ä¸å¯ç”¨")
    
    # æ£€æŸ¥GeoShapleyï¼ˆç”¨äºå¯è§£é‡Šæ€§åˆ†æï¼‰
    try:
        from geoshapley import GeoShapleyExplainer
        modules_status['HAS_GEOSHAPLEY'] = True
        print("âœ“ GeoShapleyå¯ç”¨ï¼Œå¯ä»¥è®¡ç®—SHAPå€¼")
    except ImportError:
        print("Ã— GeoShapleyä¸å¯ç”¨ï¼Œæ— æ³•è®¡ç®—SHAPå€¼")
    
    # æ£€æŸ¥hyperoptï¼ˆç”¨äºè¶…å‚æ•°ä¼˜åŒ–ï¼‰
    try:
        from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
        modules_status['HAS_HYPEROPT'] = True
        print("âœ“ hyperoptå¯ç”¨ï¼Œå¯ä»¥è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–")
    except ImportError:
        print("Ã— hyperoptä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–")
    
    # æ£€æŸ¥scikit-learnï¼ˆåŸºç¡€æœºå™¨å­¦ä¹ åº“ï¼‰
    try:
        import sklearn
        print(f"âœ“ scikit-learn {sklearn.__version__}å¯ç”¨")
    except (ImportError, AttributeError):
        print("Ã— scikit-learnä¸å¯ç”¨æˆ–ç‰ˆæœ¬ä¸æ­£ç¡®")
    
    # æ‰“å°å¯ç”¨æ¨¡å‹æ‘˜è¦
    models = modules_status['MODELS_AVAILABLE']
    print(f"å¯ç”¨çš„æ¨¡å‹: {', '.join(models) if models else 'æ— '}")
    
    return modules_status

def create_train_evaluate_wrapper():
    """
    åˆ›å»ºtrain_evaluate_stgpr_modelçš„åŒ…è£…å‡½æ•°
    
    è¿”å›:
    function: åŒ…è£…åçš„è®­ç»ƒå‡½æ•°
    """
    # å°è¯•å¯¼å…¥åŸå§‹è®­ç»ƒå‡½æ•°
    try:
        from model_analysis.stgpr import train_evaluate_stgpr_model as stgpr_original_train_fn
        has_stgpr = True
        print("âœ“ æˆåŠŸå¯¼å…¥STGPRæ¨¡å‹æ¨¡å—")
    except ImportError:
        has_stgpr = False
        stgpr_original_train_fn = None
        print("âš  è­¦å‘Š: æ— æ³•å¯¼å…¥STGPRæ¨¡å‹æ¨¡å—")
    
    # å¯¼å…¥ç›¸å…³æ¨¡å—
    try:
        from data_processing.preprocessing import prepare_features_for_stgpr
        use_new_preprocessing = True
    except ImportError:
        # å›é€€åˆ°åŸæœ‰çš„ç‰¹å¾å‡†å¤‡æ–¹æ³•
        print("âš ï¸ æ— æ³•å¯¼å…¥æ–°çš„é¢„å¤„ç†æ¨¡å—ï¼Œä½¿ç”¨åŸæœ‰æ–¹æ³•")
        from model_analysis.stgpr_utils import prepare_features_for_stgpr
        use_new_preprocessing = False
    
    # å®šä¹‰åŒ…è£…å‡½æ•°
    def train_evaluate_stgpr_model(df, resolution=None, output_dir=None, use_gpu=False, 
                                  target='VHI', use_hyperopt=True, max_hyperopt_evals=10, 
                                  num_inducing_points=None, **kwargs):
        """
        STGPRæ¨¡å‹è®­ç»ƒä¸è¯„ä¼°çš„åŒ…è£…å‡½æ•°ï¼Œæ¥æ”¶DataFrameå¹¶å¤„ç†å‚æ•°
        
        å‚æ•°:
        df: åŒ…å«ç‰¹å¾å’Œç›®æ ‡çš„DataFrame
        resolution: åˆ†è¾¨ç‡çº§åˆ« (res5, res6, res7)
        output_dir: è¾“å‡ºç›®å½•
        use_gpu: æ˜¯å¦ä½¿ç”¨GPUï¼ˆæ³¨æ„ï¼šç°åœ¨å¼ºåˆ¶ä½¿ç”¨CPUï¼‰
        target: ç›®æ ‡å˜é‡å
        use_hyperopt: æ˜¯å¦ä½¿ç”¨è¶…å‚æ•°ä¼˜åŒ–
        max_hyperopt_evals: è¶…å‚æ•°ä¼˜åŒ–çš„æœ€å¤§è¯„ä¼°æ¬¡æ•°
        num_inducing_points: ç¨€ç–å˜åˆ†GPçš„è¯±å¯¼ç‚¹æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨é€‰æ‹©
        
        è¿”å›:
        dict: åŒ…å«æ¨¡å‹å’Œæ€§èƒ½æŒ‡æ ‡çš„å­—å…¸
        """
        if not has_stgpr:
            print("âŒ é”™è¯¯: æ— æ³•è¿è¡Œæ¨¡å‹è®­ç»ƒ - STGPRæ¨¡å‹ä¸å¯ç”¨")
            print("è¯·å®‰è£…å¿…è¦çš„ä¾èµ–åº“: pytorch, gpytorch (ç”¨äºSTGPR)")
            return None
        
        from model_analysis.core import ensure_dir_exists  # ç›´æ¥ä»coreå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
        import torch
        from sklearn.model_selection import train_test_split
        
        # ä½¿ç”¨prepare_features_for_stgprå¤„ç†DataFrame
        X, y = prepare_features_for_stgpr(df, target=target)
        
        # è®¾ç½®è¯±å¯¼ç‚¹æ•°é‡ (å¦‚æœä¸ºNoneï¼Œåˆ™æ ¹æ®æ•°æ®é‡è‡ªåŠ¨ç¡®å®š)
        if num_inducing_points is None:
            # æ ¹æ®æ•°æ®é›†å¤§å°è‡ªåŠ¨ç¡®å®šè¯±å¯¼ç‚¹æ•°é‡
            data_size = X.shape[0]
            if data_size > 50000:  # å¤§å‹æ•°æ®é›†
                num_inducing_points = 500  
            elif data_size > 10000:  # ä¸­ç­‰æ•°æ®é›†
                num_inducing_points = 300
            else:  # å°å‹æ•°æ®é›†
                num_inducing_points = min(200, max(50, data_size // 10))
            print(f"è‡ªåŠ¨è®¾ç½®è¯±å¯¼ç‚¹æ•°é‡: {num_inducing_points} (æ•°æ®é›†å¤§å°: {data_size}è¡Œ)")
        else:
            print(f"ä½¿ç”¨æŒ‡å®šçš„è¯±å¯¼ç‚¹æ•°é‡: {num_inducing_points}")
            
        # å‡†å¤‡æ¨¡å‹ä¿å­˜è·¯å¾„
        model_path = None
        if output_dir:
            ensure_dir_exists(output_dir)
            model_path = os.path.join(output_dir, f"stgpr_model_{resolution}.pt")
        
        # ğŸš€ æ™ºèƒ½è®¾å¤‡é€‰æ‹© - æ”¯æŒGPUåŠ é€Ÿ
        if use_gpu and torch.cuda.is_available():
            device = torch.device('cuda')
            print(f"  ğŸ® ä½¿ç”¨GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"  ğŸ“Š GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")
        else:
            device = torch.device('cpu')
            if use_gpu:
                print(f"  âš ï¸ GPUä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
            else:
                print(f"  ğŸ’» ä½¿ç”¨CPUè®¾å¤‡ (æŒ‰é…ç½®)")
        
        
        # è®¾ç½®ç‰¹å¾åç§°
        feature_names = X.columns.tolist()
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%æµ‹è¯•ï¼‰
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # è°ƒç”¨åŸå§‹è®­ç»ƒå‡½æ•°
        # ä¼ é€’åŸå§‹DataFrameç”¨äºè¯±å¯¼ç‚¹é€‰æ‹©
        result = stgpr_original_train_fn(
            X_train, y_train, 
            X_test=X_test, 
            y_test=y_test,
            feature_names=feature_names,
            num_inducing_points=num_inducing_points,  # æ˜ç¡®ä¼ é€’è¯±å¯¼ç‚¹æ•°é‡
            optimize_hyperparams=use_hyperopt,        # å¯ç”¨è´å¶æ–¯ä¼˜åŒ–
            max_evals=max_hyperopt_evals,
            model_path=model_path,
            device=device,
            X_train_full=df  # ä¼ é€’åŒ…å«h3_indexå’Œyearçš„åŸå§‹DataFrame
        )
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯
        if result is not None:
            # åŸºæœ¬ä¿¡æ¯
            result['resolution'] = resolution
            result['model_type'] = 'STGPR'
            result['output_dir'] = output_dir
            result['num_inducing_points'] = num_inducing_points
            
            # ç‰¹å¾æ•°æ® - ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„DataFrameéƒ½å­˜åœ¨
            result['X'] = X  # å®Œæ•´ç‰¹å¾æ•°æ®
            result['X_train'] = X_train  # è®­ç»ƒé›†ç‰¹å¾
            result['X_test'] = X_test    # æµ‹è¯•é›†ç‰¹å¾
            
            # ç›®æ ‡æ•°æ®
            result['y'] = y              # å®Œæ•´ç›®æ ‡æ•°æ®
            result['y_train'] = y_train  # è®­ç»ƒé›†ç›®æ ‡
            result['y_test'] = y_test    # æµ‹è¯•é›†ç›®æ ‡
            
            # åŸå§‹æ•°æ®ï¼ˆåŒ…å«h3_indexç­‰ç©ºé—´ä¿¡æ¯ï¼‰
            result['df'] = df            # åŸå§‹DataFrame
            result['raw_data'] = df      # ç”¨äºç©ºé—´åˆ†æ
            
            # ç¡®ä¿æœ‰é¢„æµ‹ç»“æœ
            if 'predictions' in result:
                predictions = result['predictions']
                if 'mean' in predictions:
                    result['y_pred'] = predictions['mean']
                elif 'y_pred' in predictions:
                    result['y_pred'] = predictions['y_pred']
            
            # ç¡®ä¿æœ‰æ€§èƒ½æŒ‡æ ‡
            if 'metrics' in result:
                # æ ‡å‡†åŒ–metricsæ ¼å¼
                metrics = result['metrics']
                standardized_metrics = {}
                
                # RÂ²
                if 'test_r2' in metrics:
                    standardized_metrics['r2'] = metrics['test_r2']
                elif 'R2' in metrics:
                    standardized_metrics['r2'] = metrics['R2']
                elif 'r2' in metrics:
                    standardized_metrics['r2'] = metrics['r2']
                
                # RMSE
                if 'test_rmse' in metrics:
                    standardized_metrics['rmse'] = metrics['test_rmse']
                elif 'RMSE' in metrics:
                    standardized_metrics['rmse'] = metrics['RMSE']
                elif 'rmse' in metrics:
                    standardized_metrics['rmse'] = metrics['rmse']
                
                # MAE
                if 'test_mae' in metrics:
                    standardized_metrics['mae'] = metrics['test_mae']
                elif 'MAE' in metrics:
                    standardized_metrics['mae'] = metrics['MAE']
                elif 'mae' in metrics:
                    standardized_metrics['mae'] = metrics['mae']
                
                result['test_metrics'] = standardized_metrics
                result['metrics'] = standardized_metrics
            
            # ç‰¹å¾åç§°åˆ—è¡¨
            result['feature_names'] = feature_names
            
            # ç¡®ä¿elevationåˆ—å­˜åœ¨
            if 'elevation' not in X_train.columns:
                print(f"âš ï¸ è­¦å‘Š: {resolution}çš„ç‰¹å¾ä¸­ç¼ºå°‘elevationåˆ—")
                # å¯ä»¥å°è¯•ä»åŸå§‹æ•°æ®ä¸­è·å–æˆ–ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
                if 'elevation' in df.columns:
                    # ä»åŸå§‹æ•°æ®åŒ¹é…elevation
                    train_indices = X_train.index
                    test_indices = X_test.index
                    
                    if all(idx in df.index for idx in train_indices):
                        result['X_train']['elevation'] = df.loc[train_indices, 'elevation']
                    if all(idx in df.index for idx in test_indices):
                        result['X_test']['elevation'] = df.loc[test_indices, 'elevation']
                        
            print(f"âœ… {resolution}æ¨¡å‹ç»“æœå·²å‡†å¤‡å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
        
        return result
    
    return train_evaluate_stgpr_model 