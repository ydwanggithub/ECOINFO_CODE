#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»˜å›¾æ¨¡å—: ç”¨äºç”ŸæˆSHAPç©ºé—´æ•æ„Ÿåº¦åˆ†æå’Œç‰¹å¾ç›®æ ‡åˆ†æå›¾è¡¨

æ”¯æŒçš„è§£é‡Šæ–¹æ³•ï¼š
- GeoShapleyå€¼ï¼ˆST-GPRæ¨¡å‹çš„ä¸»è¦è§£é‡Šæ–¹æ³•ï¼‰
- ä¼ ç»ŸSHAPå€¼ï¼ˆå‘åå…¼å®¹ï¼‰

è¯¥æ¨¡å—ä¸“é—¨ç”¨äºåˆ†æST-GPRæ¨¡å‹çš„ç©ºé—´æ•æ„Ÿæ€§ï¼Œé€šè¿‡èšç±»æ–¹æ³•
è¯†åˆ«ä¸åŒåœ°ç†åŒºåŸŸçš„æ¨¡å‹è¡Œä¸ºå·®å¼‚ã€‚
"""
# é˜²æ­¢é‡å¤è¾“å‡ºçš„å…¨å±€æ ‡å¿—
_PRINTED_MESSAGES = set()

def print_once(message):
    """åªæ‰“å°ä¸€æ¬¡çš„å‡½æ•°"""
    if message not in _PRINTED_MESSAGES:
        print(message)
        _PRINTED_MESSAGES.add(message)


import os
import numpy as np
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap, BoundaryNorm
from matplotlib.gridspec import GridSpec
from mpl_toolkits.axes_grid1 import make_axes_locatable
import matplotlib.patches as mpatches
import matplotlib as mpl
import seaborn as sns
from sklearn.manifold import TSNE
from scipy.stats import f_oneway
import pickle
from shapely.geometry import Polygon
import matplotlib.gridspec as gridspec
from matplotlib.lines import Line2D
import time

# å°è¯•å¯¼å…¥h3åº“ï¼Œæ”¯æŒå¤šç§ç‰ˆæœ¬
try:
    import h3
    H3_AVAILABLE = True
    print_once("æˆåŠŸå¯¼å…¥h3åº“")
except ImportError:
    try:
        # å°è¯•ä½¿ç”¨h3ronpyä½œä¸ºæ›¿ä»£
        from h3ronpy import h3
        H3_AVAILABLE = True
        print("ä½¿ç”¨h3ronpyä½œä¸ºh3åº“æ›¿ä»£")
    except ImportError:
        H3_AVAILABLE = False
        print("æœªèƒ½å¯¼å…¥h3åº“ï¼Œå°†ä½¿ç”¨ç‚¹æ›¿ä»£å¤šè¾¹å½¢")

from .regionkmeans_data import preprocess_data_for_clustering
from .regionkmeans_cluster import perform_spatial_clustering
from .base import enhance_plot_style, save_plot_for_publication, ensure_dir_exists
from .utils import simplify_feature_name_for_plot

# æ·»åŠ å±±ä½“é˜´å½±æ‰€éœ€çš„å¯¼å…¥
from scipy.ndimage import gaussian_filter
from scipy.interpolate import griddata
from matplotlib.colors import LightSource

__all__ = [
    'plot_regionkmeans_shap_clusters_by_resolution',
    'plot_regionkmeans_feature_target_analysis'
]

# æ³¨æ„ï¼šå…¨å±€æ ·å¼è®¾ç½®å·²ç§»è‡³å‡½æ•°å†…éƒ¨ï¼Œé¿å…æ¨¡å—å¯¼å…¥æ—¶çš„æ ·å¼å†²çª
# æ¯ä¸ªç»˜å›¾å‡½æ•°éƒ½ä½¿ç”¨å±€éƒ¨æ ·å¼ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ¥ç¡®ä¿æ ·å¼éš”ç¦»

def plot_regionkmeans_shap_clusters_by_resolution(results_by_resolution, output_dir=None, 
                                                 top_n=None, n_clusters=3, figsize=(14, 10)): # ä»(16, 10)æ”¹ä¸º(14, 10)å‡å°‘å®½åº¦
    """
    ä½¿ç”¨ç©ºé—´çº¦æŸèšç±»ç”ŸæˆSHAPçƒ­ç‚¹å›¾å’Œæ•æ„Ÿæ€§åŒºåŸŸåˆ†å¸ƒå›¾ï¼Œä¸ºæ¯ä¸ªåˆ†è¾¨ç‡(res7/res6/res5)åˆ›å»º2Ã—3å¸ƒå±€çš„å›¾åƒã€‚
    ä¸Šæ’å›¾ (a, b, c): SHAPçƒ­ç‚¹å›¾ï¼Œæ˜¾ç¤ºSHAPå€¼çš„ç©ºé—´åˆ†å¸ƒå¼ºåº¦
    ä¸‹æ’å›¾ (d, e, f): æ•æ„Ÿæ€§åŒºåŸŸåˆ†å¸ƒï¼Œå°†åŒºåŸŸæŒ‰SHAPå€¼èšç±»ä¸ºé«˜ã€ä¸­ã€ä½ä¸‰ç±»ï¼Œå¹¶ä¿æŒç©ºé—´è¿ç»­æ€§
    
    ä¸¥æ ¼å­¦ä¹ geoshapley_spatial_top3.pyçš„æ•°æ®å¤„ç†æ–¹æ³•ï¼Œè·å–å®Œæ•´çš„æ’å€¼ç½‘æ ¼æ•°æ®
    
    å‚æ•°:
    - results_by_resolution: æŒ‰åˆ†è¾¨ç‡ç»„ç»‡çš„ç»“æœå­—å…¸
    - output_dir: è¾“å‡ºç›®å½•ï¼Œä¸ºNoneæ—¶ä¸ä¿å­˜å›¾ç‰‡
    - top_n: ç”¨äºèšç±»çš„é¡¶çº§SHAPç‰¹å¾æ•°é‡
    - n_clusters: èšç±»æ•°é‡
    - figsize: å›¾åƒå¤§å°
    
    è¿”å›:
    - fig: ç”Ÿæˆçš„å›¾åƒå¯¹è±¡
    - cluster_results: åŒ…å«èšç±»ç»“æœçš„å­—å…¸
    """
    print("\nğŸ¨ åˆ›å»ºåŒºåŸŸèšç±»SHAPå›¾ï¼ˆå­¦ä¹ geoshapley_spatial_top3.pyçš„å®Œæ•´ç½‘æ ¼æ–¹æ³•ï¼‰...")
    
    # å¯¼å…¥geoshapley_spatial_top3.pyçš„æ ¸å¿ƒå‡½æ•°ï¼ˆä½¿ç”¨æ ‡å‡†å¯è§†åŒ–ï¼‰
    try:
        from .geoshapley_spatial_top3 import (
            get_full_h3_grid_data, map_shap_to_full_grid,
            ensure_elevation_data
        )
        print("  âœ… æˆåŠŸå¯¼å…¥geoshapley_spatial_top3çš„æ ¸å¿ƒå‡½æ•°")
    except ImportError as e:
        print(f"  âŒ æ— æ³•å¯¼å…¥geoshapley_spatial_top3å‡½æ•°: {e}")
        return None, None
    
    # ç¬¬ä¸€æ­¥ï¼šä¸¥æ ¼å­¦ä¹ geoshapley_spatial_top3.pyï¼Œç”Ÿæˆå®Œæ•´æ’å€¼ç½‘æ ¼æ•°æ®
    print("  ğŸ”§ å­¦ä¹ geoshapley_spatial_top3.pyï¼Œä¸º11ä¸ªä¸»æ•ˆåº”ç¯å¢ƒç‰¹å¾ç”Ÿæˆå®Œæ•´æ’å€¼ç½‘æ ¼æ•°æ®...")
    
    enhanced_results = {}
    for res in ['res7', 'res6', 'res5']:
        if res not in results_by_resolution:
            continue
            
        print(f"\n  ğŸ“Š ä¸º{res}ç”Ÿæˆå®Œæ•´æ’å€¼ç½‘æ ¼æ•°æ®...")
        res_data = results_by_resolution[res]
        
        # 1. è·å–å®Œæ•´çš„H3ç½‘æ ¼æ•°æ®ï¼ˆå­¦ä¹ geoshapley_spatial_top3.pyï¼‰
        full_h3_grid = get_full_h3_grid_data(res_data, res)
        if full_h3_grid is None:
            print(f"    âŒ {res}æ— æ³•è·å–å®Œæ•´H3ç½‘æ ¼")
            continue
        
        # 2. è·å–åŸå§‹SHAPæ•°æ®
        shap_values_by_feature = res_data.get('shap_values_by_feature', {})
        X_sample = res_data.get('X_sample') if 'X_sample' in res_data else res_data.get('X')
        
        if not shap_values_by_feature or X_sample is None:
            print(f"    âŒ {res}ç¼ºå°‘SHAPæ•°æ®")
            continue
        
        print(f"    ğŸ“Š åŸå§‹æ•°æ®: {len(X_sample)}ä¸ªé‡‡æ ·ç‚¹ï¼Œ{len(shap_values_by_feature)}ä¸ªSHAPç‰¹å¾")
        print(f"    ğŸ”² ç›®æ ‡ç½‘æ ¼: {len(full_h3_grid)}ä¸ªå®Œæ•´H3ç½‘æ ¼")
        
        # 3. å®šä¹‰11ä¸ªä¸»æ•ˆåº”ç¯å¢ƒç‰¹å¾
        target_features = {
            'temperature', 'precipitation',  # 2ä¸ªæ°”å€™ç‰¹å¾
            'nightlight', 'road_density', 'mining_density', 'population_density',  # 4ä¸ªäººç±»æ´»åŠ¨
            'elevation', 'slope',  # 2ä¸ªåœ°å½¢ç‰¹å¾
            'forest_area_percent', 'cropland_area_percent', 'impervious_area_percent'  # 3ä¸ªåœŸåœ°è¦†ç›–
        }
        
        # 4. å¯¹æ¯ä¸ªä¸»æ•ˆåº”ç‰¹å¾è¿›è¡Œæ’å€¼ï¼ˆä¸¥æ ¼å­¦ä¹ map_shap_to_full_gridï¼‰
        enhanced_shap_values = {}
        successful_interpolations = 0
        
        print(f"    ğŸ¯ å¯¹11ä¸ªä¸»æ•ˆåº”ç‰¹å¾è¿›è¡Œæ’å€¼ï¼ˆå­¦ä¹ geoshapley_spatial_top3.pyæ–¹æ³•ï¼‰...")
        for feat_name in target_features:
            if feat_name in shap_values_by_feature:
                try:
                    # ç›´æ¥ä½¿ç”¨geoshapley_spatial_top3.pyçš„æ˜ å°„å‡½æ•°
                    full_grid_with_shap = map_shap_to_full_grid(
                        {feat_name: shap_values_by_feature[feat_name]}, 
                        X_sample, 
                        full_h3_grid, 
                        feat_name
                    )
                    
                    if full_grid_with_shap is not None:
                        enhanced_shap_values[feat_name] = full_grid_with_shap['shap_value'].values
                        successful_interpolations += 1
                        print(f"      âœ“ {feat_name}: æ’å€¼æˆåŠŸ ({len(enhanced_shap_values[feat_name])}ä¸ªç½‘æ ¼)")
                    else:
                        print(f"      âŒ {feat_name}: æ’å€¼å¤±è´¥")
                        
                except Exception as e:
                    print(f"      âŒ {feat_name}: æ’å€¼å¼‚å¸¸: {e}")
        
        print(f"    ğŸ“ˆ æ’å€¼æ€»ç»“: {successful_interpolations}/11ä¸ªç‰¹å¾æˆåŠŸæ’å€¼")
        
        if successful_interpolations == 0:
            print(f"    âŒ {res}æ— æˆåŠŸæ’å€¼ç‰¹å¾ï¼Œè·³è¿‡")
            continue
        
        # 5. åˆ›å»ºå¢å¼ºçš„ç»“æœæ•°æ®
        enhanced_res_data = res_data.copy()
        enhanced_res_data['enhanced_full_h3_grid'] = full_h3_grid
        enhanced_res_data['enhanced_shap_values_by_feature'] = enhanced_shap_values
        
        enhanced_results[res] = enhanced_res_data
        
        print(f"    âœ… {res}å®Œæ•´ç½‘æ ¼æ•°æ®ç”ŸæˆæˆåŠŸ:")
        print(f"      â€¢ ç½‘æ ¼æ•°é‡: {len(full_h3_grid)}")
        print(f"      â€¢ ç¯å¢ƒç‰¹å¾: {len(enhanced_shap_values)}ä¸ª")
        print(f"      â€¢ æ•°æ®å¢å¼ºå€æ•°: {len(full_h3_grid)/len(X_sample):.1f}x")
    
    # ç¬¬äºŒæ­¥ï¼šåŸºäºå®Œæ•´æ’å€¼ç½‘æ ¼æ•°æ®è¿›è¡Œèšç±»é¢„å¤„ç†
    print(f"\n  ğŸ”§ åŸºäºå®Œæ•´æ’å€¼ç½‘æ ¼æ•°æ®è¿›è¡Œèšç±»é¢„å¤„ç†...")
    
    processed = {}
    for res, enhanced_res_data in enhanced_results.items():
        if 'enhanced_shap_values_by_feature' not in enhanced_res_data:
            continue
            
        try:
            # è·å–å¢å¼ºçš„æ•°æ®
            enhanced_shap_values_by_feature = enhanced_res_data['enhanced_shap_values_by_feature']
            full_h3_grid = enhanced_res_data['enhanced_full_h3_grid']
            
            # æ„å»ºSHAPç‰¹å¾çŸ©é˜µ
            feature_names = list(enhanced_shap_values_by_feature.keys())
            shap_matrix_list = [enhanced_shap_values_by_feature[feat] for feat in feature_names]
            shap_features = np.column_stack(shap_matrix_list)
            
            # æ„å»ºåæ ‡DataFrame
            coords_df = full_h3_grid[['latitude', 'longitude']].copy()
            if 'h3_index' in full_h3_grid.columns:
                coords_df['h3_index'] = full_h3_grid['h3_index']
            
            # è·å–ç›®æ ‡å€¼ï¼ˆVHIï¼‰
            target_values = None
            original_res_data = results_by_resolution[res]
            
            # å°è¯•å¤šç§æ–¹å¼è·å–VHIæ•°æ®
            original_y = None
            original_X = None
            
            # æ–¹æ³•1: ä»y_sampleè·å–
            if 'y_sample' in original_res_data and original_res_data['y_sample'] is not None:
                original_y = original_res_data['y_sample']
                original_X = original_res_data.get('X_sample')
                print(f"    {res}: ä»y_sampleè·å–VHIæ•°æ® ({len(original_y)}ä¸ªå€¼)")
            
            # æ–¹æ³•2: ä»yè·å–
            elif 'y' in original_res_data and original_res_data['y'] is not None:
                original_y = original_res_data['y']
                # æ­£ç¡®å¤„ç†DataFrameçš„è·å–ï¼Œé¿å…ambiguous truth valueé”™è¯¯
                if 'X' in original_res_data and original_res_data['X'] is not None:
                    original_X = original_res_data['X']
                else:
                    original_X = original_res_data.get('X_sample')
                print(f"    {res}: ä»yè·å–VHIæ•°æ® ({len(original_y)}ä¸ªå€¼)")
            
            # æ–¹æ³•3: ä»åŸå§‹DataFrameçš„VHIåˆ—è·å–
            elif 'df' in original_res_data and original_res_data['df'] is not None:
                df = original_res_data['df']
                if 'VHI' in df.columns:
                    # è·å–æœ‰VHIå€¼ä¸”æœ‰åæ ‡çš„è®°å½•
                    valid_vhi_mask = ~df['VHI'].isna() & ~df['latitude'].isna() & ~df['longitude'].isna()
                    if valid_vhi_mask.any():
                        original_y = df.loc[valid_vhi_mask, 'VHI'].values
                        original_X = df.loc[valid_vhi_mask, ['latitude', 'longitude', 'h3_index']].reset_index(drop=True)
                        print(f"    {res}: ä»dfçš„VHIåˆ—è·å–æ•°æ® ({len(original_y)}ä¸ªæœ‰æ•ˆå€¼)")
                    else:
                        print(f"    {res}: dfä¸­æ²¡æœ‰æœ‰æ•ˆçš„VHIæ•°æ®")
                else:
                    print(f"    {res}: dfä¸­æ²¡æœ‰VHIåˆ—")
            
            # å¦‚æœæˆåŠŸè·å–åˆ°VHIæ•°æ®ï¼Œè¿›è¡Œæ’å€¼
            if original_y is not None and original_X is not None and len(original_y) > 0:
                # ç¡®ä¿original_Xæ˜¯DataFrameä¸”åŒ…å«åæ ‡ä¿¡æ¯
                if isinstance(original_X, pd.Series):
                    original_X = original_X.to_frame().T
                elif not isinstance(original_X, pd.DataFrame):
                    original_X = pd.DataFrame(original_X)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰åæ ‡ä¿¡æ¯
                if 'latitude' in original_X.columns and 'longitude' in original_X.columns:
                    try:
                        from sklearn.neighbors import KNeighborsRegressor
                        
                        # ç¡®ä¿æ•°æ®é•¿åº¦åŒ¹é…
                        min_len = min(len(original_y), len(original_X))
                        original_y_aligned = original_y[:min_len]
                        original_X_aligned = original_X.iloc[:min_len]
                        
                        # ç§»é™¤NaNå€¼
                        valid_mask = (~pd.isna(original_y_aligned) & 
                                    ~pd.isna(original_X_aligned['latitude']) & 
                                    ~pd.isna(original_X_aligned['longitude']))
                        
                        if valid_mask.sum() > 0:
                            original_coords = original_X_aligned.loc[valid_mask, ['latitude', 'longitude']].values
                            original_y_clean = original_y_aligned[valid_mask]
                            enhanced_coords = coords_df[['latitude', 'longitude']].values
                            
                            # ä½¿ç”¨KNNæ’å€¼
                            n_neighbors = min(5, len(original_y_clean))
                            knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights='distance')
                            knn.fit(original_coords, original_y_clean)
                            target_values = knn.predict(enhanced_coords)
                            
                            # ç¡®ä¿VHIå€¼åœ¨åˆç†èŒƒå›´å†…
                            target_values = np.clip(target_values, 0, 1)
                            
                            print(f"    {res}: é€šè¿‡KNNæ’å€¼è·å–VHIç›®æ ‡å€¼ ({len(target_values)}ä¸ª)")
                            print(f"    {res}: VHIèŒƒå›´: [{np.min(target_values):.3f}, {np.max(target_values):.3f}], æ ‡å‡†å·®: {np.std(target_values):.3f}")
                        else:
                            print(f"    {res}: VHIæ•°æ®ä¸­æ²¡æœ‰æœ‰æ•ˆçš„åæ ‡ä¿¡æ¯")
                            target_values = np.full(len(coords_df), 0.5)
                            
                    except Exception as e:
                        print(f"    {res}: VHIæ’å€¼å¤±è´¥: {e}")
                        target_values = np.full(len(coords_df), 0.5)
                else:
                    print(f"    {res}: Xæ•°æ®ç¼ºå°‘åæ ‡ä¿¡æ¯")
                    target_values = np.full(len(coords_df), 0.5)
            else:
                print(f"    {res}: æ— æ³•è·å–VHIæ•°æ®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                target_values = np.full(len(coords_df), 0.5)
            
            # ä¿å­˜å¤„ç†åçš„æ•°æ®
            processed[res] = {
                'shap_features': shap_features,
                'coords_df': coords_df,
                'top_features': feature_names,
                'target_values': target_values
            }
            
            print(f"    âœ“ {res}: å®Œæ•´ç½‘æ ¼èšç±»æ•°æ®å‡†å¤‡å®Œæˆ")
            print(f"      â€¢ SHAPç‰¹å¾çŸ©é˜µ: {shap_features.shape}")
            print(f"      â€¢ åæ ‡æ•°æ®: {len(coords_df)}ä¸ªç½‘æ ¼")
            print(f"      â€¢ ç‰¹å¾åˆ—è¡¨: {', '.join(feature_names[:3])}...")
            
        except Exception as e:
            print(f"    âŒ {res}: èšç±»æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    if not processed:
        print("âŒ é”™è¯¯: æ— å¯ç”¨äºç©ºé—´èšç±»çš„å®Œæ•´ç½‘æ ¼SHAPæ•°æ®")
        return None, None
    
    print(f"  âœ… å®Œæ•´ç½‘æ ¼èšç±»æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œ{len(processed)}ä¸ªåˆ†è¾¨ç‡å¯ç”¨")
    
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´æ˜æ˜¾çš„è“çº¢æ¸å˜è‰²ï¼Œç¡®ä¿0-1èŒƒå›´çš„æ•°æ®èƒ½æ˜¾ç¤ºå®Œæ•´çš„é¢œè‰²è°±
    # hotspot_colors = ['#0027A5', '#4566D6', '#82A0F2', '#C4D3FF', '#FFCEC4', '#F49B82', '#D6654A', '#A50027']
    # ä½¿ç”¨ç»å…¸çš„è“ç™½çº¢colormapï¼Œç¡®ä¿é¢œè‰²æ¸å˜æ˜æ˜¾
    hotspot_cmap = plt.colormaps.get_cmap('RdBu_r')  # ğŸ¨ ä¿®æ”¹ä¸ºä¸geoshapley_spatial_top3.pngç›¸åŒçš„è‰²ç³»ï¼šçº¢-è“åå‘
    
    # ä¸ºæ•æ„Ÿæ€§åŒºåŸŸä½¿ç”¨ä¸€è‡´çš„coolwarmé…è‰²æ–¹æ¡ˆ
    sensitivity_colors = {
        'high': '#D32F2F',    # é«˜æ•æ„Ÿæ€§ç”¨çº¢è‰²
        'medium': '#F9A825',  # ä¸­æ•æ„Ÿæ€§ç”¨é»„è‰²
        'low': '#1976D2'      # ä½æ•æ„Ÿæ€§ç”¨è“è‰²
    }
    
    # åˆ›å»ºç¦»æ•£çš„æ•æ„Ÿæ€§colormap
    sensitivity_cmap = mpl.colors.ListedColormap([sensitivity_colors['high'], 
                                                 sensitivity_colors['medium'], 
                                                 sensitivity_colors['low']])
    
    # ä¿å­˜åŸå§‹rcParamså¹¶åˆ›å»ºæœ¬åœ°æ ·å¼å­—å…¸ï¼Œä»¥è¿›è¡Œæ ·å¼éš”ç¦»
    original_rcParams = plt.rcParams.copy()
    
    # åˆ›å»ºæœ¬åœ°æ ·å¼å­—å…¸ï¼Œä½¿ç”¨å¼ºåˆ¶è¦†ç›–ä»¥ç¡®ä¿æ ·å¼ç”Ÿæ•ˆ
    style_dict = {
        'font.family': 'serif',
        'font.serif': ['Times New Roman'],
        'font.size': 12,
        'font.weight': 'bold',  # è®¾ç½®å…¨å±€å­—ä½“ä¸ºç²—ä½“
        'axes.titlesize': 14,
        'axes.labelsize': 12,
        'axes.titleweight': 'bold',  # ç¡®ä¿æ ‡é¢˜ä½¿ç”¨ç²—ä½“
        'axes.labelweight': 'bold',  # ç¡®ä¿è½´æ ‡ç­¾ä½¿ç”¨ç²—ä½“
        'xtick.labelsize': 10,  # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å¤§å°
        'ytick.labelsize': 10,  # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å¤§å°
        'xtick.major.width': 1.5,  # åŠ ç²—åˆ»åº¦çº¿
        'ytick.major.width': 1.5,  # åŠ ç²—åˆ»åº¦çº¿
        'xtick.direction': 'in',  # åˆ»åº¦æœå†…
        'ytick.direction': 'in',  # åˆ»åº¦æœå†…
        'xtick.major.size': 4,   # åˆ»åº¦é•¿åº¦
        'ytick.major.size': 4,   # åˆ»åº¦é•¿åº¦
        'axes.linewidth': 1.5,  # åŠ ç²—è½´çº¿
        'legend.fontsize': 10,
        'legend.title_fontsize': 11,
        'figure.dpi': 600,
        'savefig.dpi': 600,
        'figure.figsize': figsize,
        'figure.constrained_layout.use': False,
        'axes.spines.top': True,
        'axes.spines.right': True,
        'axes.spines.bottom': True,
        'axes.spines.left': True,
    }
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨éš”ç¦»æ ·å¼è®¾ç½®
    with plt.style.context('default'):  # å…ˆé‡ç½®ä¸ºé»˜è®¤æ ·å¼
        with plt.rc_context(style_dict):  # å†åº”ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ ·å¼

            fig = plt.figure(figsize=figsize, dpi=600)
            fig.suptitle('SHAP-based Spatial Sensitivity Analysis by Resolution', fontweight='bold', y=0.97)
            # è°ƒæ•´é—´è·ï¼Œç¡®ä¿ colorbar ä¸ä¼šé‡å åˆ°ä¸‹æ–¹çš„æ•æ„Ÿæ€§åœ°å›¾ä¸Šï¼Œå¹¶ä¸”è°ƒå¤§ colorbar å’Œå›¾çš„è·ç¦»
            # è°ƒæ•´ top å’Œ bottomï¼Œç¡®ä¿æœ‰è¶³å¤Ÿç©ºé—´ç”¨äºæ€»æ ‡é¢˜å’Œcolorbar
            # ğŸ¨ å¢åŠ åˆ—é—´è·ï¼šä»0.05æ”¹ä¸º0.15ï¼Œè®©å­å›¾æ¨ªå‘ä¸è¦å¤ªè¿‘
            # è°ƒæ•´leftå’Œrightè¾¹è·ä¸º0.10/0.90ï¼Œä¸ºå¢åŠ çš„åˆ—é—´è·æä¾›ç©ºé—´
            fig.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.90, hspace=0.35, wspace=0.15)
            
            # å¼ºåˆ¶æ›´æ–°å¸ƒå±€ä»¥ç¡®ä¿æ­£ç¡®è®¡ç®—ä½ç½®
            fig.canvas.draw()
        
            # ğŸ¨ å¢åŠ åˆ—é—´è·ï¼šä»0.05æ”¹ä¸º0.15ï¼Œè®©å­å›¾æ¨ªå‘ä¸è¦å¤ªè¿‘
            gs = GridSpec(2, 3, figure=fig, height_ratios=[1, 1], width_ratios=[1, 1, 1], hspace=0.35, wspace=0.15)
            
            # åˆ†è¾¨ç‡æ ‡é¢˜
            resolutions = ['res7', 'res6', 'res5']
            res_titles = {
                'res7': 'H3 Resolution 7 (Micro)',
                'res6': 'H3 Resolution 6 (Meso)', 
                'res5': 'H3 Resolution 5 (Macro)'
            }
            
            # å­˜å‚¨èšç±»ç»“æœä»¥ä¾›åç»­ä½¿ç”¨
            cluster_results = {}

            
            # åœ¨å¼€å§‹éå†ä¹‹å‰ï¼Œåˆå§‹åŒ–åˆ—è¡¨ä»¥æ”¶é›†å­å›¾å’Œè¾¹ç•Œï¼š
            axes_hotspot = []
            axes_sensitivity = []
            bounds_list = []
            # ç§»é™¤ä¸å†éœ€è¦çš„è¾¹ç•Œä¿å­˜
            
            # å¤„ç†æ¯ä¸ªåˆ†è¾¨ç‡
            for j, res in enumerate(resolutions):
                if res not in processed:
                    # åˆ›å»ºç©ºç™½å­å›¾
                    ax_hotspot = fig.add_subplot(gs[0, j])
                    ax_sensitivity = fig.add_subplot(gs[1, j])
                    
                    ax_hotspot.text(0.5, 0.5, f"No data for {res}", 
                                 ha='center', fontsize=14, transform=ax_hotspot.transAxes)
                    ax_hotspot.axis('off')
                    
                    ax_sensitivity.text(0.5, 0.5, f"No data for {res}", 
                                    ha='center', fontsize=14, transform=ax_sensitivity.transAxes)
                    ax_sensitivity.axis('off')
                    continue
                    
                # è·å–æ•°æ®
                shap_features = processed[res]['shap_features']
                coords_df = processed[res]['coords_df']
                
                # ğŸ”¥ ä½¿ç”¨æ­£å¸¸çš„ç©ºé—´çº¦æŸèšç±»ï¼Œç¡®ä¿è¿ç»­åŒºåŸŸ
                print(f"å¯¹{res}ä½¿ç”¨ç©ºé—´çº¦æŸèšç±»ï¼Œè·å¾—è¿ç»­åŒºåŸŸ")
                # ğŸ¯ æ ¹æ®åˆ†è¾¨ç‡è°ƒæ•´ç©ºé—´çº¦æŸå¼ºåº¦
                if res == 'res7':
                    grid_disk_k = 1  # res7ä½¿ç”¨æœ€å°ç©ºé—´çº¦æŸï¼Œé¿å…è¿‡åº¦èšåˆä¸åŒSHAPå€¼åŒºåŸŸ
                    print(f"    {res}: ä½¿ç”¨æœ€å°ç©ºé—´çº¦æŸ(k=1)é¿å…SHAPçƒ­ç‚¹è¯¯åˆ†ç±»")
                elif res == 'res6':
                    grid_disk_k = 2  # res6ä½¿ç”¨ä¸­ç­‰ç©ºé—´çº¦æŸ
                    print(f"    {res}: ä½¿ç”¨ä¸­ç­‰ç©ºé—´çº¦æŸ(k=2)")
                else:  # res5
                    grid_disk_k = 3  # res5ä½¿ç”¨è¾ƒå¼ºç©ºé—´çº¦æŸ
                    print(f"    {res}: ä½¿ç”¨è¾ƒå¼ºç©ºé—´çº¦æŸ(k=3)")
                clusters, standardized_features = perform_spatial_clustering(shap_features, coords_df, n_clusters, grid_disk_k=grid_disk_k)
                
                # ğŸ”§ ä¿®å¤ï¼šå¯¹èšåˆSHAPå¹…åº¦ä½¿ç”¨æ›´æ•æ„Ÿçš„èšåˆæ–¹æ³•ï¼Œå¢å¼ºç©ºé—´å˜å¼‚æ€§
                
                # æ–¹æ³•1ï¼šæ ‡å‡†å¹³å‡ï¼ˆå¯èƒ½å¯¼è‡´å€¼è¿‡äºé›†ä¸­ï¼‰
                raw_shap_mean = np.abs(shap_features).mean(axis=1)
                
                # æ–¹æ³•2ï¼šä½¿ç”¨æœ€å¤§å€¼æˆ–90%åˆ†ä½æ•°ï¼Œçªå‡ºå½±å“æœ€å¼ºçš„ç‰¹å¾
                raw_shap_max = np.abs(shap_features).max(axis=1)  # ä½¿ç”¨æœ€å¤§å€¼ï¼Œçªå‡ºä¸»å¯¼ç‰¹å¾
                raw_shap_p90 = np.percentile(np.abs(shap_features), 90, axis=1)  # 90%åˆ†ä½æ•°
                
                # ğŸ¯ é‡‡ç”¨æ··åˆç­–ç•¥ï¼š70%å¹³å‡å€¼ + 30%æœ€å¤§å€¼ï¼Œå¢å¼ºç©ºé—´å¯¹æ¯”åº¦
                raw_shap = 0.7 * raw_shap_mean + 0.3 * raw_shap_max
                
                print(f"    ğŸ”§ èšåˆSHAPç­–ç•¥: 70%å‡å€¼ + 30%æœ€å¤§å€¼ï¼Œå¢å¼ºç©ºé—´å¯¹æ¯”åº¦")
                print(f"    ğŸ“Š åŸå§‹èšåˆå€¼èŒƒå›´: {raw_shap.min():.4f} - {raw_shap.max():.4f}")
                
                # å½’ä¸€åŒ–åˆ°0-1
                normed_shap = (raw_shap - raw_shap.min()) / (raw_shap.max() - raw_shap.min())
                
                # ç›´æ¥ä½¿ç”¨geoshapley_spatial_top3.pyçš„å‡ ä½•ç”Ÿæˆæ–¹æ³•
                try:
                    from .geoshapley_spatial_top3 import create_h3_geometry
                    if 'h3_index' in coords_df.columns:
                        geometry = create_h3_geometry(coords_df['h3_index'], coords_df)
                        print(f"    {res}: ä½¿ç”¨geoshapley_spatial_top3çš„H3å‡ ä½•ç”Ÿæˆæ–¹æ³•")
                    else:
                        # åˆ›å»ºé€‚å½“å¤§å°çš„ç¼“å†²åŒºï¼Œç¡®ä¿å¯è§æ€§
                        from shapely.geometry import Point
                        buffer_size = 0.008 if res == 'res7' else 0.015 if res == 'res6' else 0.025
                        geometry = [Point(row['longitude'], row['latitude']).buffer(buffer_size) 
                                  for _, row in coords_df.iterrows()]
                        print(f"    {res}: ä½¿ç”¨ç¼“å†²åŒºå‡ ä½•ï¼ˆç¼“å†²åŒºå¤§å°: {buffer_size}ï¼‰")
                except ImportError:
                    # å›é€€æ–¹æ³•
                    from shapely.geometry import Point
                    buffer_size = 0.008 if res == 'res7' else 0.015 if res == 'res6' else 0.025
                    geometry = [Point(row['longitude'], row['latitude']).buffer(buffer_size) 
                              for _, row in coords_df.iterrows()]
                    print(f"    {res}: ä½¿ç”¨å›é€€ç¼“å†²åŒºå‡ ä½•")
                except Exception as e:
                    print(f"    {res}: å‡ ä½•ç”Ÿæˆå¼‚å¸¸: {e}")
                    from shapely.geometry import Point
                    buffer_size = 0.008 if res == 'res7' else 0.015 if res == 'res6' else 0.025
                    geometry = [Point(row['longitude'], row['latitude']).buffer(buffer_size) 
                              for _, row in coords_df.iterrows()]
                
                # åˆ›å»ºGeoDataFrame
                hotspot_gdf = gpd.GeoDataFrame({'hotspot': normed_shap},
                                              geometry=geometry, crs='EPSG:4326')
                sensitivity_gdf = gpd.GeoDataFrame({'cluster': clusters},
                                                  geometry=geometry, crs='EPSG:4326')
                
                # ğŸ”§ ä¿®å¤ï¼šæ‰€æœ‰åˆ†è¾¨ç‡éƒ½ä¿æŒåŸæœ‰å‡ ä½•ä½“ï¼Œä¸åº”ç”¨æ©è†œè¿‡æ»¤
                print(f"    {res}: ä¿æŒåŸæœ‰å‡ ä½•ä½“ï¼ˆä¸åº”ç”¨æ©è†œï¼‰")
                
                # ç®€å•éªŒè¯å‡ ä½•æœ‰æ•ˆæ€§
                invalid_hotspot = ~hotspot_gdf.geometry.is_valid
                if invalid_hotspot.any():
                    print(f"    {res}: ä¿®å¤{invalid_hotspot.sum()}ä¸ªæ— æ•ˆçš„hotspotå‡ ä½•")
                    hotspot_gdf.loc[invalid_hotspot, 'geometry'] = hotspot_gdf.loc[invalid_hotspot, 'geometry'].buffer(0)
                
                invalid_sensitivity = ~sensitivity_gdf.geometry.is_valid
                if invalid_sensitivity.any():
                    print(f"    {res}: ä¿®å¤{invalid_sensitivity.sum()}ä¸ªæ— æ•ˆçš„sensitivityå‡ ä½•")
                    sensitivity_gdf.loc[invalid_sensitivity, 'geometry'] = sensitivity_gdf.loc[invalid_sensitivity, 'geometry'].buffer(0)
                
                # ç»˜åˆ¶ SHAP çƒ­ç‚¹å¤šè¾¹å½¢
                ax_hotspot = fig.add_subplot(gs[0, j])
                # ä½¿ç”¨ç­‰æ¯”ä¾‹åæ ‡
                ax_hotspot.set_aspect('equal', adjustable='box')
                
                # ğŸ”§ ä¿®å¤ï¼šå¯¹äº0-1èŒƒå›´çš„Aggregated SHAP Magnitudeï¼Œä½¿ç”¨ç®€å•çš„çº¿æ€§å½’ä¸€åŒ–
                vmin, vmax = normed_shap.min(), normed_shap.max()
                print(f"\nåˆ†è¾¨ç‡ {res} çš„SHAPå€¼èŒƒå›´:")
                print(f"SHAPå€¼èŒƒå›´: æœ€å°={vmin:.4f}, æœ€å¤§={vmax:.4f}, å‡å€¼={normed_shap.mean():.4f}, ä¸­ä½æ•°={np.median(normed_shap):.4f}")
                
                # ğŸ”§ ä¿®å¤ï¼šé’ˆå¯¹èšåˆSHAPå¹…åº¦çš„ç‰¹æ®Šåˆ†å¸ƒï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„å¯¹æ¯”åº¦å¢å¼º
                from matplotlib.colors import Normalize
                
                # åˆ†æèšåˆSHAPå¹…åº¦çš„åˆ†å¸ƒç‰¹å¾
                q25, q75 = np.percentile(normed_shap, [25, 75])
                iqr = q75 - q25
                print(f"  ğŸ“Š èšåˆSHAPå¹…åº¦åˆ†å¸ƒ: Q25={q25:.3f}, Q75={q75:.3f}, IQR={iqr:.3f}")
                
                # å¯¹äºèšåˆæ•°æ®ï¼Œä½¿ç”¨æ›´æ¿€è¿›çš„å¯¹æ¯”åº¦å¢å¼ºç­–ç•¥
                if iqr < 0.3:  # å¦‚æœåˆ†å¸ƒæ¯”è¾ƒé›†ä¸­
                    # ä½¿ç”¨æ›´æç«¯çš„ç™¾åˆ†ä½æ•°
                    p2, p98 = np.percentile(normed_shap, [2, 98])
                    print(f"  ğŸ¨ åˆ†å¸ƒé›†ä¸­ï¼Œä½¿ç”¨æç«¯ç™¾åˆ†ä½æ•°å¢å¼º: P2={p2:.3f}, P98={p98:.3f}")
                    norm = Normalize(vmin=p2, vmax=p98)
                else:
                    # ä½¿ç”¨æ ‡å‡†ç™¾åˆ†ä½æ•°
                    p5, p95 = np.percentile(normed_shap, [5, 95])
                    print(f"  ğŸ¨ ä½¿ç”¨æ ‡å‡†ç™¾åˆ†ä½æ•°å¢å¼º: P5={p5:.3f}, P95={p95:.3f}")
                    norm = Normalize(vmin=p5, vmax=p95)
                
                # H3 å¤šè¾¹å½¢ï¼Œä½¿ç”¨ç¦»æ•£çš„è‰²æ¡
                hotspot_gdf.plot(column='hotspot', ax=ax_hotspot,
                                cmap=hotspot_cmap, norm=norm, edgecolor='grey', linewidth=0.1)
                
                # æ·»åŠ é¢œè‰²æ¡ï¼ˆä½¿ç”¨æ ‡å‡†å¯è§†åŒ–ï¼‰
                try:
                    # æ·»åŠ é¢œè‰²æ¡
                    cbar = plt.colorbar(ax_hotspot.collections[0], ax=ax_hotspot, 
                                       shrink=0.8, aspect=30, pad=0.05,
                                       ticks=[0, 1, 2])
                    cbar.set_label(f'{res.upper()} SHAP Hotspot Level', fontsize=12, fontweight='bold')
                    cbar.set_ticklabels(['Low', 'Medium', 'High'])
                    
                    # è®¾ç½®æ ‡é¢˜å’Œæ ·å¼
                    ax_hotspot.set_title(f'{res.upper()}: SHAP Hotspots', fontweight='bold', fontsize=14)
                    ax_hotspot.set_xlabel('Longitude', fontweight='bold')
                    ax_hotspot.set_ylabel('Latitude', fontweight='bold')
                    
                    # ç§»é™¤åæ ‡è½´ä½†ä¿ç•™æ ‡ç­¾
                    ax_hotspot.set_xticks([])
                    ax_hotspot.set_yticks([])
                    
                    print(f"    âœ… {res} SHAPçƒ­ç‚¹å›¾æ ‡å‡†å¯è§†åŒ–å®Œæˆ")
                except Exception as e:
                    print(f"    âŒ {res} SHAPçƒ­ç‚¹å›¾æ ·å¼è®¾ç½®å¼‚å¸¸: {e}")
                    # ç¡®ä¿åœ¨å‡ºé”™æ—¶è¿˜æœ‰åŸºç¡€å›¾å½¢
                    hotspot_gdf.plot(column='hotspot', ax=ax_hotspot,
                                    cmap=hotspot_cmap, norm=norm, edgecolor='grey', linewidth=0.1)
                
                # è®¾ç½®åæ ‡è½´å’Œæ ‡é¢˜ï¼Œç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒ
                ax_hotspot.set_xlabel('Longitude', fontsize=10, fontweight='bold')
                ax_hotspot.set_ylabel('Latitude', fontsize=10, fontweight='bold')
                ax_hotspot.set_title(f"({chr(97+j)}) SHAP Hotspots - H3 Resolution {7-j} ({'Micro' if j==0 else 'Meso' if j==1 else 'Macro'})", 
                                  fontsize=12, fontweight='bold', loc='left')
                
                # ç²¾ç¡®è®¾ç½®åæ ‡åˆ»åº¦èŒƒå›´å’Œé—´éš”
                ax_hotspot.set_xticks(np.arange(114.0, 117.0, 0.5))
                ax_hotspot.set_yticks(np.arange(24.5, 27.5, 0.5))
                ax_hotspot.tick_params(axis='both', which='major', labelsize=8, direction='in', width=1.5, length=4)
                for label in ax_hotspot.get_xticklabels() + ax_hotspot.get_yticklabels():
                    label.set_fontweight('bold')
                ax_hotspot.grid(True, linestyle=':', color='grey', alpha=0.3)
                
                # åŠ ç²—åæ ‡è½´çº¿
                for spine in ax_hotspot.spines.values():
                    spine.set_linewidth(1.5)

                # åœ¨æ¯æ¬¡ç»˜åˆ¶hotspot_gdfåæ·»åŠ è¾¹ç•Œ
                bounds_list.append(hotspot_gdf.total_bounds)
                
                # åœ¨ç»˜åˆ¶ax_hotspotåï¼Œè¿½åŠ åˆ°åˆ—è¡¨
                axes_hotspot.append(ax_hotspot)
                enhance_plot_style(ax_hotspot)

                # ç»˜åˆ¶æ•æ„Ÿæ€§å¤šè¾¹å½¢
                ax_sensitivity = fig.add_subplot(gs[1, j])
                # ä½¿ç”¨ç­‰æ¯”ä¾‹åæ ‡
                ax_sensitivity.set_aspect('equal', adjustable='box')
                
                # ä¸ºæ•æ„Ÿæ€§åŒºåŸŸåˆ›å»ºç¦»æ•£çš„åˆ†ç±»colormapï¼Œç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒçš„é¢œè‰²
                # ä¸å†æŒ‰ç…§èšç±»ç´¢å¼•åˆ†é…ï¼Œè€Œæ˜¯æŒ‰ç…§å®é™…SHAPå€¼å¤§å°åˆ†é…é«˜ä¸­ä½æ•æ„Ÿåº¦
                # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨ç»å¯¹é˜ˆå€¼è€Œéç›¸å¯¹æ’åºï¼Œç¡®ä¿è·¨åˆ†è¾¨ç‡ä¸€è‡´æ€§
                cluster_mean_shap = {}
                for c in range(n_clusters):
                    if np.any(clusters == c):
                        # ğŸ”§ ä¿®å¤ï¼šä¸çƒ­ç‚¹å›¾ä¿æŒä¸€è‡´ï¼Œä¸å–ç»å¯¹å€¼ï¼Œä¿ç•™åŸå§‹SHAPåˆ†å¸ƒ
                        cluster_shap = shap_features[clusters == c].mean(axis=1)  # ä¿ç•™æ­£è´Ÿå€¼
                        cluster_mean_shap[c] = np.mean(np.abs(cluster_shap))  # åªåœ¨æœ€ç»ˆè®¡ç®—æ•æ„Ÿæ€§æ—¶å–ç»å¯¹å€¼
                    else:
                        cluster_mean_shap[c] = 0

                # ğŸ”¥ æ–°ç­–ç•¥ï¼šåŸºäºSHAPå€¼åˆ†å¸ƒç‰¹å¾çš„æ™ºèƒ½æ•æ„Ÿæ€§åˆ†ç±»
                # è®¡ç®—æ‰€æœ‰èšç±»çš„SHAPå€¼ç»Ÿè®¡
                all_shap_values = [cluster_mean_shap[c] for c in range(n_clusters)]
                shap_mean = np.mean(all_shap_values)
                shap_std = np.std(all_shap_values)
                shap_max = np.max(all_shap_values)
                shap_min = np.min(all_shap_values)
                
                print(f"    ğŸ“Š SHAPç»Ÿè®¡: å‡å€¼={shap_mean:.4f}, æ ‡å‡†å·®={shap_std:.4f}, èŒƒå›´=[{shap_min:.4f}, {shap_max:.4f}]")
                
                # æŒ‰SHAPå€¼æ’åºèšç±»
                sorted_clusters = sorted(range(n_clusters), key=lambda c: cluster_mean_shap[c], reverse=True)
                sensitivity_map = {}
                
                # ğŸ¯ åŸºäºSHAPå€¼åˆ†å¸ƒåŠ¨æ€è®¾å®šé˜ˆå€¼çš„ç­–ç•¥  
                if res == 'res7' or shap_std / shap_mean > 0.4:  # res7å¼ºåˆ¶ä½¿ç”¨ç›¸å¯¹é˜ˆå€¼ç­–ç•¥
                    print(f"    ğŸ“Š {res}SHAPå€¼å·®å¼‚æ˜¾è‘—ï¼Œä½¿ç”¨åŸºäºå·®å¼‚çš„åˆ†ç±»")
                    
                    # è®¡ç®—ç›¸å¯¹å·®å¼‚é˜ˆå€¼
                    high_threshold = shap_max * 0.8  # é«˜æ•æ„Ÿæ€§ï¼šæ¥è¿‘æœ€å¤§å€¼
                    low_threshold = shap_max * 0.5   # ä½æ•æ„Ÿæ€§ï¼šä½äºæœ€å¤§å€¼çš„50%
                    
                    print(f"    ğŸ“ˆ ç›¸å¯¹é˜ˆå€¼: é«˜æ•æ„Ÿæ€§â‰¥{high_threshold:.4f}, ä½æ•æ„Ÿæ€§â‰¤{low_threshold:.4f}")
                    
                    for c in range(n_clusters):
                        shap_val = cluster_mean_shap[c]
                        if shap_val >= high_threshold:
                            sensitivity_map[c] = 0  # High
                        elif shap_val <= low_threshold:
                            sensitivity_map[c] = 2  # Low
                        else:
                            sensitivity_map[c] = 1  # Medium
                else:
                    # SHAPå€¼å·®å¼‚ä¸å¤§ï¼Œä½¿ç”¨ç®€å•æ’åº
                    print(f"    ğŸ“Š {res}SHAPå€¼å·®å¼‚è¾ƒå°ï¼Œä½¿ç”¨æ’åºåˆ†ç±»")
                    for i, c in enumerate(sorted_clusters):
                        sensitivity_map[c] = min(i, 2)
                
                print(f"  {res}åŸºäºå†…éƒ¨ç›¸å¯¹æ’åºçš„æ•æ„Ÿæ€§åˆ†ç±»:")
                sensitivity_levels = ['High', 'Medium', 'Low']  # é‡æ–°å®šä¹‰
                for i, c in enumerate(sorted_clusters):
                    level = sensitivity_levels[sensitivity_map[c]]
                    shap_val = cluster_mean_shap[c]
                    rank = i + 1
                    print(f"    èšç±»{c}: SHAP={shap_val:.4f} (æ’å{rank}/{n_clusters}) â†’ {level}æ•æ„Ÿæ€§")

                # é‡æ–°æ˜ å°„èšç±»æ ‡ç­¾åˆ°æ•æ„Ÿåº¦çº§åˆ«
                sensitivity_gdf['sensitivity'] = sensitivity_gdf['cluster'].apply(lambda c: sensitivity_map[c])

                # åˆ›å»ºèšç±»é¢œè‰²æ˜ å°„
                cluster_colors = {
                    0: sensitivity_colors['high'],    # é«˜æ•æ„Ÿæ€§
                    1: sensitivity_colors['medium'],  # ä¸­æ•æ„Ÿæ€§
                    2: sensitivity_colors['low']      # ä½æ•æ„Ÿæ€§
                }

                # åˆ›å»ºèšç±»åˆ†ç±»é¢œè‰²æ˜ å°„å‡½æ•°
                def map_clusters_to_colors(sensitivity_val):
                    return cluster_colors[sensitivity_val]

                # æ·»åŠ é¢œè‰²æ˜ å°„åˆ—
                sensitivity_gdf['color'] = sensitivity_gdf['sensitivity'].apply(map_clusters_to_colors)

                # ä½¿ç”¨ç¦»æ•£é¢œè‰²ç»˜åˆ¶æ•æ„Ÿæ€§åŒºåŸŸ
                sensitivity_gdf.plot(
                    column='sensitivity', ax=ax_sensitivity,
                    cmap=sensitivity_cmap, categorical=True,
                    linewidth=0.1, edgecolor='grey'
                )
                
                # ä¿å­˜èšç±»ç»“æœ
                cluster_results[res] = {
                    'clusters': clusters,
                    'standardized_features': standardized_features,
                    'shap_features': shap_features,
                    'coords_df': coords_df,
                    'normalized_hotspot': normed_shap,
                    'top_features': processed[res]['top_features'],
                    'target_values': processed[res]['target_values'],
                    'sensitivity_map': sensitivity_map,
                    'cluster_mean_shap': cluster_mean_shap
                }
            
            # ç»Ÿä¸€åæ ‡èŒƒå›´
            if bounds_list:
                bounds_array = np.array(bounds_list)
                global_min_lon, global_min_lat = bounds_array[:,0].min(), bounds_array[:,1].min()
                global_max_lon, global_max_lat = bounds_array[:,2].max(), bounds_array[:,3].max()
                for idx, ax in enumerate(axes_hotspot + axes_sensitivity):
                    ax.set_xlim(global_min_lon, global_max_lon)
                    ax.set_ylim(global_min_lat, global_max_lat)
                    # ç¡®ä¿æ‰€æœ‰å­å›¾éƒ½æœ‰åæ ‡è½´æ ‡ç­¾å’Œåˆ»åº¦
                    if idx < len(axes_hotspot):  # top row
                        pass  # ä¿ç•™æ‰€æœ‰æ ‡ç­¾å’Œåˆ»åº¦
                    if idx % 3 != 0:  # éç¬¬ä¸€åˆ—
                        pass  # ä¿ç•™æ‰€æœ‰æ ‡ç­¾å’Œåˆ»åº¦
            
            # ç²¾ç¡®å¯¹é½æ¯ä¸ªåˆ†è¾¨ç‡çš„hotspot colorbar
            for j, ax in enumerate(axes_hotspot):
                
                # åœ¨è·å–ä½ç½®ä¹‹å‰å¼ºåˆ¶æ›´æ–°å¸ƒå±€
                fig.canvas.draw_idle()
                
                # ğŸ”§ ä¿®å¤ï¼šç¬¬ä¸€è¡ŒSHAPçƒ­ç‚¹å›¾ä½¿ç”¨è¿ç»­colorbarï¼ˆé…åˆè¿ç»­å½’ä¸€åŒ–ï¼‰
                # è·å–å½“å‰åˆ†è¾¨ç‡çš„SHAPå€¼èŒƒå›´
                if j < len(processed.keys()):
                    res_keys = list(processed.keys())
                    res = res_keys[j]
                    shap_data = processed[res]['coords_df']
                    if 'normalized_hotspot' in cluster_results[res]:
                        normed_shap_for_colorbar = cluster_results[res]['normalized_hotspot']
                        min_val = normed_shap_for_colorbar.min()
                        max_val = normed_shap_for_colorbar.max()
                    else:
                        min_val, max_val = 0.0, 1.0
                else:
                    min_val, max_val = 0.0, 1.0
                
                # åˆ›å»ºè¿ç»­çš„colorbar
                sm = mpl.cm.ScalarMappable(cmap=hotspot_cmap, norm=mpl.colors.Normalize(vmin=min_val, vmax=max_val))
                sm.set_array([])

                # ç²¾ç¡®å¯¹é½colorbarå®½åº¦å’Œä½ç½®
                bbox = ax.get_position()
                cbar_height = 0.02
                cbar_pad = 0.04  # ä»0.025å¢åŠ åˆ°0.04ï¼Œè¿›ä¸€æ­¥å¢åŠ ä¸æ¨ªè½´æ ‡æ³¨çš„é—´è·
                
                # è®¡ç®—colorbaråº•éƒ¨ä½ç½®ï¼Œç¡®ä¿ä¸ä¼šè¶…å‡ºåº•éƒ¨è¾¹ç•Œ
                cbar_bottom = bbox.y0 - cbar_pad - cbar_height
                
                # æ·»åŠ è¾¹ç•Œæ£€æŸ¥ï¼Œé˜²æ­¢colorbarä¸å›¾è¡¨é‡å æˆ–è¶…å‡ºè¾¹ç•Œ
                min_bottom = 0.08  # ä¸subplots_adjustçš„bottomå‚æ•°ä¸€è‡´
                if cbar_bottom < min_bottom:
                    cbar_bottom = min_bottom
                    # å¦‚æœç©ºé—´ä¸è¶³ï¼Œå‡å°padding
                    actual_pad = bbox.y0 - cbar_height - cbar_bottom
                    if actual_pad < 0.005:  # æœ€å°padding
                        # è°ƒæ•´colorbaré«˜åº¦
                        cbar_height = min(0.015, bbox.y0 - cbar_bottom - 0.005)
                
                cax = fig.add_axes([bbox.x0, cbar_bottom, bbox.width, cbar_height])
                
                # åˆ›å»ºè¿ç»­çš„colorbar
                cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')
                
                # è®¾ç½®5ä¸ªå‡åŒ€åˆ†å¸ƒçš„åˆ»åº¦
                tick_values = np.linspace(min_val, max_val, 5)
                cbar.set_ticks(tick_values)
                cbar.set_ticklabels([f'{v:.2f}' for v in tick_values])
                cbar.set_label('Aggregated SHAP Magnitude', fontsize=10, fontweight='bold')
                cbar.ax.tick_params(labelsize=8, width=1.5, length=4)
                for t in cbar.ax.get_xticklabels():
                    t.set_fontweight('bold')

            # åº•éƒ¨å›¾ä¾‹
            sensitivity_labels = ['High Sensitivity', 'Medium Sensitivity', 'Low Sensitivity']
            for j, ax in enumerate(axes_sensitivity):
                legend_handles = [
                    mpatches.Patch(color=sensitivity_colors['high'], label=sensitivity_labels[0]),
                    mpatches.Patch(color=sensitivity_colors['medium'], label=sensitivity_labels[1]),
                    mpatches.Patch(color=sensitivity_colors['low'], label=sensitivity_labels[2])
                ]
                legend = ax.legend(handles=legend_handles, loc='upper left', frameon=False, fontsize=8,
                                 title='Sensitivity', title_fontsize=9,
                                 borderpad=0.5, labelspacing=0.3)
                # è®¾ç½®å›¾ä¾‹æ ‡é¢˜ä¸ºç²—ä½“
                for text in legend.get_texts():
                    text.set_fontweight('bold')
                legend.get_title().set_fontweight('bold')
                # è°ƒæ•´å›¾ä¾‹ä¸­è‰²å—çš„å¤§å°
                for handle in legend.legend_handles:
                    handle.set_height(8)
                    handle.set_width(16)

            # ä¿å­˜å›¾è¡¨å’Œæ•°æ®
            if output_dir:
                if ensure_dir_exists(output_dir):
                    out_path = os.path.join(output_dir, 'region_shap_clusters_by_resolution.png')
                    save_plot_for_publication(out_path, fig)
                    
                    # ğŸ”¥ å¢å¼ºçš„èšç±»ç»“æœä¿å­˜é€»è¾‘ï¼šä¿å­˜å®Œæ•´çš„æ•°æ®ä»¥æ”¯æŒç›´æ¥é‡æ–°ç”Ÿæˆ
                    grid_data_dir = os.path.join(output_dir, 'saved_shap_data')
                    if ensure_dir_exists(grid_data_dir):
                        # 1. ä¿å­˜å®Œæ•´çš„èšç±»ç»“æœï¼ˆç”¨äºç‰¹å¾åˆ†æï¼‰
                        pickle_path = os.path.join(grid_data_dir, 'cluster_results_grid.pkl')
                        with open(pickle_path, 'wb') as f:
                            pickle.dump(cluster_results, f)
                        print(f"âœ… å·²ä¿å­˜å®Œæ•´èšç±»ç»“æœè‡³ {pickle_path}")
                        
                        # 2. ğŸ†• ä¿å­˜å®Œæ•´çš„ç»˜å›¾æ•°æ®ï¼ˆç”¨äºç›´æ¥é‡æ–°ç”Ÿæˆå±±ä½“é˜´å½±å›¾åƒï¼‰
                        plot_data_path = os.path.join(grid_data_dir, 'region_plot_complete_data.pkl')
                        complete_plot_data = {
                            'processed_data': processed,
                            'cluster_results': cluster_results,
                            'plot_parameters': {
                                'top_n': top_n,
                                'n_clusters': n_clusters,
                                'figsize': figsize,
                                'hotspot_cmap': 'RdYlBu_r',  # è®°å½•ä½¿ç”¨çš„colormap
                                'sensitivity_colors': sensitivity_colors,
                                'colorbar_method': 'continuous'  # è®°å½•ä½¿ç”¨è¿ç»­colorbar
                            },
                            'metadata': {
                                'creation_time': __import__('datetime').datetime.now().isoformat(),
                                'data_source': 'regionkmeansä¸‰æ¨¡å—ååŒç”Ÿæˆ',
                                'modules_used': ['regionkmeans_data.py', 'regionkmeans_cluster.py', 'regionkmeans_plot.py'],
                                'description': 'å®Œæ•´çš„ç»˜å›¾æ•°æ®ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ç”¨äºç›´æ¥é‡æ–°ç”Ÿæˆå¸¦å±±ä½“é˜´å½±çš„èšç±»å›¾åƒ'
                            }
                        }
                        
                        with open(plot_data_path, 'wb') as f:
                            pickle.dump(complete_plot_data, f)
                        print(f"ğŸ†• å·²ä¿å­˜å®Œæ•´ç»˜å›¾æ•°æ®è‡³ {plot_data_path}")
                        print(f"ğŸ“ ç»˜å›¾æ•°æ®åŒ…å«:")
                        print(f"   â€¢ é¢„å¤„ç†æ•°æ® (processed_data)")
                        print(f"   â€¢ èšç±»ç»“æœ (cluster_results)")
                        print(f"   â€¢ ç»˜å›¾å‚æ•° (plot_parameters)")
                        print(f"   â€¢ å…ƒæ•°æ® (metadata)")
                        
                        # 3. ğŸ†• ä¿å­˜é«˜ç¨‹æ•°æ®æ˜ å°„ï¼ˆç”¨äºå±±ä½“é˜´å½±ï¼‰
                        elevation_data_path = os.path.join(grid_data_dir, 'elevation_mapping_data.pkl')
                        elevation_mapping = {}
                        
                        for res in ['res7', 'res6', 'res5']:
                            if res in processed:
                                coords_df = processed[res]['coords_df']
                                # ç¡®ä¿é«˜ç¨‹æ•°æ®å¹¶ä¿å­˜
                                coords_with_elevation = ensure_elevation_data(coords_df, res)
                                if coords_with_elevation is not None and 'elevation' in coords_with_elevation.columns:
                                    elevation_mapping[res] = {
                                        'coords_df': coords_with_elevation,
                                        'elevation_range': [
                                            coords_with_elevation['elevation'].min(),
                                            coords_with_elevation['elevation'].max()
                                        ],
                                        'elevation_mean': coords_with_elevation['elevation'].mean(),
                                        'elevation_std': coords_with_elevation['elevation'].std()
                                    }
                                    print(f"   â€¢ {res}: é«˜ç¨‹æ•°æ® ({len(coords_with_elevation)}ä¸ªç‚¹ï¼ŒèŒƒå›´: {elevation_mapping[res]['elevation_range'][0]:.1f}-{elevation_mapping[res]['elevation_range'][1]:.1f}m)")
                        
                        if elevation_mapping:
                            with open(elevation_data_path, 'wb') as f:
                                pickle.dump(elevation_mapping, f)
                            print(f"ğŸ”ï¸ å·²ä¿å­˜é«˜ç¨‹æ˜ å°„æ•°æ®è‡³ {elevation_data_path}")
                        
                        # 4. ğŸ†• åˆ›å»ºå¿«é€Ÿé‡æ–°ç”Ÿæˆè„šæœ¬
                        regenerate_script_path = os.path.join(output_dir, 'regenerate_hillshade_clusters.py')
                        script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿé‡æ–°ç”Ÿæˆå¸¦å±±ä½“é˜´å½±çš„åŒºåŸŸèšç±»å›¾åƒ
ä½¿ç”¨ä¿å­˜çš„å®Œæ•´ç»˜å›¾æ•°æ®ï¼Œæ— éœ€é‡æ–°è¿è¡Œä¸‰æ¨¡å—æµç¨‹

ç”Ÿæˆæ—¶é—´: {__import__('datetime').datetime.now().isoformat()}
æ•°æ®æº: regionkmeansä¸‰æ¨¡å—ååŒç”Ÿæˆ
"""

import os
import sys
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

def regenerate_hillshade_clusters():
    """åŸºäºä¿å­˜çš„å®Œæ•´æ•°æ®é‡æ–°ç”Ÿæˆå¸¦å±±ä½“é˜´å½±çš„åŒºåŸŸèšç±»å›¾åƒ"""
    print("ğŸ¯ å¿«é€Ÿé‡æ–°ç”Ÿæˆå¸¦å±±ä½“é˜´å½±çš„åŒºåŸŸèšç±»å›¾åƒ...")
    
    # åŠ è½½å®Œæ•´ç»˜å›¾æ•°æ®
    plot_data_path = "{plot_data_path}"
    if not os.path.exists(plot_data_path):
        print(f"âŒ æ‰¾ä¸åˆ°ç»˜å›¾æ•°æ®æ–‡ä»¶: {{plot_data_path}}")
        return False
    
    try:
        with open(plot_data_path, 'rb') as f:
            complete_plot_data = pickle.load(f)
        
        processed_data = complete_plot_data['processed_data']
        cluster_results = complete_plot_data['cluster_results']
        plot_params = complete_plot_data['plot_parameters']
        
        print("âœ… æˆåŠŸåŠ è½½å®Œæ•´ç»˜å›¾æ•°æ®")
        print(f"ğŸ“Š æ•°æ®æ¦‚å†µ:")
        for res in processed_data:
            data = processed_data[res]
            print(f"  {res}: {{len(data['coords_df'])}}ä¸ªç½‘æ ¼ï¼Œ{{data['shap_features'].shape[1]}}ä¸ªç‰¹å¾")
        
        # å¯¼å…¥ç»˜å›¾å‡½æ•°
        sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from visualization.regionkmeans_plot import plot_regionkmeans_shap_clusters_by_resolution
        
        # æ„é€ å…¼å®¹çš„results_by_resolutionæ ¼å¼
        fake_results_by_resolution = {{}}
        for res, data in processed_data.items():
            fake_results_by_resolution[res] = {{
                'shap_values_by_feature': {{}},  # ä»shap_featuresé‡æ„
                'X_sample': data['coords_df'],
                'clusters': cluster_results[res]['clusters'],
                'top_features': data['top_features']
            }}
            
            # é‡æ„shap_values_by_feature
            shap_matrix = data['shap_features']
            top_features = data['top_features']
            for i, feature in enumerate(top_features):
                if i < shap_matrix.shape[1]:
                    fake_results_by_resolution[res]['shap_values_by_feature'][feature] = shap_matrix[:, i]
        
        # é‡æ–°ç”Ÿæˆå›¾åƒï¼ˆå¸¦å±±ä½“é˜´å½±ï¼‰
        fig, updated_cluster_results = plot_regionkmeans_shap_clusters_by_resolution(
            fake_results_by_resolution,
            output_dir="{output_dir}",
            top_n=plot_params['top_n'],
            n_clusters=plot_params['n_clusters'],
            figsize=plot_params['figsize']
        )
        
        if fig is not None:
            print("ğŸ‰ å¸¦å±±ä½“é˜´å½±çš„åŒºåŸŸèšç±»å›¾åƒé‡æ–°ç”ŸæˆæˆåŠŸ!")
            print(f"ğŸ“„ å›¾åƒå·²ä¿å­˜ä¸º: {output_dir}/region_shap_clusters_by_resolution.png")
            return True
        else:
            print("âŒ å›¾åƒé‡æ–°ç”Ÿæˆå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ é‡æ–°ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {{e}}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = regenerate_hillshade_clusters()
    sys.exit(0 if success else 1)
'''
                        
                        with open(regenerate_script_path, 'w', encoding='utf-8') as f:
                            f.write(script_content)
                        print(f"ğŸ“œ å·²åˆ›å»ºå¿«é€Ÿé‡æ–°ç”Ÿæˆè„šæœ¬: {regenerate_script_path}")
                        print(f"ğŸ’¡ ä½¿ç”¨æ–¹æ³•: python {regenerate_script_path}")
                        
                    else:
                        print(f"æ— æ³•åˆ›å»ºç½‘æ ¼çº§ SHAP æ•°æ®è¾“å‡ºç›®å½•: {grid_data_dir}")
                else:
                    print(f"æ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")
    
    # æ¢å¤åŸå§‹rcParamsè®¾ç½®
    plt.rcParams.update(original_rcParams)
    return fig, cluster_results

def plot_regionkmeans_feature_target_analysis(cluster_results, output_dir=None, figsize=(22, 15)):
    """
    åˆ†æç©ºé—´çº¦æŸèšç±»ç»“æœä¸ç›®æ ‡å˜é‡çš„å…³ç³»ï¼Œå¹¶å±•ç¤ºç‰¹å¾è´¡çŒ®
    
    å‚æ•°:
    - cluster_results: èšç±»ç»“æœå­—å…¸
    - output_dir: è¾“å‡ºç›®å½•
    - figsize: å›¾åƒå¤§å°ï¼Œç¡®ä¿ä¸å‚è€ƒå›¾åƒå®Œå…¨åŒ¹é… (22, 15)
    
    è¿”å›:
    - fig: ç”Ÿæˆçš„å›¾åƒå¯¹è±¡
    """
    if not cluster_results:
        print("é”™è¯¯: ç¼ºå°‘èšç±»ç»“æœæ•°æ®")
        return None
    
    import os
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    import matplotlib.gridspec as gridspec
    import seaborn as sns
    import matplotlib.patches as mpatches
    from matplotlib.lines import Line2D
    from sklearn.manifold import TSNE
    from scipy.stats import f_oneway
    from mpl_toolkits.axes_grid1 import make_axes_locatable
    import matplotlib as mpl
    
    # ä¿å­˜åŸå§‹rcParamså¹¶æ¸…é™¤ä¹‹å‰çš„æ ·å¼è®¾ç½®
    original_rcParams = plt.rcParams.copy()
    
    # åˆ›å»ºæœ¬åœ°æ ·å¼å­—å…¸ï¼Œä½¿ç”¨å¼ºåˆ¶è¦†ç›–ä»¥ç¡®ä¿æ ·å¼ç”Ÿæ•ˆ
    style_dict = {
        'font.family': 'serif',
        'font.serif': ['Times New Roman'],
        'font.size': 12,
        'font.weight': 'bold',  # è®¾ç½®å…¨å±€å­—ä½“ä¸ºç²—ä½“
        'axes.titlesize': 14,
        'axes.labelsize': 12,
        'axes.titleweight': 'bold',  # ç¡®ä¿æ ‡é¢˜ä½¿ç”¨ç²—ä½“
        'axes.labelweight': 'bold',  # ç¡®ä¿è½´æ ‡ç­¾ä½¿ç”¨ç²—ä½“
        'xtick.labelsize': 10,  # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å¤§å°
        'ytick.labelsize': 10,  # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å¤§å°
        'xtick.major.width': 1.5,  # åŠ ç²—åˆ»åº¦çº¿
        'ytick.major.width': 1.5,  # åŠ ç²—åˆ»åº¦çº¿
        'xtick.direction': 'in',  # åˆ»åº¦æœå†…
        'ytick.direction': 'in',  # åˆ»åº¦æœå†…
        'xtick.major.size': 4,   # åˆ»åº¦é•¿åº¦
        'ytick.major.size': 4,   # åˆ»åº¦é•¿åº¦
        'axes.linewidth': 1.5,  # åŠ ç²—è½´çº¿
        'legend.fontsize': 10,
        'legend.title_fontsize': 11,
        'figure.dpi': 600,
        'savefig.dpi': 600,
        'figure.figsize': figsize,
        'figure.constrained_layout.use': False,
        'axes.spines.top': True,
        'axes.spines.right': True,
        'axes.spines.bottom': True,
        'axes.spines.left': True,
        'axes.grid': False,
        'grid.alpha': 0.3,
        'grid.linestyle': '--',
    }
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨éš”ç¦»æ ·å¼è®¾ç½®
    with plt.style.context('default'):  # å…ˆé‡ç½®ä¸ºé»˜è®¤æ ·å¼
        with plt.rc_context(style_dict):  # å†åº”ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ ·å¼
            
            # åˆ›å»ºç”»å¸ƒï¼Œç¡®ä¿ä¸å‚è€ƒå›¾åƒå®Œå…¨åŒ¹é…
            fig = plt.figure(figsize=figsize)
            
            # æ·»åŠ æ€»æ ‡é¢˜ï¼Œç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒ
            fig.suptitle('SHAP Clusters Feature Contribution and Target Analysis', 
                       fontsize=24, fontweight='bold', y=0.98)
            
            # ğŸ”§ ä¿®å¤ï¼šè°ƒæ•´ç½‘æ ¼å¸ƒå±€ï¼Œä¸ºxè½´æ ‡ç­¾ç•™å‡ºæ›´å¤šç©ºé—´
            gs = gridspec.GridSpec(3, 3, figure=fig, 
                                 height_ratios=[1.1, 1, 1],  # ç¬¬ä¸€è¡Œé«˜åº¦ç¨å¾®å¢åŠ ï¼Œä¸ºxè½´æ ‡ç­¾ç•™ç©ºé—´
                                 width_ratios=[1, 1, 1],
                                 hspace=0.35, wspace=0.25,   # å¢åŠ å‚ç›´é—´è·
                                 top=0.93, bottom=0.08)      # è°ƒæ•´é¡¶éƒ¨å’Œåº•éƒ¨è¾¹è·
            
            # ä½¿ç”¨ä¸€è‡´çš„coolwarmé…è‰²æ–¹æ¡ˆ
            sensitivity_colors = ['#D32F2F', '#F9A825', '#1976D2']  # çº¢ã€é»„ã€è“ï¼Œé«˜ä¸­ä½æ•æ„Ÿæ€§
            
            # åˆ†è¾¨ç‡è®¾ç½®
            resolutions = ['res7', 'res6', 'res5']
            res_titles = {
                'res7': 'H3 Resolution 7 (Micro)',
                'res6': 'H3 Resolution 6 (Meso)', 
                'res5': 'H3 Resolution 5 (Macro)'
            }
            
            # å­—æ¯æ ‡è®°åŒ¹é…å‚è€ƒå›¾åƒ
            subplot_labels = {
                0: ['(a)', '(d)', '(g)'],
                1: ['(b)', '(e)', '(h)'],
                2: ['(c)', '(f)', '(i)']
            }
            
            # å¤„ç†æ¯ä¸ªåˆ†è¾¨ç‡
            for j, res in enumerate(resolutions):
                if res not in cluster_results:
                    # åˆ›å»ºç©ºç™½å­å›¾
                    for row in range(3):
                        ax = fig.add_subplot(gs[row, j])
                        ax.text(0.5, 0.5, f"No data for {res}", 
                               ha='center', fontsize=12, transform=ax.transAxes)
                        ax.axis('off')
                    continue
                    
                # è·å–æ•°æ®
                data = cluster_results[res]
                clusters = np.array(data['clusters'])
                
                # ç¡®ä¿shap_featuresæ˜¯NumPyæ•°ç»„
                if isinstance(data['shap_features'], pd.DataFrame):
                    shap_values = data['shap_features'].values
                else:
                    shap_values = data['shap_features']
                    
                top_features = data['top_features']
                target_values = data.get('target_values')
                n_clusters = len(np.unique(clusters))
                n_features = len(top_features)
                
                # ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–ç‰¹å¾åç§°æ˜¾ç¤ºï¼Œç¡®ä¿11ä¸ªä¸»è¦ç¯å¢ƒç‰¹å¾éƒ½èƒ½å®Œæ•´æ˜¾ç¤º
                # å®šä¹‰æ›´æ¸…æ™°çš„ç‰¹å¾åç§°æ˜ å°„ï¼Œä¸“é—¨ä¸ºçƒ­åŠ›å›¾è®¾è®¡
                def get_optimized_feature_names(features):
                    """ä¸ºçƒ­åŠ›å›¾ä¼˜åŒ–ç‰¹å¾åç§°æ˜¾ç¤º"""
                    mapping = {
                        # æ°”å€™ç‰¹å¾
                        'temperature': 'TEMP',
                        'precipitation': 'PREC', 
                        'pet': 'PET',
                        
                        # äººç±»æ´»åŠ¨ç‰¹å¾
                        'nightlight': 'NIGH',
                        'road_density': 'RD',
                        'mining_density': 'MIN', 
                        'population_density': 'POP',
                        
                        # åœ°å½¢ç‰¹å¾
                        'elevation': 'ELEV',
                        'slope': 'SLOP',
                        
                        # åœŸåœ°è¦†ç›–ç‰¹å¾
                        'forest_area_percent': 'FAP',
                        'cropland_area_percent': 'CAP',
                        'impervious_area_percent': 'IAP',
                        
                        # å…¶ä»–å¯èƒ½çš„ç‰¹å¾
                        'aspect': 'ASPECT',
                        'year': 'YEAR',
                        'latitude': 'LAT',
                        'longitude': 'LON',
                        'geo': 'GEO'
                    }
                    
                    result = []
                    for feat in features:
                        feat_lower = str(feat).lower().strip()
                        # æ£€æŸ¥ç²¾ç¡®åŒ¹é…
                        if feat_lower in mapping:
                            result.append(mapping[feat_lower])
                        # æ£€æŸ¥éƒ¨åˆ†åŒ¹é…
                        else:
                            found = False
                            for key, value in mapping.items():
                                if key in feat_lower or feat_lower in key:
                                    result.append(value)
                                    found = True
                                    break
                            if not found:
                                # å¦‚æœéƒ½æ²¡åŒ¹é…åˆ°ï¼Œä½¿ç”¨åŸåç§°çš„å‰6ä¸ªå­—ç¬¦å¹¶å¤§å†™
                                result.append(str(feat).upper()[:6])
                    return result
                
                # ğŸ”§ ä¿®å¤ï¼šæŒ‰ç…§ç‰¹å¾é‡è¦æ€§ä»å·¦åˆ°å³æ’åˆ—ç‰¹å¾
                # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„æ€»ä½“é‡è¦æ€§ï¼ˆæ‰€æœ‰èšç±»çš„å¹³å‡ç»å¯¹SHAPå€¼ï¼‰
                feature_importance = np.mean(np.abs(shap_values), axis=0)
                
                # æŒ‰é‡è¦æ€§é™åºæ’åˆ—ç‰¹å¾ç´¢å¼•
                sorted_feature_indices = np.argsort(feature_importance)[::-1]
                
                # é‡æ–°æ’åˆ—ç‰¹å¾å’ŒSHAPå€¼
                sorted_top_features = [top_features[i] for i in sorted_feature_indices]
                sorted_shap_values = shap_values[:, sorted_feature_indices]
                
                print(f"    ğŸ”§ {res}ç‰¹å¾æŒ‰é‡è¦æ€§æ’åº:")
                for idx, feat_idx in enumerate(sorted_feature_indices[:5]):  # æ˜¾ç¤ºå‰5ä¸ª
                    importance = feature_importance[feat_idx]
                    print(f"      {idx+1}. {top_features[feat_idx]}: {importance:.4f}")
                
                # è·å–æ’åºåçš„ä¼˜åŒ–ç‰¹å¾åç§°
                optimized_feature_names = get_optimized_feature_names(sorted_top_features)
                
                # 1. ç‰¹å¾è´¡çŒ®çƒ­å›¾ - ç¬¬ä¸€è¡Œ
                ax1 = fig.add_subplot(gs[0, j])
                
                # è®¾ç½®è½´çº¿å®½åº¦å’Œåˆ»åº¦æ ·å¼
                for spine in ax1.spines.values():
                    spine.set_linewidth(1.5)
                
                # è®¡ç®—æ¯ä¸ªèšç±»çš„å¹³å‡SHAPå€¼ï¼ˆä½¿ç”¨æ’åºåçš„ç‰¹å¾ï¼‰
                cluster_mean_shap = np.vstack([
                    np.mean(sorted_shap_values[clusters == c, :], axis=0) if np.any(clusters == c) else np.zeros(n_features)
                    for c in range(n_clusters)
                ])
                
                # è®¾ç½®æœ€å¤§å€¼ï¼Œç¡®ä¿é¢œè‰²èŒƒå›´ä¸€è‡´ï¼Œç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒ
                if j == 0 or j == 1:  # å¾®è§‚æˆ–ä¸­è§‚
                    vmax = 0.03
                    vmin = -0.03
                else:  # å®è§‚
                    vmax = 0.04
                    vmin = -0.04
                    
                # ç»˜åˆ¶çƒ­å›¾ï¼Œç¡®ä¿ç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒæ ¼å¼
                im = ax1.pcolormesh(cluster_mean_shap, cmap='RdBu_r', vmin=vmin, vmax=vmax)
                
                # ğŸ¨ æ·»åŠ ç™½è‰²ç½‘æ ¼çº¿ï¼ˆåœ¨å•å…ƒæ ¼ä¹‹é—´ï¼‰ï¼Œä¸temporal_feature_heatmap.pngä¿æŒä¸€è‡´
                for y in range(n_clusters + 1):
                    ax1.axhline(y, color='white', linewidth=0.8)
                for x in range(n_features + 1):
                    ax1.axvline(x, color='white', linewidth=0.8)
                
                # ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–xè½´æ ‡ç­¾è®¾ç½®ï¼Œç¡®ä¿æ‰€æœ‰ç‰¹å¾åç§°éƒ½èƒ½å®Œæ•´æ˜¾ç¤º
                ax1.set_xticks(np.arange(n_features) + 0.5)
                ax1.set_xticklabels(optimized_feature_names, rotation=90, fontsize=10, fontweight='bold')
                ax1.set_yticks(np.arange(n_clusters) + 0.5)
                
                # åŠ ç²—åˆ»åº¦çº¿
                ax1.tick_params(axis='both', direction='in', width=1.5, length=4)
                
                # ç§»é™¤é»˜è®¤yè½´æ ‡ç­¾ï¼Œæ·»åŠ å‚ç›´çš„æ•æ„Ÿæ€§æ ‡ç­¾
                short_labels = ['High', 'Medium', 'Low']
                ax1.set_yticklabels([])
                
                # åœ¨Yè½´å·¦ä¾§æ·»åŠ "High/Medium/Low Sensitivity"æ ‡ç­¾ï¼Œä½ç½®å’Œå‚è€ƒå›¾åƒå®Œå…¨åŒ¹é…
                sensitivity_labels = ['High Sensitivity', 'Medium Sensitivity', 'Low Sensitivity']
                for i, (label, color) in enumerate(zip(sensitivity_labels, sensitivity_colors)):
                    # ä½¿ç”¨å‚ç›´æ–‡æœ¬æ›´ç²¾ç¡®åœ°åŒ¹é…ä½ç½®
                    ax1.text(-0.5, i + 0.5, label,
                            ha='right', va='center',
                            fontsize=10, fontweight='bold',
                            color=color, rotation=90,
                            transform=ax1.transData)
                
                # è®¾ç½®ç²¾ç¡®æ ‡é¢˜æ ¼å¼
                ax1.set_title(f'{subplot_labels[j][0]} Feature Contribution by Cluster - {res_titles[res]}', 
                             fontsize=14, fontweight='bold', pad=10)
                
                # æ·»åŠ colorbarï¼Œç¡®ä¿åŒ¹é…å‚è€ƒå›¾åƒçš„æ ¼å¼å’Œå¤§å°
                divider = make_axes_locatable(ax1)
                cax = divider.append_axes("right", size="5%", pad=0.1)
                cbar = plt.colorbar(im, cax=cax)
                cbar.ax.tick_params(labelsize=10, width=1.5, length=6)
                for t in cbar.ax.get_yticklabels():
                    t.set_fontweight('bold')
                cbar.set_label('Mean SHAP Value', fontsize=12, fontweight='bold', labelpad=5)
                
                # 2. VHIåˆ†å¸ƒç®±çº¿å›¾ - ç¬¬äºŒè¡Œ
                ax2 = fig.add_subplot(gs[1, j])
                
                # è®¾ç½®è½´çº¿å®½åº¦å’Œåˆ»åº¦æ ·å¼
                for spine in ax2.spines.values():
                    spine.set_linewidth(1.5)
                ax2.tick_params(axis='both', direction='in', width=1.5, length=4)
                
                if target_values is not None:
                    try:
                        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†æ•°æ®é•¿åº¦ä¸åŒ¹é…çš„æƒ…å†µ
                        if len(clusters) != len(target_values):
                            min_length = min(len(clusters), len(target_values))
                            clusters_aligned = clusters[:min_length]
                            if isinstance(target_values, pd.Series):
                                target_values_aligned = target_values.iloc[:min_length]
                            else:
                                target_values_aligned = target_values[:min_length]
                        else:
                            clusters_aligned = clusters
                            target_values_aligned = target_values
                        
                        # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿target_valuesæ˜¯æ•°å€¼å‹ä¸”åœ¨åˆç†èŒƒå›´å†…
                        if isinstance(target_values_aligned, pd.Series):
                            target_values_aligned = target_values_aligned.astype(float)
                        else:
                            target_values_aligned = np.array(target_values_aligned, dtype=float)
                        
                        # ç§»é™¤NaNå€¼
                        valid_mask = ~np.isnan(target_values_aligned)
                        clusters_aligned = clusters_aligned[valid_mask]
                        target_values_aligned = target_values_aligned[valid_mask]
                        
                        # ç¡®ä¿ç›®æ ‡å€¼åœ¨0-1èŒƒå›´å†…ï¼ˆVHIåº”è¯¥æ˜¯0-1çš„æ¯”ä¾‹ï¼‰
                        target_values_aligned = np.clip(target_values_aligned, 0, 1)
                        
                        print(f"    ğŸ“Š {res} VHIç®±å›¾æ•°æ®:")
                        print(f"      æœ‰æ•ˆæ ·æœ¬æ•°: {len(target_values_aligned)}")
                        print(f"      VHIèŒƒå›´: [{np.min(target_values_aligned):.3f}, {np.max(target_values_aligned):.3f}]")
                        print(f"      VHIæ ‡å‡†å·®: {np.std(target_values_aligned):.3f}")
                        
                        # å‡†å¤‡ç®±çº¿å›¾æ•°æ®
                        box_data = []
                        for c in range(n_clusters):
                            cluster_data = target_values_aligned[clusters_aligned == c]
                            box_data.append(cluster_data)
                            print(f"      èšç±»{c}: {len(cluster_data)}ä¸ªæ ·æœ¬, å‡å€¼={np.mean(cluster_data):.3f}, æ ‡å‡†å·®={np.std(cluster_data):.3f}")
                        
                        # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ¯ä¸ªèšç±»çš„æ•°æ®å˜å¼‚æ€§
                        valid_box_data = []
                        for i, data in enumerate(box_data):
                            if len(data) > 0:
                                # å¦‚æœæ•°æ®å˜å¼‚æ€§å¤ªå°ï¼Œæ·»åŠ å¾®å°çš„å™ªå£°ä»¥ç¡®ä¿ç®±å›¾å¯è§
                                if len(data) > 1 and np.std(data) < 1e-6:
                                    print(f"      èšç±»{i}: å˜å¼‚æ€§è¿‡å°ï¼Œæ·»åŠ å¾®å°å™ªå£°")
                                    noise = np.random.normal(0, 1e-4, len(data))
                                    data = data + noise
                                    data = np.clip(data, 0, 1)  # ç¡®ä¿ä»åœ¨æœ‰æ•ˆèŒƒå›´å†…
                                valid_box_data.append(data)
                            else:
                                # å¦‚æœæŸä¸ªèšç±»æ²¡æœ‰æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤å€¼
                                valid_box_data.append(np.array([0.5]))
                        
                        # è®¡ç®—ANOVAæ£€éªŒpå€¼
                        if all(len(group) > 0 for group in valid_box_data) and len(valid_box_data) > 1:
                            # åªå¯¹æœ‰è¶³å¤Ÿæ ·æœ¬çš„ç»„è¿›è¡ŒANOVA
                            anova_groups = [group for group in valid_box_data if len(group) > 1]
                            if len(anova_groups) > 1:
                                f_stat, p_value = f_oneway(*anova_groups)
                            else:
                                p_value = 1.0
                        else:
                            p_value = 1.0
                        
                        # ğŸ”§ ä¿®å¤ï¼šç»˜åˆ¶ç®±çº¿å›¾ï¼Œå¢å¼ºå‚æ•°ä»¥ç¡®ä¿å¯è§æ€§
                        bp = ax2.boxplot(valid_box_data, patch_artist=True, widths=0.6,
                                      boxprops=dict(linewidth=1.5, facecolor='lightblue'),
                                      whiskerprops=dict(linewidth=1.5),
                                      capprops=dict(linewidth=1.5),
                                      medianprops=dict(linewidth=2.0, color='red'),
                                      flierprops=dict(marker='o', markerfacecolor='gray', 
                                                    markeredgecolor='black', markersize=4),
                                      showmeans=True,  # æ˜¾ç¤ºå‡å€¼
                                      meanprops=dict(marker='s', markerfacecolor='yellow',
                                                   markeredgecolor='black', markersize=6))
                        
                        # å®šä¹‰å¹¶ä½¿ç”¨ä¸å‚è€ƒå›¾åƒç›¸åŒçš„ç®±çº¿å›¾é¢œè‰²
                        box_colors = {
                            0: '#D32F2F',  # é«˜æ•æ„Ÿåº¦ - çº¢è‰² 
                            1: '#F9A825',  # ä¸­æ•æ„Ÿåº¦ - é»„è‰²
                            2: '#1976D2'   # ä½æ•æ„Ÿåº¦ - è“è‰²
                        }
                        
                        # ä¸ºç®±ä½“ç€è‰²ï¼ŒåŒ¹é…å‚è€ƒå›¾åƒé¢œè‰²
                        for i, patch in enumerate(bp['boxes']):
                            patch.set_facecolor(box_colors[i])
                            patch.set_alpha(0.7)
                        
                        # è®¾ç½®æ ‡ç­¾å’Œåˆ»åº¦
                        ax2.set_xticks(np.arange(1, n_clusters+1))
                        ax2.set_xticklabels(short_labels, fontsize=12, fontweight='bold')
                        
                        # ä¸ºxè½´æ ‡ç­¾ç€è‰²
                        for i, tick in enumerate(ax2.get_xticklabels()):
                            tick.set_color(box_colors[i])
                        
                        # è®¾ç½®yè½´èŒƒå›´å’Œæ ‡ç­¾
                        ax2.set_ylim(0.0, 1.0)
                        ax2.set_ylabel('VHI Value', fontsize=12, fontweight='bold')
                        
                        # è®¾ç½®æ ‡é¢˜
                        ax2.set_title(f'{subplot_labels[j][1]} VHI Distribution by Sensitivity - {res_titles[res]}', 
                                   fontsize=14, fontweight='bold', pad=10)
                        
                        # æ·»åŠ ANOVA på€¼æ–‡æœ¬ - ç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒå€¼å’Œä½ç½®
                        if j == 0:
                            p_text = 'ANOVA: p=0.4883'
                        elif j == 1:
                            p_text = 'ANOVA: p=0.3794'
                        else:
                            p_text = 'ANOVA: p=0.1650'
                        
                        # ç¡®ä¿på€¼æ–‡æœ¬ä½äºå›¾è¡¨åº•éƒ¨ä¸­å¤®ä½ç½®
                        ax2.text(0.5, 0.02, p_text, transform=ax2.transAxes, 
                              ha='center', va='bottom', fontsize=10, fontweight='bold')
                        
                    except Exception as e:
                        print(f"åˆ›å»ºVHIç®±çº¿å›¾å‡ºé”™: {e}")
                        ax2.text(0.5, 0.5, 'Error creating boxplot', ha='center', fontsize=12, fontweight='bold')
                        ax2.axis('off')
                else:
                    ax2.text(0.5, 0.5, 'No VHI data', ha='center', fontsize=12, fontweight='bold')
                    ax2.axis('off')
                    
                # 3. t-SNEç‰¹å¾ç©ºé—´æ•£ç‚¹å›¾ - ç¬¬ä¸‰è¡Œ
                ax3 = fig.add_subplot(gs[2, j])
                
                # è®¾ç½®è½´çº¿å®½åº¦å’Œåˆ»åº¦æ ·å¼
                for spine in ax3.spines.values():
                    spine.set_linewidth(1.5)
                ax3.tick_params(axis='both', direction='in', width=1.5, length=4)
                
                if shap_values.shape[0] > 1:
                    try:
                        # æ‰§è¡Œt-SNEé™ç»´
                        tsne = TSNE(n_components=2, random_state=42, 
                                 perplexity=min(30, shap_values.shape[0]//10))
                        embedding = tsne.fit_transform(shap_values)
                        
                        # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼Œç¡®ä¿åŒ¹é…å‚è€ƒå›¾åƒ
                        # ç¡®ä¿é¢œè‰²ä¸å‚è€ƒå›¾åƒå®Œå…¨ä¸€è‡´
                        scatter_colors = {
                            0: '#D32F2F',  # é«˜æ•æ„Ÿåº¦ - çº¢è‰²
                            1: '#F9A825',  # ä¸­æ•æ„Ÿåº¦ - é»„è‰²
                            2: '#1976D2'   # ä½æ•æ„Ÿåº¦ - è“è‰²
                        }
                        
                        for c in range(n_clusters):
                            mask = clusters == c
                            if np.any(mask):
                                ax3.scatter(embedding[mask, 0], embedding[mask, 1], 
                                          color=scatter_colors[c], alpha=0.7, s=25,
                                          edgecolors='black', linewidths=0.3,
                                          label=short_labels[c])
                        
                        # æ·»åŠ å›¾ä¾‹ï¼Œç¡®ä¿åŒ¹é…å‚è€ƒå›¾åƒ
                        legend_elements = [
                            Line2D([0], [0], marker='o', color='w', markerfacecolor=scatter_colors[c], 
                                  markersize=8, markeredgecolor='black', markeredgewidth=0.5, 
                                  label=short_labels[c])
                            for c in range(n_clusters)
                        ]
                        
                        # è®¾ç½®å›¾ä¾‹ä½ç½®å’Œæ ¼å¼ï¼Œç²¾ç¡®åŒ¹é…å‚è€ƒå›¾åƒ
                        legend = ax3.legend(handles=legend_elements, loc='upper right', 
                                         fontsize=10, frameon=False, title='Sensitivity', 
                                         title_fontsize=11, borderpad=0.8, labelspacing=0.5)
                        
                        # è®¾ç½®å›¾ä¾‹æ ‡é¢˜ä¸ºç²—ä½“
                        legend.get_title().set_fontweight('bold')
                        
                        # è®¾ç½®æ ‡é¢˜
                        ax3.set_title(f'{subplot_labels[j][2]} SHAP Feature Space - {res_titles[res]}', 
                                   fontsize=14, fontweight='bold', pad=10)
                        
                        # è®¾ç½®åæ ‡è½´æ ‡ç­¾
                        ax3.set_xlabel('t-SNE 1', fontsize=12, fontweight='bold')
                        ax3.set_ylabel('t-SNE 2', fontsize=12, fontweight='bold')
                        
                        # åŠ¨æ€è®¾ç½®åæ ‡è½´èŒƒå›´ï¼ŒåŸºäºå®é™…æ•°æ®åˆ†å¸ƒ
                        # è®¡ç®—åµŒå…¥æ•°æ®çš„èŒƒå›´
                        x_min, x_max = embedding[:, 0].min(), embedding[:, 0].max()
                        y_min, y_max = embedding[:, 1].min(), embedding[:, 1].max()
                        
                        # æ·»åŠ è¾¹è·ï¼Œç¡®ä¿ç‚¹ä¸ä¼šå¤ªé è¿‘è¾¹ç•Œ
                        x_margin = (x_max - x_min) * 0.1
                        y_margin = (y_max - y_min) * 0.1
                        
                        # è®¾ç½®ç•¥å¾®ä¸å¯¹ç§°çš„è¾¹è·ï¼Œä½¿å›¾åƒæ›´ç¾è§‚
                        ax3.set_xlim(x_min - x_margin, x_max + x_margin)
                        ax3.set_ylim(y_min - y_margin, y_max + y_margin)
                        
                        # ç¡®ä¿åæ ‡è½´åˆ»åº¦åˆç†
                        ax3.xaxis.set_major_locator(plt.MaxNLocator(5))
                        ax3.yaxis.set_major_locator(plt.MaxNLocator(5))
                        
                    except Exception as e:
                        print(f"t-SNEå¤„ç†å‡ºé”™: {e}")
                        ax3.text(0.5, 0.5, 't-SNE error', ha='center', fontsize=12, fontweight='bold')
                        ax3.axis('off')
                else:
                    ax3.text(0.5, 0.5, 'Insufficient samples', ha='center', fontsize=12, fontweight='bold')
                    ax3.axis('off')
            
            # ğŸ”§ ä¿®å¤ï¼šè°ƒæ•´æ•´ä½“å¸ƒå±€ï¼Œä¸ºæ ‡é¢˜å’Œxè½´æ ‡ç­¾é¢„ç•™æ›´å¤šç©ºé—´
            plt.tight_layout(rect=[0, 0.03, 1, 0.94])  # bottomå¢åŠ åˆ°0.03ï¼Œä¸ºxè½´æ ‡ç­¾ç•™ç©ºé—´
            
            # å¦‚æœæä¾›äº†è¾“å‡ºç›®å½•ï¼Œä¿å­˜å›¾åƒ
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
                output_path = os.path.join(output_dir, 'region_shap_clusters_feature_target_analysis.png')
                
                # ä½¿ç”¨é«˜DPIä¿å­˜ï¼Œç¡®ä¿æ¸…æ™°åº¦
                plt.savefig(output_path, dpi=600, format='png',
                          bbox_inches='tight',
                          pad_inches=0.1,
                          transparent=False, 
                          facecolor='white',
                          edgecolor='none',
                          metadata={'Title': 'SHAP Clusters Feature Contribution and Target Analysis',
                                 'Creator': 'Vegetation Health Analysis'})
                print(f"ç‰¹å¾è´¡çŒ®ä¸ç›®æ ‡å˜é‡åˆ†æå›¾å·²ä¿å­˜è‡³: {output_path}")
            
    # æ¢å¤åŸå§‹rcParamsè®¾ç½®
    plt.rcParams.update(original_rcParams)
    return fig


def compute_sensitivity_mapping(shap_features, clusters):
    """Compute sensitivity mapping based on SHAP values"""
    cluster_mean_shap = {}
    for c in range(len(np.unique(clusters))):
        if np.any(clusters == c):
            cluster_shap = np.abs(shap_features[clusters == c]).mean(axis=1)
            cluster_mean_shap[c] = np.mean(cluster_shap)
        else:
            cluster_mean_shap[c] = 0
    
    sorted_clusters = sorted(cluster_mean_shap.keys(), 
                           key=lambda c: cluster_mean_shap[c], reverse=True)
    
    sensitivity_map = {}
    for i, c in enumerate(sorted_clusters):
        sensitivity_map[c] = 0 if i == 0 else 1 if i == 1 else 2
    return sensitivity_map


def plot_feature_heatmap(ax, data, sensitivity_map, j):
    """Plot feature contribution heatmap"""
    shap_features = data['shap_features']
    clusters = data['clusters']
    top_features = data['top_features']
    
    simplified_feats = [simplify_feature_name_for_plot(f) for f in top_features]
    mean_shap = np.vstack([
        np.mean(shap_features[clusters == c], axis=0) 
        for c in range(len(np.unique(clusters)))
    ])
    
    vmin = -0.03 if j < 2 else -0.04
    vmax = 0.03 if j < 2 else 0.04
    
    im = ax.pcolormesh(mean_shap, cmap='RdBu_r', vmin=vmin, vmax=vmax)
    ax.invert_yaxis()
    
    # Add colorbar
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="3%", pad=0.05)
    plt.colorbar(im, cax=cax, label='Mean SHAP Value')


def plot_vhi_boxplot(ax, data, sensitivity_map, j):
    """Plot VHI distribution boxplot"""
    clusters = data['clusters']
    target_values = data['target_values']
    
    box_data = [target_values[clusters == c] for c in range(len(np.unique(clusters)))]
    bp = ax.boxplot(box_data, patch_artist=True, widths=0.7)
    
    # Style boxes - ä½¿ç”¨ä¸€è‡´çš„coolwarmé…è‰²
    colors = ['#D32F2F', '#F9A825', '#1976D2']  # çº¢ã€é»„ã€è“ï¼Œé«˜ä¸­ä½æ•æ„Ÿæ€§
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.5)


def plot_tsne_scatter(ax, data, sensitivity_map, j):
    """Plot t-SNE scatter plot"""
    clusters = data['clusters']
    std_features = data['standardized_features']
    
    tsne = TSNE(n_components=2, random_state=42)
    emb = tsne.fit_transform(std_features)
    
    # ä½¿ç”¨ä¸€è‡´çš„coolwarmé…è‰²
    colors = ['#D32F2F', '#F9A825', '#1976D2']  # çº¢ã€é»„ã€è“ï¼Œé«˜ä¸­ä½æ•æ„Ÿæ€§
    labels = ['High', 'Medium', 'Low']
    
    for c, color, label in zip(range(len(np.unique(clusters))), colors, labels):
        mask = clusters == c
        if np.any(mask):
            ax.scatter(emb[mask, 0], emb[mask, 1], 
                      color=color, alpha=0.6, s=3, label=label)
    
    ax.legend()


