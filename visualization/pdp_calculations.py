#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
PDPè®¡ç®—å’ŒSHAPä¾èµ–å›¾æ¨¡å—

ä»pdp_plots.pyé‡æ„è€Œæ¥ï¼Œä¸“æ³¨äºï¼š
- æ ‡å‡†PDPè®¡ç®—åŠŸèƒ½
- ç‰¹å¾PDPè®¡ç®—åŒ…è£…å‡½æ•°
- SHAPä¾èµ–å›¾ç½‘æ ¼ç»˜åˆ¶

é€‚é…ST-GPRæ¨¡å‹çš„ç‰¹æ®Šéœ€æ±‚
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from matplotlib.gridspec import GridSpec
from typing import Dict, List, Optional, Tuple, Union
import seaborn as sns

# å¯¼å…¥é€šç”¨çš„ç»˜å›¾å‡½æ•°å’Œå·¥å…·
try:
    from .base import enhance_plot_style, ensure_dir_exists, save_plot_for_publication, color_map
    from .utils import clean_feature_name_for_plot, categorize_feature, simplify_feature_name_for_plot, enhance_feature_display_name, clean_feature_name, format_pdp_feature_name
    from model_analysis.core import standardize_feature_name
except ImportError:
    # ç›¸å¯¹å¯¼å…¥å¤±è´¥æ—¶å°è¯•ç»å¯¹å¯¼å…¥
    from visualization.base import enhance_plot_style, ensure_dir_exists, save_plot_for_publication, color_map
    from visualization.utils import clean_feature_name_for_plot, categorize_feature, simplify_feature_name_for_plot, enhance_feature_display_name, clean_feature_name, format_pdp_feature_name
    from model_analysis.core import standardize_feature_name

# è®¾ç½®matplotlibé»˜è®¤å­—ä½“ä»¥æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False


def calculate_standard_pdp(model, likelihood, X_sample, feature_name, n_points=50):
    """
    è®¡ç®—æ ‡å‡†çš„éƒ¨åˆ†ä¾èµ–å›¾(PDP)
    
    PDPç®—æ³•ï¼š
    1. é€‰æ‹©ç›®æ ‡ç‰¹å¾
    2. åˆ›å»ºç‰¹å¾å€¼ç½‘æ ¼
    3. å¯¹æ¯ä¸ªç½‘æ ¼å€¼ï¼šå›ºå®šå…¶ä»–ç‰¹å¾ä¸ºå¹³å‡å€¼ï¼Œç”¨æ¨¡å‹é¢„æµ‹
    4. è¿”å›ï¼šç‰¹å¾å€¼ vs å¹³å‡é¢„æµ‹å€¼
    
    å‚æ•°:
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    likelihood: æ¨¡å‹çš„ä¼¼ç„¶å‡½æ•°ï¼ˆç”¨äºGPyTorchæ¨¡å‹ï¼‰
    X_sample: è®­ç»ƒæ•°æ®æ ·æœ¬
    feature_name: ç›®æ ‡ç‰¹å¾åç§°
    n_points: PDPç½‘æ ¼ç‚¹æ•°
    
    è¿”å›:
    tuple: (pdp_x_values, pdp_y_values) æˆ– (None, None) å¦‚æœå¤±è´¥
    """
    try:
        print(f"    ğŸ¯ è®¡ç®—{feature_name}çš„æ ‡å‡†PDP...")
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
        if feature_name not in X_sample.columns:
            print(f"    âŒ ç‰¹å¾{feature_name}ä¸åœ¨æ•°æ®ä¸­")
            return None, None
        
        # 1. åˆ›å»ºç‰¹å¾å€¼ç½‘æ ¼ï¼ˆä½¿ç”¨5%-95%åˆ†ä½æ•°èŒƒå›´ï¼‰
        feature_values = X_sample[feature_name]
        feat_min, feat_max = np.percentile(feature_values, [5, 95])
        pdp_x = np.linspace(feat_min, feat_max, n_points)
        
        # 2. å‡†å¤‡åŸºç¡€æ•°æ®ï¼ˆå…¶ä»–ç‰¹å¾å›ºå®šä¸ºå‡å€¼ï¼‰
        base_sample = X_sample.mean().to_frame().T  # è½¬ä¸ºDataFrameè¡Œ
        
        # 3. ä½¿ç”¨æ‰¹å¤„ç†è®¡ç®—PDP
        try:
            import torch
            import gpytorch
            
            # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
            model.eval()
            if likelihood:
                likelihood.eval()
            
            # æ£€æŸ¥è®¾å¤‡
            device = next(model.parameters()).device
            
            # ğŸš€ æ‰¹å¤„ç†è®¾ç½® - æ ¹æ®æ•°æ®å¤§å°å’ŒGPUå†…å­˜è°ƒæ•´
            batch_size = min(16, n_points)  # æ¯æ‰¹å¤„ç†16ä¸ªç‚¹ï¼Œæˆ–æ›´å°‘
            pdp_y = []
            
            print(f"    ğŸ”„ ä½¿ç”¨æ‰¹å¤„ç†è®¡ç®—PDP: {n_points}ä¸ªç‚¹ï¼Œæ‰¹å¤§å°={batch_size}")
            
            # åˆ†æ‰¹å¤„ç†PDPè®¡ç®—
            for i in range(0, n_points, batch_size):
                batch_end = min(i + batch_size, n_points)
                batch_size_actual = batch_end - i
                
                # ä¸ºå½“å‰æ‰¹æ¬¡åˆ›å»ºæ•°æ®
                batch_data = pd.concat([base_sample] * batch_size_actual, ignore_index=True)
                batch_data[feature_name] = pdp_x[i:batch_end]  # è®¾ç½®å½“å‰æ‰¹æ¬¡çš„ç‰¹å¾å€¼
                
                # è½¬æ¢ä¸ºå¼ é‡å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
                X_tensor = torch.tensor(batch_data.values, dtype=torch.float32).to(device)
                
                # æ‰¹é‡é¢„æµ‹
                with torch.no_grad(), gpytorch.settings.fast_pred_var():
                    output = model(X_tensor)
                    if likelihood:
                        pred_dist = likelihood(output)
                        batch_predictions = pred_dist.mean.cpu().numpy()
                    else:
                        batch_predictions = output.mean.cpu().numpy()
                
                # æ”¶é›†æ‰¹æ¬¡ç»“æœ
                pdp_y.extend(batch_predictions)
                
                # å¯é€‰ï¼šæ˜¾ç¤ºè¿›åº¦
                if i % (batch_size * 2) == 0:  # æ¯2ä¸ªæ‰¹æ¬¡æ˜¾ç¤ºä¸€æ¬¡
                    progress = (batch_end / n_points) * 100
                    print(f"      è¿›åº¦: {progress:.1f}% ({batch_end}/{n_points}ä¸ªç‚¹)")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            pdp_y = np.array(pdp_y)
            
            print(f"    âœ… {feature_name}çš„æ‰¹å¤„ç†PDPè®¡ç®—æˆåŠŸï¼Œ{len(pdp_x)}ä¸ªç‚¹")
            return pdp_x, pdp_y
                
        except Exception as model_error:
            print(f"    âš ï¸ æ¨¡å‹é¢„æµ‹å¤±è´¥: {model_error}")
            return None, None
        
    except Exception as e:
        print(f"    âŒ PDPè®¡ç®—å¼‚å¸¸: {e}")
        return None, None


def calculate_pdp_for_feature(res_data, feature_name, feature_values, n_points=50):
    """
    ä¸ºç‰¹å¾è®¡ç®—PDPçš„åŒ…è£…å‡½æ•°ï¼Œä¿æŒå‘åå…¼å®¹
    
    å‚æ•°:
    res_data: åˆ†è¾¨ç‡ç»“æœæ•°æ®
    feature_name: ç‰¹å¾åç§°  
    feature_values: ç‰¹å¾å€¼æ•°ç»„ï¼ˆç°åœ¨å®é™…ä¸ä½¿ç”¨ï¼Œä»X_sampleä¸­è·å–ï¼‰
    n_points: PDPè®¡ç®—ç‚¹æ•°
    
    è¿”å›:
    tuple: (pdp_x_values, pdp_y_values) æˆ– (None, None) å¦‚æœå¤±è´¥
    """
    # è·å–æ¨¡å‹å’Œæ•°æ®
    model = res_data.get('model')
    likelihood = res_data.get('likelihood')
    X_sample = res_data.get('X_sample')
    
    if model is None or X_sample is None:
        print(f"    âŒ ç¼ºå°‘æ¨¡å‹æˆ–æ•°æ®")
        return None, None
    
    # è°ƒç”¨æ ‡å‡†PDPè®¡ç®—
    return calculate_standard_pdp(model, likelihood, X_sample, feature_name, n_points)


def plot_single_feature_dependency_grid(results, output_dir=None, top_n=3):
    """
    åˆ›å»ºSHAPä¾èµ–å›¾ç½‘æ ¼ï¼ˆä¸æ˜¯PDPï¼ï¼‰
    
    ä¸ºä¸‰ä¸ªåˆ†è¾¨ç‡ä¸‹çš„topä¸»æ•ˆåº”ç¯å¢ƒç‰¹å¾ç»˜åˆ¶SHAPä¾èµ–å›¾ï¼š
    - 3Ã—3ç½‘æ ¼å¸ƒå±€ï¼Œæ¯è¡Œä¸€ä¸ªåˆ†è¾¨ç‡ï¼Œæ¯åˆ—ä¸€ä¸ªç‰¹å¾
    - Xè½´ï¼šç‰¹å¾å€¼ï¼ŒYè½´ï¼šGeoShapley Valueï¼ˆSHAPå€¼ï¼‰
    - è“è‰²æ•£ç‚¹ + çº¢è‰²å¹³æ»‘è¶‹åŠ¿çº¿ + é›¶çº¿
    
    å‚æ•°:
    results (dict): åŒ…å«å„åˆ†è¾¨ç‡æ¨¡å‹ç»“æœå’ŒSHAPå€¼çš„å­—å…¸
    output_dir (str): è¾“å‡ºç›®å½•
    top_n (int): æ¯ä¸ªåˆ†è¾¨ç‡æ˜¾ç¤ºçš„é¡¶çº§ä¸»æ•ˆåº”ç‰¹å¾æ•°é‡ï¼ˆé»˜è®¤3ä¸ªï¼‰
    
    è¿”å›:
    str: ç”Ÿæˆçš„å›¾è¡¨è·¯å¾„
    """
    print("\nğŸ¨ åˆ›å»ºSHAPä¾èµ–å›¾ç½‘æ ¼...")
    print("æ˜¾ç¤ºä¸‰ä¸ªåˆ†è¾¨ç‡ä¸‹top3ä¸»æ•ˆåº”ç¯å¢ƒç‰¹å¾çš„SHAPä¾èµ–å…³ç³»")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if output_dir:
        ensure_dir_exists(output_dir)
    
    # ğŸ”§ ä¿®å¤ï¼šåŠ è½½GeoShapleyæ•°æ®æ–‡ä»¶ä¸­çš„SHAPå€¼
    print("  ğŸ”§ ä»GeoShapleyæ•°æ®æ–‡ä»¶åŠ è½½SHAPå€¼...")
    enhanced_results = {}
    
    for res in ['res5', 'res6', 'res7']:
        if res in results:
            enhanced_results[res] = results[res].copy()
            
            # å°è¯•ä»GeoShapleyæ•°æ®æ–‡ä»¶åŠ è½½SHAPå€¼
            geoshapley_file = f'output/{res}/{res}_geoshapley_data.pkl'
            if os.path.exists(geoshapley_file):
                try:
                    import pickle
                    with open(geoshapley_file, 'rb') as f:
                        geoshapley_data = pickle.load(f)
                    
                    # åˆå¹¶GeoShapleyæ•°æ®åˆ°ç»“æœä¸­
                    enhanced_results[res].update(geoshapley_data)
                    print(f"    âœ… {res}: æˆåŠŸåŠ è½½GeoShapleyæ•°æ®ï¼ŒåŒ…å«é”®: {list(geoshapley_data.keys())}")
                    
                    # éªŒè¯SHAPå€¼
                    if 'shap_values_by_feature' in geoshapley_data:
                        shap_dict = geoshapley_data['shap_values_by_feature']
                        if 'slope' in shap_dict:
                            print(f"    ğŸ“Š {res}: slope SHAPå€¼é•¿åº¦: {len(shap_dict['slope'])}")
                        else:
                            print(f"    âš ï¸ {res}: ç¼ºå°‘slope SHAPå€¼")
                    
                except Exception as e:
                    print(f"    âŒ {res}: åŠ è½½GeoShapleyæ•°æ®å¤±è´¥: {e}")
            else:
                print(f"    âŒ {res}: æœªæ‰¾åˆ°GeoShapleyæ•°æ®æ–‡ä»¶: {geoshapley_file}")
    
    # åˆ†è¾¨ç‡æ ‡ç­¾
    res_titles = {'res7': 'H3 Resolution 7 (Micro)', 'res6': 'H3 Resolution 6 (Meso)', 'res5': 'H3 Resolution 5 (Macro)'}
    
    # å­å›¾æ ‡ç­¾ - 9ä¸ªæ ‡ç­¾ï¼ŒæŒ‰è¡Œæ’åˆ—
    subplot_labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i']
    
    # å®šä¹‰åˆ†è¾¨ç‡åˆ—è¡¨
    resolutions = ['res7', 'res6', 'res5']
    
    # ä¿å­˜åŸå§‹rcParams
    original_rcParams = plt.rcParams.copy()
    
    # åˆ›å»ºæœ¬åœ°æ ·å¼å­—å…¸ï¼ˆå‚è€ƒregionkmeans_plot.pyçš„é£æ ¼ï¼‰
    style_dict = {
        'font.family': 'serif',
        'font.serif': ['Times New Roman'],
        'font.size': 12,
        'font.weight': 'bold',
        'axes.titlesize': 14,
        'axes.labelsize': 12,
        'axes.titleweight': 'bold',
        'axes.labelweight': 'bold',
        'xtick.labelsize': 10,
        'ytick.labelsize': 10,
        'xtick.major.width': 1.5,
        'ytick.major.width': 1.5,
        'xtick.direction': 'in',
        'ytick.direction': 'in',
        'xtick.major.size': 4,
        'ytick.major.size': 4,
        'axes.linewidth': 1.5,
        'legend.fontsize': 10,
        'legend.title_fontsize': 11,
        'figure.dpi': 600,
        'savefig.dpi': 600,
        'figure.constrained_layout.use': False,
        'axes.spines.top': True,
        'axes.spines.right': True,
        'axes.spines.bottom': True,
        'axes.spines.left': True,
    }
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨éš”ç¦»æ ·å¼è®¾ç½®
    with plt.style.context('default'):
        with plt.rc_context(style_dict):
            
            # åˆ›å»º 3Ã—3 ç½‘æ ¼å›¾
            fig, axes = plt.subplots(3, 3, figsize=(16, 14), dpi=600)
            axes = axes.flatten()
            
            plot_idx = 0
            
            # éå†æ¯ä¸ªåˆ†è¾¨ç‡
            for res_idx, res in enumerate(resolutions):
                if res not in enhanced_results:
                    print(f"è­¦å‘Š: ç»“æœä¸­ç¼ºå°‘ {res} æ•°æ®")
                    # åˆ›å»ºç©ºç™½å­å›¾
                    for i in range(top_n):
                        if plot_idx < 9:
                            ax = axes[plot_idx]
                            ax.text(0.5, 0.5, f"No data for {res}", 
                                   ha='center', va='center', fontsize=12, transform=ax.transAxes)
                            ax.axis('off')
                            plot_idx += 1
                    continue
                
                # è·å–è¯¥åˆ†è¾¨ç‡çš„ç»“æœ
                res_data = enhanced_results[res]
                
                # è·å–SHAPå€¼å’Œç‰¹å¾æ•°æ®
                shap_values = res_data.get('shap_values')
                shap_values_by_feature = res_data.get('shap_values_by_feature', {})
                X_sample = res_data.get('X_sample')
                feature_importance = res_data.get('feature_importance', [])
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å½¢å¼çš„SHAPæ•°æ®
                has_shap_data = (shap_values is not None) or (len(shap_values_by_feature) > 0)
                
                if not has_shap_data or X_sample is None:
                    print(f"è­¦å‘Š: {res} ç¼ºå°‘SHAPå€¼æˆ–X_sampleæ•°æ®")
                    # åˆ›å»ºç©ºç™½å­å›¾
                    for i in range(top_n):
                        if plot_idx < 9:
                            ax = axes[plot_idx]
                            ax.text(0.5, 0.5, f"No SHAP data for {res}", 
                                   ha='center', va='center', fontsize=12, transform=ax.transAxes)
                            ax.axis('off')
                            plot_idx += 1
                    continue
                
                # è¿‡æ»¤å‡ºä¸»æ•ˆåº”ç‰¹å¾ï¼ˆæ’é™¤GEOã€yearå’Œäº¤äº’æ•ˆåº”ï¼‰
                primary_effects = []
                for feat_item in feature_importance:
                    # å¤„ç†ä¸åŒæ ¼å¼çš„ç‰¹å¾é‡è¦æ€§æ•°æ®
                    if isinstance(feat_item, tuple) and len(feat_item) >= 2:
                        feat_name = feat_item[0]
                        importance = feat_item[1]
                    elif isinstance(feat_item, dict):
                        feat_name = feat_item.get('feature', '')
                        importance = feat_item.get('importance', 0)
                    else:
                        continue
                    
                    # æ’é™¤GEOã€yearç‰¹å¾å’Œäº¤äº’æ•ˆåº”ï¼Œåªä¿ç•™ç¯å¢ƒç‰¹å¾
                    feat_name_lower = str(feat_name).lower()
                    if (feat_name != 'GEO' and 
                        feat_name_lower != 'year' and 
                        'Ã—' not in str(feat_name) and 
                        ' x ' not in str(feat_name) and
                        feat_name_lower not in ['latitude', 'longitude', 'h3_index']):
                        primary_effects.append((feat_name, importance))
                
                # æŒ‰é‡è¦æ€§æ’åºå¹¶é€‰æ‹©å‰top_nä¸ªç‰¹å¾
                primary_effects.sort(key=lambda x: x[1], reverse=True)
                selected_features = primary_effects[:top_n]
                
                if not selected_features:
                    print(f"è­¦å‘Š: {res} æ²¡æœ‰æœ‰æ•ˆçš„ä¸»æ•ˆåº”ç‰¹å¾")
                    # åˆ›å»ºç©ºç™½å­å›¾
                    for i in range(top_n):
                        if plot_idx < 9:
                            ax = axes[plot_idx]
                            ax.text(0.5, 0.5, f"No primary effects for {res}", 
                                   ha='center', va='center', fontsize=12, transform=ax.transAxes)
                            ax.axis('off')
                            plot_idx += 1
                    continue
                
                print(f"\n{res} çš„å‰ {len(selected_features)} ä¸ªä¸»æ•ˆåº”ç‰¹å¾:")
                for feat, imp in selected_features:
                    print(f"  - {feat}: {imp:.4f}")
                
                # è·å–ç‰¹å¾åç§°åˆ—è¡¨ï¼ˆç”¨äºç´¢å¼•SHAPå€¼ï¼‰
                feature_names = list(X_sample.columns)
                
                # ä¼˜å…ˆä½¿ç”¨shap_values_by_featureï¼Œå¦‚æœæ²¡æœ‰æ‰ä½¿ç”¨shap_valuesçŸ©é˜µ
                if len(shap_values_by_feature) > 0:
                    print(f"\n{res} SHAPä¾èµ–å›¾ç»˜åˆ¶å‡†å¤‡ï¼Œä½¿ç”¨shap_values_by_featureæ ¼å¼")
                elif shap_values is not None:
                    print(f"\n{res} SHAPä¾èµ–å›¾ç»˜åˆ¶å‡†å¤‡ï¼ŒSHAPå€¼å½¢çŠ¶: {shap_values.shape}")
                else:
                    print(f"\n{res} æ— å¯ç”¨SHAPæ•°æ®")
                
                # ç»˜åˆ¶æ¯ä¸ªç‰¹å¾çš„SHAPä¾èµ–å›¾
                for feat_idx, (feat_name, importance) in enumerate(selected_features):
                    if plot_idx >= 9:
                        break
                    
                    ax = axes[plot_idx]
                    
                    # è®¾ç½®è½´çº¿å®½åº¦
                    for spine in ax.spines.values():
                        spine.set_linewidth(1.5)
                    
                    # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨äºæ•°æ®ä¸­
                    if feat_name not in feature_names:
                        print(f"    âŒ ç‰¹å¾{feat_name}ä¸åœ¨{res}çš„ç‰¹å¾åˆ—è¡¨ä¸­")
                        ax.text(0.5, 0.5, f"Feature {feat_name} not found", 
                               ha='center', va='center', fontsize=12, transform=ax.transAxes)
                        res_short = {'res7': 'Resolution 7 (Micro)', 'res6': 'Resolution 6 (Meso)', 'res5': 'Resolution 5 (Macro)'}
                        ax.set_title(f'({subplot_labels[plot_idx]}) {res_short[res]} - {enhance_feature_display_name(feat_name)}', 
                                   fontsize=11, fontweight='bold')
                        ax.axis('off')
                        plot_idx += 1
                        continue
                    
                    # ğŸ¯ è·å–ç‰¹å¾å€¼å’Œå¯¹åº”çš„SHAPå€¼
                    x_values = X_sample[feat_name].values
                    
                    # ä»ä¸åŒæ¥æºè·å–SHAPå€¼
                    if feat_name in shap_values_by_feature:
                        # ä»shap_values_by_featureå­—å…¸è·å–
                        y_values = shap_values_by_feature[feat_name]
                        print(f"      ğŸ“Š ä»shap_values_by_featureè·å–{feat_name}çš„SHAPå€¼ï¼Œé•¿åº¦: {len(y_values)}")
                    elif shap_values is not None:
                        # ä»shap_valuesçŸ©é˜µè·å–
                        feat_idx_in_data = feature_names.index(feat_name)
                        y_values = shap_values[:, feat_idx_in_data]
                        print(f"      ğŸ“Š ä»shap_valuesçŸ©é˜µè·å–{feat_name}çš„SHAPå€¼ï¼Œç´¢å¼•: {feat_idx_in_data}")
                    else:
                        print(f"      âŒ æ— æ³•è·å–{feat_name}çš„SHAPå€¼")
                        ax.text(0.5, 0.5, f"SHAP values not available\nfor {feat_name}", 
                               ha='center', va='center', fontsize=12, transform=ax.transAxes, color='red')
                        res_short = {'res7': 'Resolution 7 (Micro)', 'res6': 'Resolution 6 (Meso)', 'res5': 'Resolution 5 (Macro)'}
                        ax.set_title(f'({subplot_labels[plot_idx]}) {res_short[res]} - {enhance_feature_display_name(feat_name)}', 
                                   fontsize=11, fontweight='bold')
                        ax.axis('off')
                        plot_idx += 1
                        continue
                    
                    print(f"    ğŸ”„ ç»˜åˆ¶{feat_name}çš„SHAPä¾èµ–å›¾...")
                    
                    try:
                        # ğŸ¨ SHAPä¾èµ–å›¾æ ·å¼ï¼šç°è‰²ç½®ä¿¡åŒºé—´ + è“è‰²æ•£ç‚¹ + çº¢è‰²æ‹Ÿåˆæ›²çº¿
                        
                        # 1. âœ¨ æ”¹è¿›çš„å¹³æ»‘ç½®ä¿¡åŒºé—´è®¡ç®—
                        try:
                            # æ’åºæ•°æ®ä»¥ä¾¿è®¡ç®—ç½®ä¿¡åŒºé—´
                            sorted_indices = np.argsort(x_values)
                            x_sorted = x_values[sorted_indices]
                            y_sorted = y_values[sorted_indices]
                            
                            # ğŸ”§ æ”¹è¿›æ–¹æ³•ï¼šä½¿ç”¨ç§»åŠ¨çª—å£ + å¹³æ»‘å¤„ç†
                            n_points = len(x_sorted)
                            if n_points >= 10:
                                # è‡ªé€‚åº”çª—å£å¤§å°ï¼šç¡®ä¿æ¯ä¸ªçª—å£æœ‰è¶³å¤Ÿæ ·æœ¬ä½†ä¸è¿‡å¤§
                                window_size = max(10, min(50, n_points // 5))
                                
                                # ç”Ÿæˆå¹³æ»‘çš„xè½´é‡‡æ ·ç‚¹
                                n_smooth_points = min(50, n_points // 2)
                                x_smooth = np.linspace(x_sorted.min(), x_sorted.max(), n_smooth_points)
                                
                                y_lower_smooth = []
                                y_upper_smooth = []
                                
                                for x_target in x_smooth:
                                    # è®¡ç®—åˆ°ç›®æ ‡xå€¼çš„è·ç¦»
                                    distances = np.abs(x_sorted - x_target)
                                    
                                    # é€‰æ‹©æœ€è¿‘çš„window_sizeä¸ªç‚¹
                                    closest_indices = np.argsort(distances)[:window_size]
                                    y_window = y_sorted[closest_indices]
                                    
                                    # ä½¿ç”¨åŠ æƒåˆ†ä½æ•°ï¼šè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§
                                    weights = 1.0 / (distances[closest_indices] + 1e-8)
                                    weights = weights / np.sum(weights)
                                    
                                    # è®¡ç®—åŠ æƒåˆ†ä½æ•°
                                    sorted_window_indices = np.argsort(y_window)
                                    sorted_weights = weights[sorted_window_indices]
                                    cumsum_weights = np.cumsum(sorted_weights)
                                    
                                    # æ‰¾åˆ°25%å’Œ75%åˆ†ä½æ•°å¯¹åº”çš„å€¼
                                    q25_idx = np.searchsorted(cumsum_weights, 0.25)
                                    q75_idx = np.searchsorted(cumsum_weights, 0.75)
                                    
                                    q25_idx = min(q25_idx, len(y_window) - 1)
                                    q75_idx = min(q75_idx, len(y_window) - 1)
                                    
                                    y_lower_smooth.append(y_window[sorted_window_indices[q25_idx]])
                                    y_upper_smooth.append(y_window[sorted_window_indices[q75_idx]])
                                
                                # ğŸ¯ è¿›ä¸€æ­¥å¹³æ»‘è¾¹ç•Œä»¥æ¶ˆé™¤é”¯é½¿
                                from scipy.ndimage import gaussian_filter1d
                                # ä½¿ç”¨é«˜æ–¯æ»¤æ³¢å™¨å¹³æ»‘è¾¹ç•Œ
                                sigma = max(1, len(y_lower_smooth) / 20)  # è‡ªé€‚åº”å¹³æ»‘å¼ºåº¦
                                y_lower_smooth = gaussian_filter1d(y_lower_smooth, sigma=sigma, mode='nearest')
                                y_upper_smooth = gaussian_filter1d(y_upper_smooth, sigma=sigma, mode='nearest')
                                
                                # ç»˜åˆ¶å¹³æ»‘çš„ç°è‰²ç½®ä¿¡åŒºé—´
                                ax.fill_between(x_smooth, y_lower_smooth, y_upper_smooth, 
                                               color='gray', alpha=0.3, 
                                               label='25%-75% Range', zorder=1)
                                print(f"      âœ… æ·»åŠ äº†å¹³æ»‘çš„ç°è‰²ç½®ä¿¡åŒºé—´èƒŒæ™¯ï¼ˆ{len(x_smooth)}ä¸ªç‚¹ï¼‰")
                            
                            elif n_points >= 5:
                                # æ•°æ®ç‚¹è¾ƒå°‘æ—¶ï¼Œä½¿ç”¨ç®€åŒ–çš„å…¨å±€åˆ†ä½æ•°
                                q25 = np.percentile(y_sorted, 25)
                                q75 = np.percentile(y_sorted, 75)
                                
                                # ç»˜åˆ¶æ°´å¹³ç½®ä¿¡å¸¦
                                ax.fill_between([x_sorted.min(), x_sorted.max()], [q25, q25], [q75, q75],
                                               color='gray', alpha=0.2, zorder=1)
                                print(f"      âœ… æ•°æ®ç‚¹è¾ƒå°‘ï¼Œä½¿ç”¨å…¨å±€åˆ†ä½æ•°ç½®ä¿¡å¸¦")
                                
                        except ImportError:
                            # å¦‚æœæ²¡æœ‰scipyï¼Œä½¿ç”¨ç®€åŒ–çš„ç§»åŠ¨å¹³å‡æ–¹æ³•
                            try:
                                sorted_indices = np.argsort(x_values)
                                x_sorted = x_values[sorted_indices]
                                y_sorted = y_values[sorted_indices]
                                
                                # ç®€åŒ–çš„ç§»åŠ¨çª—å£æ–¹æ³•
                                window_size = max(5, len(x_sorted) // 8)
                                n_smooth = min(30, len(x_sorted) // 2)
                                x_smooth = np.linspace(x_sorted.min(), x_sorted.max(), n_smooth)
                                
                                y_lower_simple = []
                                y_upper_simple = []
                                
                                for x_target in x_smooth:
                                    distances = np.abs(x_sorted - x_target)
                                    closest_indices = np.argsort(distances)[:window_size]
                                    y_window = y_sorted[closest_indices]
                                    
                                    y_lower_simple.append(np.percentile(y_window, 30))  # ç¨å¾®ä¿å®ˆ
                                    y_upper_simple.append(np.percentile(y_window, 70))
                                
                                # ç®€å•å¹³æ»‘ï¼šç§»åŠ¨å¹³å‡
                                smooth_window = max(1, len(y_lower_simple) // 10)
                                if smooth_window > 1:
                                    y_lower_smooth = np.convolve(y_lower_simple, np.ones(smooth_window)/smooth_window, mode='same')
                                    y_upper_smooth = np.convolve(y_upper_simple, np.ones(smooth_window)/smooth_window, mode='same')
                                else:
                                    y_lower_smooth = y_lower_simple
                                    y_upper_smooth = y_upper_simple
                                
                                ax.fill_between(x_smooth, y_lower_smooth, y_upper_smooth, 
                                               color='gray', alpha=0.3, zorder=1)
                                print(f"      âœ… ä½¿ç”¨ç®€åŒ–å¹³æ»‘æ–¹æ³•ç”Ÿæˆç½®ä¿¡åŒºé—´")
                                
                            except Exception as e:
                                print(f"      âš ï¸ ç®€åŒ–ç½®ä¿¡åŒºé—´ç”Ÿæˆä¹Ÿå¤±è´¥: {e}")
                                
                        except Exception as e:
                            print(f"      âš ï¸ å¹³æ»‘ç½®ä¿¡åŒºé—´ç”Ÿæˆå¤±è´¥: {e}")
                        
                        # 2. ç»˜åˆ¶è“è‰²æ•£ç‚¹å›¾ï¼ˆåœ¨ç½®ä¿¡åŒºé—´ä¹‹ä¸Šï¼‰
                        ax.scatter(x_values, y_values, color='#1f77b4', s=15, 
                                 alpha=0.6, edgecolors='none', zorder=3)
                        
                        # 3. æ·»åŠ çº¢è‰²æ‹Ÿåˆæ›²çº¿ï¼ˆåœ¨æœ€ä¸Šå±‚ï¼‰- ä½¿ç”¨æ”¹è¿›çš„å±€éƒ¨å›å½’æ–¹æ³•
                        try:
                            # æ’åºæ•°æ®ç”¨äºæ‹Ÿåˆ
                            sorted_indices = np.argsort(x_values)
                            x_sorted = x_values[sorted_indices]
                            y_sorted = y_values[sorted_indices]
                            
                            # ğŸ”§ æ”¹è¿›çš„è¶‹åŠ¿çº¿æ‹Ÿåˆæ–¹æ³•
                            if len(np.unique(x_sorted)) > 5:
                                # æ–¹æ³•1ï¼šå°è¯•ä½¿ç”¨scipyçš„UnivariateSplineè¿›è¡Œå¹³æ»‘
                                try:
                                    from scipy.interpolate import UnivariateSpline
                                    # ä½¿ç”¨è¾ƒå¤§çš„å¹³æ»‘å› å­ï¼Œé¿å…è¿‡æ‹Ÿåˆ
                                    smoothing_factor = len(x_sorted) * np.var(y_sorted) * 0.1
                                    spline = UnivariateSpline(x_sorted, y_sorted, s=smoothing_factor)
                                    x_smooth = np.linspace(x_sorted.min(), x_sorted.max(), 100)
                                    y_smooth = spline(x_smooth)
                                    
                                    # ğŸ”§ æ£€æŸ¥å¹¶å¤„ç†NaNå€¼
                                    if np.any(np.isnan(y_smooth)) or np.any(np.isinf(y_smooth)):
                                        print(f"      âš ï¸ UnivariateSplineç”Ÿæˆäº†NaN/Infå€¼ï¼Œè·³è¿‡")
                                        raise ValueError("æ‹Ÿåˆçº¿åŒ…å«NaNå€¼")
                                    
                                    ax.plot(x_smooth, y_smooth, color='red', linewidth=4, alpha=1.0, zorder=100)
                                    print(f"      âœ… ä½¿ç”¨UnivariateSplineç”Ÿæˆè¶‹åŠ¿çº¿")
                                except (ImportError, ValueError):
                                    # æ–¹æ³•2ï¼šå¢å¼ºå¹³æ»‘ç§»åŠ¨çª—å£å›å½’
                                    # ğŸ¯ åˆ›å»ºæ›´å¯†é›†çš„æ’å€¼ç‚¹ï¼Œæé«˜å¹³æ»‘åº¦
                                    x_min, x_max = x_sorted.min(), x_sorted.max()
                                    n_interp_points = max(50, len(np.unique(x_sorted)) * 3)  # å¢åŠ æ’å€¼ç‚¹å¯†åº¦
                                    x_interp = np.linspace(x_min, x_max, n_interp_points)
                                    
                                    # ğŸ”§ ä½¿ç”¨åŠ æƒå±€éƒ¨å›å½’ (LOWESSé£æ ¼)
                                    y_interp = []
                                    bandwidth = max(0.1, 1.0 / len(np.unique(x_sorted)))  # è‡ªé€‚åº”å¸¦å®½
                                    
                                    for x_target in x_interp:
                                        # è®¡ç®—æƒé‡ï¼šåŸºäºè·ç¦»çš„é«˜æ–¯æƒé‡
                                        distances = np.abs(x_sorted - x_target)
                                        # è‡ªé€‚åº”å¸¦å®½ï¼šåŸºäºæ•°æ®å¯†åº¦
                                        h = bandwidth * (x_max - x_min)
                                        weights = np.exp(-0.5 * (distances / h) ** 2)
                                        
                                        # é¿å…æƒé‡è¿‡å°
                                        if np.sum(weights) < 1e-10:
                                            # å¦‚æœæ‰€æœ‰æƒé‡éƒ½å¤ªå°ï¼Œä½¿ç”¨æœ€è¿‘çš„å‡ ä¸ªç‚¹
                                            nearest_indices = distances.argsort()[:max(3, len(x_sorted) // 10)]
                                            weights = np.zeros_like(distances)
                                            weights[nearest_indices] = 1.0
                                        
                                        # åŠ æƒå¹³å‡
                                        weights = weights / np.sum(weights)
                                        y_weighted = np.sum(weights * y_sorted)
                                        y_interp.append(y_weighted)
                                    
                                    # ğŸ¨ å¤šå±‚å¹³æ»‘å¤„ç†
                                    y_smooth_final = np.array(y_interp)
                                    
                                    # ç¬¬ä¸€å±‚ï¼šé«˜æ–¯æ»¤æ³¢å¹³æ»‘
                                    try:
                                        from scipy.ndimage import gaussian_filter1d
                                        sigma = max(1.0, len(y_smooth_final) * 0.03)  # è‡ªé€‚åº”å¹³æ»‘å¼ºåº¦
                                        y_smooth_final = gaussian_filter1d(y_smooth_final, sigma=sigma, mode='nearest')
                                        print(f"      ğŸ¯ åº”ç”¨é«˜æ–¯æ»¤æ³¢å¹³æ»‘ (sigma={sigma:.2f})")
                                    except ImportError:
                                        # å¤‡ç”¨ï¼šç§»åŠ¨å¹³å‡å¹³æ»‘
                                        window = max(3, len(y_smooth_final) // 15)
                                        if window % 2 == 0:
                                            window += 1
                                        y_smooth_temp = []
                                        half_window = window // 2
                                        for i in range(len(y_smooth_final)):
                                            start_i = max(0, i - half_window)
                                            end_i = min(len(y_smooth_final), i + half_window + 1)
                                            y_smooth_temp.append(np.mean(y_smooth_final[start_i:end_i]))
                                        y_smooth_final = np.array(y_smooth_temp)
                                        print(f"      ğŸ¯ åº”ç”¨ç§»åŠ¨å¹³å‡å¹³æ»‘ (çª—å£={window})")
                                    
                                    # ğŸ¨ ç»˜åˆ¶è¶…å¹³æ»‘çš„çº¢è‰²æ‹Ÿåˆçº¿
                                    ax.plot(x_interp, y_smooth_final, color='red', linewidth=4, alpha=1.0, zorder=100)
                                    print(f"      âœ… ä½¿ç”¨å¢å¼ºå¹³æ»‘ç§»åŠ¨çª—å£ç”Ÿæˆè¶‹åŠ¿çº¿ ({n_interp_points}ä¸ªæ’å€¼ç‚¹)")
                                        
                            elif len(np.unique(x_sorted)) > 2:
                                # å¯¹äºç‚¹æ•°è¾ƒå°‘çš„æƒ…å†µï¼Œä½¿ç”¨2æ¬¡å¤šé¡¹å¼æ‹Ÿåˆ
                                try:
                                    z = np.polyfit(x_sorted, y_sorted, deg=min(2, len(np.unique(x_sorted))-1))
                                    p = np.poly1d(z)
                                    x_smooth = np.linspace(x_sorted.min(), x_sorted.max(), 50)
                                    y_smooth = p(x_smooth)
                                    ax.plot(x_smooth, y_smooth, color='red', linewidth=4, alpha=1.0, zorder=100)
                                    print(f"      âœ… ä½¿ç”¨å¤šé¡¹å¼æ‹Ÿåˆç”Ÿæˆè¶‹åŠ¿çº¿")
                                except np.linalg.LinAlgError:
                                    # ç®€å•çº¿æ€§æ‹Ÿåˆä½œä¸ºæœ€åå¤‡é€‰
                                    z = np.polyfit(x_sorted, y_sorted, 1)
                                    p = np.poly1d(z)
                                    ax.plot(x_sorted, p(x_sorted), color='red', linewidth=4, alpha=1.0, zorder=100)
                                    print(f"      âœ… ä½¿ç”¨çº¿æ€§æ‹Ÿåˆç”Ÿæˆè¶‹åŠ¿çº¿")
                            else:
                                # æ•°æ®ç‚¹å¤ªå°‘ï¼Œåªç»˜åˆ¶ç®€å•è¿çº¿
                                ax.plot(x_sorted, y_sorted, color='red', linewidth=4, alpha=1.0, zorder=100)
                                print(f"      âœ… æ•°æ®ç‚¹è¾ƒå°‘ï¼Œä½¿ç”¨ç›´æ¥è¿çº¿")
                                
                        except Exception as e:
                            print(f"      âš ï¸ çº¢è‰²æ‹Ÿåˆæ›²çº¿ç”Ÿæˆå¤±è´¥: {e}")
                            # å¤±è´¥æ—¶ç»˜åˆ¶ç®€å•çš„çº¿æ€§æ‹Ÿåˆä½œä¸ºå¤‡é€‰
                            try:
                                sorted_indices = np.argsort(x_values)
                                x_sorted = x_values[sorted_indices] 
                                y_sorted = y_values[sorted_indices]
                                z = np.polyfit(x_sorted, y_sorted, 1)
                                p = np.poly1d(z)
                                ax.plot(x_sorted, p(x_sorted), color='red', linewidth=4, alpha=1.0, zorder=100)
                                print(f"      ğŸ”§ ä½¿ç”¨å¤‡ç”¨çº¿æ€§æ‹Ÿåˆ")
                            except:
                                print(f"      âŒ æ‰€æœ‰æ‹Ÿåˆæ–¹æ³•éƒ½å¤±è´¥")
                        
                        # 4. æ·»åŠ é›¶çº¿ï¼ˆé»‘è‰²è™šçº¿ï¼Œåœ¨èƒŒæ™¯å±‚ï¼‰
                        ax.axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1, zorder=2)
                        
                        print(f"    âœ… {feat_name} SHAPä¾èµ–å›¾ç»˜åˆ¶æˆåŠŸï¼ˆå«ç°è‰²ç½®ä¿¡åŒºé—´ï¼‰")
                    
                    except Exception as e:
                        # SHAPä¾èµ–å›¾ç»˜åˆ¶å‡ºé”™
                        ax.text(0.5, 0.5, f"SHAP dependency error\nfor {feat_name}\n{str(e)[:30]}...", 
                               ha='center', va='center', fontsize=10, 
                               transform=ax.transAxes, color='red')
                        print(f"    âŒ {feat_name} SHAPä¾èµ–å›¾ç»˜åˆ¶å‡ºé”™: {e}")
                    
                    # è®¾ç½®æ ‡ç­¾å’Œæ ¼å¼
                    ax.set_xlabel(enhance_feature_display_name(feat_name), fontsize=11, fontweight='bold')
                    ax.set_ylabel('GeoShapley Value', fontsize=11, fontweight='bold')
                    
                    # è®¾ç½®æ ‡é¢˜ - ä½¿ç”¨"åˆ†è¾¨ç‡-ç‰¹å¾"æ ¼å¼
                    res_short = {'res7': 'Resolution 7 (Micro)', 'res6': 'Resolution 6 (Meso)', 'res5': 'Resolution 5 (Macro)'}
                    title = f'({subplot_labels[plot_idx]}) {res_short[res]} - {enhance_feature_display_name(feat_name)}'
                    ax.set_title(title, fontsize=11, fontweight='bold')
                    
                    # æ·»åŠ ç½‘æ ¼ï¼ˆä½¿ç”¨ç‚¹çŠ¶ç½‘æ ¼ï¼‰
                    ax.grid(True, alpha=0.3, linestyle=':', linewidth=1)
                    
                    # è®¾ç½®åˆ»åº¦
                    ax.tick_params(axis='both', which='major', labelsize=10, width=1.5, length=4, direction='in')
                    
                    # è®¾ç½®åˆ»åº¦æ ‡ç­¾ä¸ºç²—ä½“
                    for tick in ax.get_xticklabels():
                        tick.set_fontweight('bold')
                    for tick in ax.get_yticklabels():
                        tick.set_fontweight('bold')
                    
                    plot_idx += 1
                
                # å¡«å……å‰©ä½™çš„å­å›¾ï¼ˆå¦‚æœç‰¹å¾å°‘äºtop_nï¼‰
                while plot_idx < (res_idx + 1) * top_n and plot_idx < 9:
                    ax = axes[plot_idx]
                    ax.axis('off')
                    plot_idx += 1
            
            # æ·»åŠ æ€»æ ‡é¢˜
            fig.suptitle('SHAP Dependency Plots for Top Primary Effects Across Resolutions', 
                        fontsize=18, fontweight='bold')
            
            # è°ƒæ•´å¸ƒå±€
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            
            # ä¿å­˜å›¾è¡¨
            if output_dir:
                output_path = os.path.join(output_dir, 'all_resolutions_pdp_grid.png')
                plt.savefig(output_path, dpi=600, bbox_inches='tight', 
                           transparent=False, facecolor='white', edgecolor='none')
                plt.close()
                
                # è¾“å‡ºè¯¦ç»†çš„ä¿å­˜ä¿¡æ¯
                print(f"\n  âœ… SHAPä¾èµ–å›¾ç½‘æ ¼å·²ä¿å­˜åˆ°: {output_path}")
                print(f"    ğŸ“Š åŒ…å«è“è‰²æ•£ç‚¹ã€çº¢è‰²è¶‹åŠ¿çº¿å’Œé›¶çº¿çš„æ ‡å‡†SHAPä¾èµ–å›¾")
                
                return output_path
            else:
                plt.close()  # ç¡®ä¿å›¾å½¢è¢«å…³é—­
                return None
    
    # æ¢å¤åŸå§‹rcParamsè®¾ç½®
    plt.rcParams.update(original_rcParams) 