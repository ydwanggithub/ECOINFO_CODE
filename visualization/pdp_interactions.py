#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
PDPäº¤äº’æ•ˆåº”ç»˜åˆ¶æ¨¡å— - ç‰¹å¾äº¤äº’å¯è§†åŒ–åŠŸèƒ½

ä»pdp_plots.pyé‡æ„è€Œæ¥ï¼Œä¸“æ³¨äºï¼š
- è¯†åˆ«é¡¶çº§äº¤äº’ç‰¹å¾å¯¹
- äº¤äº’æ•ˆåº”PDPç½‘æ ¼ç»˜åˆ¶
- å•ä¸ªäº¤äº’æ•ˆåº”PDPç»˜åˆ¶

é€‚é…ST-GPRæ¨¡å‹çš„ç‰¹æ®Šéœ€æ±‚å’ŒGeoShapleyåˆ†æ
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import re
from matplotlib.gridspec import GridSpec
from sklearn.inspection import partial_dependence
from typing import Dict, List, Optional, Tuple, Union, Any
from scipy.stats import gaussian_kde
import matplotlib.patches as mpatches

# å¯¼å…¥é€šç”¨çš„ç»˜å›¾å‡½æ•°å’Œå·¥å…·
try:
    from .base import enhance_plot_style, ensure_dir_exists, save_plot_for_publication, color_map
    from .utils import clean_feature_name_for_plot, categorize_feature, simplify_feature_name_for_plot, enhance_feature_display_name, clean_feature_name, format_pdp_feature_name
    from model_analysis.core import standardize_feature_name
    from visualization.utils import ensure_spatiotemporal_features
except ImportError:
    # ç›¸å¯¹å¯¼å…¥å¤±è´¥æ—¶å°è¯•ç»å¯¹å¯¼å…¥
    from visualization.base import enhance_plot_style, ensure_dir_exists, save_plot_for_publication, color_map
    from visualization.utils import clean_feature_name_for_plot, categorize_feature, simplify_feature_name_for_plot, enhance_feature_display_name, clean_feature_name, format_pdp_feature_name
    from model_analysis.core import standardize_feature_name
    from visualization.utils import ensure_spatiotemporal_features

# è®¾ç½®matplotlibé»˜è®¤å­—ä½“ä»¥æ”¯æŒä¸­æ–‡
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False


def identify_top_interactions(results, top_n=3):
    """
    åŸºäºSHAPäº¤äº’å€¼è¯†åˆ«æ¯ä¸ªåˆ†è¾¨ç‡çš„é¡¶çº§äº¤äº’ç‰¹å¾å¯¹ï¼Œé€‚ç”¨äºSTGPRæ¨¡å‹åˆ†æ
    
    ä½¿ç”¨å…¨éƒ¨18ä¸ªç‰¹å¾ï¼ˆGeoShapleyè¾“å‡ºï¼‰ï¼š
    åœ¨GeoShapleyåˆ†æè¾“å‡ºçš„18ä¸ªç‰¹å¾ä¸­è®¡ç®—äº¤äº’
    
    å‚æ•°:
    results (dict): åŒ…å«å„åˆ†è¾¨ç‡æ¨¡å‹ç»“æœçš„å­—å…¸
    top_n (int): æ¯ä¸ªåˆ†è¾¨ç‡è¿”å›çš„é¡¶çº§äº¤äº’ç‰¹å¾å¯¹æ•°é‡
    
    è¿”å›:
    dict: æ¯ä¸ªåˆ†è¾¨ç‡çš„é¡¶çº§äº¤äº’ç‰¹å¾å¯¹å­—å…¸
    """
    print("è¯†åˆ«é¡¶çº§ç‰¹å¾äº¤äº’å¯¹...")
    
    # å­˜å‚¨æ¯ä¸ªåˆ†è¾¨ç‡çš„é¡¶çº§äº¤äº’ç‰¹å¾å¯¹
    top_interactions = {}
    
    for res, res_data in results.items():
        if 'shap_interaction_values' not in res_data or res_data['shap_interaction_values'] is None:
            print(f"  âŒ {res}: æœªæ‰¾åˆ°SHAPäº¤äº’å€¼")
            print(f"     åŸå› ï¼šå¯èƒ½æœªè®¡ç®—SHAPäº¤äº’å€¼æˆ–è®¡ç®—å¤±è´¥")
            print(f"     å»ºè®®ï¼šæ£€æŸ¥GeoShapleyè®¡ç®—æ˜¯å¦æˆåŠŸå®Œæˆäº¤äº’å€¼è®¡ç®—")
            print(f"     è¯´æ˜ï¼šPDPäº¤äº’å›¾éœ€è¦SHAPäº¤äº’å€¼æ¥è¯†åˆ«é‡è¦çš„ç‰¹å¾äº¤äº’å¯¹")
            top_interactions[res] = []
            continue
        
        # è·å–åŸå§‹ç‰¹å¾åç§°å’Œäº¤äº’å€¼
        all_feature_names = list(res_data['X_sample'].columns)
        interaction_values = res_data['shap_interaction_values']
        
        print(f"  {res}: åŸå§‹ç‰¹å¾æ•°é‡ = {len(all_feature_names)}")
        
        # ä½¿ç”¨å…¨éƒ¨ç‰¹å¾ï¼ˆGeoShapleyè¾“å‡ºçš„18ä¸ªç‰¹å¾ï¼‰
        # 1. è·å–ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºSHAPå€¼ï¼‰
        if 'feature_importance' in res_data:
            # ä»è®¡ç®—å¥½çš„ç‰¹å¾é‡è¦æ€§ä¸­ç­›é€‰æ—¶ç©ºç‰¹å¾
            feature_importance_list = res_data['feature_importance']
            
            # ç­›é€‰æ’é™¤'GEO'å’Œ'year'çš„æ—¶ç©ºç‰¹å¾
            environmental_features = []
            for feat in feature_importance_list:
                if isinstance(feat, tuple):
                    feat_name = feat[0]
                elif isinstance(feat, dict):
                    feat_name = feat['feature']
                else:
                    feat_name = str(feat)
                
                # æ’é™¤GEOã€yearå’Œäº¤äº’æ•ˆåº”ï¼Œåªä¿ç•™ä¸»æ•ˆåº”ç¯å¢ƒç‰¹å¾
                if (feat_name != 'GEO' and 
                    str(feat_name).lower() != 'year' and
                    'Ã—' not in str(feat_name) and 
                    ' x ' not in str(feat_name)):
                    environmental_features.append(feat_name)
            
            print(f"     ç¬¦åˆæ¡ä»¶çš„ç¯å¢ƒç‰¹å¾æ•°é‡: {len(environmental_features)}")
            
            # ä½¿ç”¨å‰12ä¸ªç¯å¢ƒç‰¹å¾
            selected_features = environmental_features[:12]
            print(f"     é€‰æ‹©äº¤äº’åˆ†æçš„ç‰¹å¾æ•°é‡: {len(selected_features)}")
        else:
            # ä½¿ç”¨æ‰€æœ‰å¯ç”¨ç‰¹å¾
            selected_features = all_feature_names
            print(f"     ä½¿ç”¨æ‰€æœ‰ç‰¹å¾è¿›è¡Œäº¤äº’åˆ†æ: {len(selected_features)}")
        
        if len(selected_features) < 2:
            print(f"  âŒ {res}: å¯ç”¨ç‰¹å¾æ•°é‡ ({len(selected_features)}) ä¸è¶³ä»¥è¿›è¡Œäº¤äº’åˆ†æ")
            top_interactions[res] = []
            continue
        
        # è®¡ç®—äº¤äº’å€¼çŸ©é˜µ - æ”¹è¿›çš„äº¤äº’å¼ºåº¦è®¡ç®—
        print(f"     è®¡ç®—äº¤äº’å€¼çŸ©é˜µï¼Œç‰¹å¾æ•°é‡: {len(selected_features)}")
        
        try:
            # åªè®¡ç®—ä¸‰è§’çŸ©é˜µï¼Œé¿å…é‡å¤
            interaction_scores = []
            valid_pairs = []
            
            for i in range(len(selected_features)):
                for j in range(i+1, len(selected_features)):
                    feat1 = selected_features[i]
                    feat2 = selected_features[j]
                    
                    # è·å–è¿™ä¸¤ä¸ªç‰¹å¾åœ¨åŸå§‹ç‰¹å¾åˆ—è¡¨ä¸­çš„ç´¢å¼•
                    try:
                        idx1 = all_feature_names.index(feat1)
                        idx2 = all_feature_names.index(feat2)
                        
                        # è®¡ç®—äº¤äº’å¼ºåº¦ï¼šä½¿ç”¨Shapleyäº¤äº’å€¼çš„ç»å¯¹å€¼å¹³å‡
                        # SHAPäº¤äº’å€¼ [i,j] è¡¨ç¤ºç‰¹å¾iå’Œç‰¹å¾jçš„äº¤äº’å½±å“
                        interaction_score = np.abs(interaction_values[:, idx1, idx2]).mean()
                        
                        interaction_scores.append(interaction_score)
                        valid_pairs.append((feat1, feat2, interaction_score))
                        
                    except ValueError as e:
                        print(f"       ç‰¹å¾{feat1}æˆ–{feat2}åœ¨ç‰¹å¾åˆ—è¡¨ä¸­æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
                        continue
            
            if not valid_pairs:
                print(f"  âŒ {res}: æ²¡æœ‰æœ‰æ•ˆçš„äº¤äº’ç‰¹å¾å¯¹")
                top_interactions[res] = []
                continue
            
            # æŒ‰äº¤äº’å¼ºåº¦æ’åº
            valid_pairs.sort(key=lambda x: x[2], reverse=True)
            
            # é€‰æ‹©å‰top_nä¸ªäº¤äº’å¯¹
            top_pairs = valid_pairs[:top_n]
            
            # å­˜å‚¨ç»“æœ
            top_interactions[res] = [(pair[0], pair[1]) for pair in top_pairs]
            
            print(f"  âœ… {res}: æˆåŠŸè¯†åˆ«å‡º {len(top_pairs)} ä¸ªé¡¶çº§äº¤äº’ç‰¹å¾å¯¹")
            for i, (feat1, feat2, score) in enumerate(top_pairs):
                print(f"     {i+1}. {feat1} Ã— {feat2}: äº¤äº’å¼ºåº¦ = {score:.4f}")
        
        except Exception as e:
            print(f"  âŒ {res}: äº¤äº’å€¼è®¡ç®—å‡ºé”™: {e}")
            top_interactions[res] = []
    
    return top_interactions


def plot_pdp_interaction_grid(results, output_dir=None, top_n=3):
    """
    ç»˜åˆ¶PDPäº¤äº’æ•ˆåº”ç½‘æ ¼å›¾ï¼Œå±•ç¤ºä¸åŒåˆ†è¾¨ç‡ä¸‹çš„é¡¶çº§ç‰¹å¾äº¤äº’å¯¹
    
    ä¸ºæ¯ä¸ªåˆ†è¾¨ç‡çš„å‰top_nä¸ªäº¤äº’ç‰¹å¾å¯¹åˆ›å»º2D PDPçƒ­åŠ›å›¾ï¼š
    - è‡ªåŠ¨è¯†åˆ«åŸºäºSHAPäº¤äº’å€¼çš„é¡¶çº§äº¤äº’å¯¹
    - ä½¿ç”¨çƒ­åŠ›å›¾æ˜¾ç¤ºç‰¹å¾äº¤äº’æ•ˆåº”
    - æ·»åŠ ç­‰é«˜çº¿å’Œé¢œè‰²æ¡
    
    å‚æ•°:
    results (dict): åŒ…å«å„åˆ†è¾¨ç‡æ¨¡å‹ç»“æœçš„å­—å…¸
    output_dir (str): è¾“å‡ºç›®å½•
    top_n (int): æ¯ä¸ªåˆ†è¾¨ç‡æ˜¾ç¤ºçš„é¡¶çº§äº¤äº’ç‰¹å¾å¯¹æ•°é‡
    
    è¿”å›:
    str: ç”Ÿæˆçš„å›¾è¡¨è·¯å¾„
    """
    print(f"\nğŸ¨ åˆ›å»ºPDPäº¤äº’æ•ˆåº”ç½‘æ ¼å›¾...")
    print(f"    ğŸ“Š æ¯ä¸ªåˆ†è¾¨ç‡å±•ç¤ºå‰{top_n}ä¸ªæœ€é‡è¦çš„ç‰¹å¾äº¤äº’å¯¹")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if output_dir:
        ensure_dir_exists(output_dir)
    
    # 1. è¯†åˆ«é¡¶çº§äº¤äº’ç‰¹å¾å¯¹
    top_interactions = identify_top_interactions(results, top_n)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æœ‰æ•ˆçš„äº¤äº’å¯¹
    has_any_interactions = any(len(interactions) > 0 for interactions in top_interactions.values())
    if not has_any_interactions:
        print("  âŒ æ‰€æœ‰åˆ†è¾¨ç‡éƒ½æ²¡æœ‰æœ‰æ•ˆçš„äº¤äº’ç‰¹å¾å¯¹ï¼Œæ— æ³•ç”Ÿæˆäº¤äº’å›¾")
        return None
    
    # åˆ›å»ºå­å›¾ç½‘æ ¼
    resolutions = ['res7', 'res6', 'res5']
    valid_resolutions = [res for res in resolutions if res in results and len(top_interactions.get(res, [])) > 0]
    
    if not valid_resolutions:
        print("  âŒ æ²¡æœ‰åˆ†è¾¨ç‡åŒ…å«æœ‰æ•ˆçš„äº¤äº’ç‰¹å¾å¯¹")
        return None
    
    # è®¡ç®—ç½‘æ ¼å¤§å°
    n_resolutions = len(valid_resolutions)
    cols = top_n
    rows = n_resolutions
    
    # åˆ›å»ºå›¾è¡¨
    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
    if rows == 1:
        axes = axes.reshape(1, -1)
    elif cols == 1:
        axes = axes.reshape(-1, 1)
    
    plot_count = 0
    
    for res_idx, res in enumerate(valid_resolutions):
        print(f"\n  ğŸ”„ å¤„ç†{res}çš„äº¤äº’å›¾...")
        
        res_data = results[res]
        res_interactions = top_interactions[res]
        
        # è·å–æ¨¡å‹å’Œæ•°æ®
        model = res_data.get('model')
        likelihood = res_data.get('likelihood')
        X_sample = res_data.get('X_sample')
        
        if not model or X_sample is None:
            print(f"    âŒ {res}: ç¼ºå°‘æ¨¡å‹æˆ–æ•°æ®")
            continue
        
        # ä¸ºæ¯ä¸ªäº¤äº’ç‰¹å¾å¯¹åˆ›å»ºPDPå›¾
        for pair_idx, (feat1, feat2) in enumerate(res_interactions[:top_n]):
            if pair_idx >= cols:  # é˜²æ­¢è¶…å‡ºåˆ—æ•°
                break
            
            ax = axes[res_idx, pair_idx] if rows > 1 else axes[pair_idx]
            
            print(f"    ğŸ¯ ç»˜åˆ¶ {feat1} Ã— {feat2} äº¤äº’å›¾...")
            
            try:
                # åˆ›å»ºPDPé¢„æµ‹å‡½æ•°
                if likelihood:
                    # GPyTorchæ¨¡å‹
                    def make_gpytorch_predict_fn(model_obj, likelihood_obj):
                        def predict_fn(X):
                            model_obj.eval()
                            likelihood_obj.eval()
                            
                            with torch.no_grad():
                                try:
                                    import torch
                                    if not isinstance(X, torch.Tensor):
                                        X_tensor = torch.tensor(X, dtype=torch.float32)
                                    else:
                                        X_tensor = X
                                    
                                    # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
                                    device = next(model_obj.parameters()).device
                                    X_tensor = X_tensor.to(device)
                                    
                                    output = model_obj(X_tensor)
                                    pred_dist = likelihood_obj(output)
                                    predictions = pred_dist.mean.cpu().numpy()
                                    
                                    return predictions
                                except Exception as e:
                                    print(f"      é¢„æµ‹å‡½æ•°é”™è¯¯: {e}")
                                    return np.zeros(len(X))
                        return predict_fn
                    
                    predict_fn = make_gpytorch_predict_fn(model, likelihood)
                else:
                    # å…¶ä»–æ¨¡å‹ç±»å‹çš„å®‰å…¨é¢„æµ‹å‡½æ•°
                    def make_safe_predict(model_obj):
                        def safe_predict(X):
                            try:
                                if hasattr(model_obj, 'predict'):
                                    return model_obj.predict(X)
                                elif hasattr(model_obj, '__call__'):
                                    return model_obj(X)
                                else:
                                    print(f"      æ¨¡å‹æ²¡æœ‰predictæ–¹æ³•")
                                    return np.zeros(len(X))
                            except Exception as e:
                                print(f"      é¢„æµ‹å‡ºé”™: {e}")
                                return np.zeros(len(X))
                        return safe_predict
                    
                    predict_fn = make_safe_predict(model)
                
                # ä½¿ç”¨scikit-learnçš„partial_dependenceè®¡ç®—2D PDP
                try:
                    # è·å–ç‰¹å¾ç´¢å¼•
                    feature_names = list(X_sample.columns)
                    feat1_idx = feature_names.index(feat1)
                    feat2_idx = feature_names.index(feat2)
                    
                    # è®¡ç®—2D PDP - ä½¿ç”¨è¾ƒå°çš„ç½‘æ ¼ä»¥åŠ å¿«è®¡ç®—
                    pdp_result = partial_dependence(
                        predict_fn, X_sample.values, 
                        features=[feat1_idx, feat2_idx], 
                        grid_resolution=15, 
                        kind='average'
                    )
                    
                    # æå–PDPæ•°æ®
                    pdp_values = pdp_result['average'][0]
                    feat1_values = pdp_result['grid_values'][0]
                    feat2_values = pdp_result['grid_values'][1]
                    
                    # åˆ›å»ºç½‘æ ¼
                    f1_mesh, f2_mesh = np.meshgrid(feat1_values, feat2_values)
                    
                    # ç»˜åˆ¶çƒ­åŠ›å›¾
                    contour = ax.contourf(f1_mesh, f2_mesh, pdp_values.T, 
                                        cmap='viridis', alpha=0.9, levels=15)
                    
                    # æ·»åŠ ç­‰é«˜çº¿
                    contour_lines = ax.contour(f1_mesh, f2_mesh, pdp_values.T, 
                                             colors='white', alpha=0.6, levels=8)
                    ax.clabel(contour_lines, inline=True, fontsize=8, fmt='%.3f')
                    
                    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
                    ax.set_xlabel(simplify_feature_name_for_plot(feat1, max_length=4), 
                                fontsize=11, fontweight='bold')
                    ax.set_ylabel(simplify_feature_name_for_plot(feat2, max_length=4), 
                                fontsize=11, fontweight='bold')
                    
                    # è®¾ç½®æ ‡é¢˜
                    res_short = {'res7': 'Res7', 'res6': 'Res6', 'res5': 'Res5'}
                    ax.set_title(f'{res_short[res]}: {simplify_feature_name_for_plot(feat1, max_length=4)} Ã— {simplify_feature_name_for_plot(feat2, max_length=4)}', 
                               fontsize=12, fontweight='bold')
                    
                    # æ·»åŠ é¢œè‰²æ¡ï¼ˆåªä¸ºç¬¬ä¸€åˆ—æ·»åŠ ï¼‰
                    if pair_idx == 0:
                        cbar = plt.colorbar(contour, ax=ax)
                        cbar.set_label('Predicted VHI', fontsize=10, fontweight='bold')
                    
                    print(f"    âœ… {feat1} Ã— {feat2} äº¤äº’å›¾ç»˜åˆ¶æˆåŠŸ")
                    plot_count += 1
                
                except Exception as pdp_error:
                    print(f"    âŒ {feat1} Ã— {feat2} PDPè®¡ç®—å¤±è´¥: {pdp_error}")
                    ax.text(0.5, 0.5, f"PDP Error\n{feat1} Ã— {feat2}", 
                           ha='center', va='center', fontsize=10, 
                           transform=ax.transAxes, color='red')
                    ax.set_title(f'{res} - Error', fontsize=12)
            
            except Exception as e:
                print(f"    âŒ {feat1} Ã— {feat2} æ•´ä½“ç»˜åˆ¶å¤±è´¥: {e}")
                ax.text(0.5, 0.5, f"Error\n{feat1} Ã— {feat2}", 
                       ha='center', va='center', fontsize=10, 
                       transform=ax.transAxes, color='red')
                ax.set_title(f'{res} - Error', fontsize=12)
    
    # éšè—ç©ºçš„å­å›¾
    for res_idx in range(len(valid_resolutions)):
        for pair_idx in range(len(top_interactions.get(valid_resolutions[res_idx], [])), cols):
            if res_idx < rows and pair_idx < cols:
                ax = axes[res_idx, pair_idx] if rows > 1 else axes[pair_idx]
                ax.axis('off')
    
    # è®¾ç½®æ€»æ ‡é¢˜
    plt.suptitle('PDP Interaction Effects Grid Across Resolutions', 
               fontsize=16, fontweight='bold')
    
    # è°ƒæ•´å¸ƒå±€
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    
    # ä¿å­˜å›¾è¡¨
    if output_dir and plot_count > 0:
        output_path = os.path.join(output_dir, 'pdp_interaction_grid.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"\n  âœ… PDPäº¤äº’æ•ˆåº”ç½‘æ ¼å›¾å·²ä¿å­˜åˆ°: {output_path}")
        print(f"    ğŸ“Š æˆåŠŸç»˜åˆ¶äº† {plot_count} ä¸ªäº¤äº’æ•ˆåº”å›¾")
        
        return output_path
    else:
        plt.close()
        print(f"\n  âŒ æœªç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„äº¤äº’å›¾")
        return None


def plot_pdp_single_interaction(feat1, feat2, model, X_sample, output_dir=None, resolution=None):
    """
    ç»˜åˆ¶å•ä¸ªç‰¹å¾å¯¹çš„2D PDPäº¤äº’å›¾
    
    å‚æ•°:
    feat1 (str): ç¬¬ä¸€ä¸ªç‰¹å¾åç§°
    feat2 (str): ç¬¬äºŒä¸ªç‰¹å¾åç§°
    model: è®­ç»ƒå¥½çš„æ¨¡å‹
    X_sample (DataFrame): æ ·æœ¬æ•°æ®
    output_dir (str): è¾“å‡ºç›®å½•
    resolution (str): åˆ†è¾¨ç‡æ ‡è¯†
    
    è¿”å›:
    stræˆ–matplotlib.figure.Figure: å›¾è¡¨è·¯å¾„æˆ–å›¾è¡¨å¯¹è±¡
    """
    try:
        print(f"ç»˜åˆ¶ {feat1} Ã— {feat2} çš„PDPäº¤äº’å›¾...")
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
        feature_names = list(X_sample.columns)
        if feat1 not in feature_names or feat2 not in feature_names:
            print(f"ç‰¹å¾ {feat1} æˆ– {feat2} ä¸åœ¨æ•°æ®ä¸­")
            return None
        
        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(10, 8))
        
        # åˆ›å»ºé¢„æµ‹å‡½æ•°
        try:
            import torch
            import gpytorch
            
            if hasattr(model, 'eval'):  # GPyTorchæ¨¡å‹
                def predict_fn(X):
                    model.eval()
                    with torch.no_grad():
                        if not isinstance(X, torch.Tensor):
                            X_tensor = torch.tensor(X, dtype=torch.float32)
                        else:
                            X_tensor = X
                        
                        # ç§»åŠ¨åˆ°æ¨¡å‹è®¾å¤‡
                        device = next(model.parameters()).device
                        X_tensor = X_tensor.to(device)
                        
                        output = model(X_tensor)
                        return output.mean.cpu().numpy()
            else:
                # å…¶ä»–æ¨¡å‹ç±»å‹
                def make_pytorch_predict(model_obj):
                    def pytorch_predict(X):
                        try:
                            if hasattr(model_obj, 'predict'):
                                return model_obj.predict(X)
                            elif hasattr(model_obj, '__call__'):
                                # å¯¹äºPyTorchæ¨¡å‹
                                if not isinstance(X, torch.Tensor):
                                    X = torch.tensor(X, dtype=torch.float32)
                                return model_obj(X).detach().numpy()
                            else:
                                return np.zeros(len(X))
                        except Exception as e:
                            print(f"é¢„æµ‹å‡½æ•°é”™è¯¯: {e}")
                            return np.zeros(len(X))
                    return pytorch_predict
                
                predict_fn = make_pytorch_predict(model)
        
        except ImportError:
            # å¦‚æœæ²¡æœ‰PyTorchï¼Œä½¿ç”¨é€šç”¨é¢„æµ‹å‡½æ•°
            def predict_fn(X):
                try:
                    if hasattr(model, 'predict'):
                        return model.predict(X)
                    else:
                        return np.zeros(len(X))
                except:
                    return np.zeros(len(X))
        
        # è·å–ç‰¹å¾ç´¢å¼•
        feat1_idx = feature_names.index(feat1)
        feat2_idx = feature_names.index(feat2)
        
        # ä½¿ç”¨scikit-learnè®¡ç®—2D PDP
        try:
            pdp_result = partial_dependence(
                predict_fn, X_sample.values, 
                features=[feat1_idx, feat2_idx], 
                grid_resolution=20, 
                kind='average'
            )
            
            # æå–æ•°æ®
            pdp_values = pdp_result['average'][0]
            feat1_values = pdp_result['grid_values'][0]
            feat2_values = pdp_result['grid_values'][1]
            
            # åˆ›å»ºç½‘æ ¼
            f1_mesh, f2_mesh = np.meshgrid(feat1_values, feat2_values)
            
            # é¢„æµ‹VHIå€¼
            vhi_pred = pdp_values.T
            
        except Exception as e:
            print(f"ä½¿ç”¨scikit-learnè®¡ç®—PDPå¤±è´¥: {e}")
            print("å°è¯•ä½¿ç”¨è‡ªå®šä¹‰æ–¹æ³•...")
            
            # è‡ªå®šä¹‰PDPè®¡ç®—
            feat1_range = np.linspace(X_sample[feat1].min(), X_sample[feat1].max(), 20)
            feat2_range = np.linspace(X_sample[feat2].min(), X_sample[feat2].max(), 20)
            
            f1_mesh, f2_mesh = np.meshgrid(feat1_range, feat2_range)
            vhi_pred = np.zeros_like(f1_mesh)
            
            # åŸºå‡†æ•°æ®ï¼ˆå›ºå®šå…¶ä»–ç‰¹å¾ä¸ºå‡å€¼ï¼‰
            base_data = X_sample.mean().values
            
            for i in range(len(feat1_range)):
                for j in range(len(feat2_range)):
                    # åˆ›å»ºæµ‹è¯•æ ·æœ¬
                    test_sample = base_data.copy()
                    test_sample[feat1_idx] = feat1_range[i]
                    test_sample[feat2_idx] = feat2_range[j]
                    
                    # é¢„æµ‹
                    pred = predict_fn(test_sample.reshape(1, -1))
                    vhi_pred[j, i] = pred[0] if len(pred) > 0 else 0
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        contour = ax.contourf(f1_mesh, f2_mesh, vhi_pred, cmap='viridis', alpha=0.9, levels=15)
        
        # æ·»åŠ ç­‰é«˜çº¿
        contour_lines = ax.contour(f1_mesh, f2_mesh, vhi_pred, colors='white', alpha=0.6, levels=8)
        ax.clabel(contour_lines, inline=True, fontsize=10, fmt='%.3f')
        
        # è·å–ç‰¹å¾ç±»åˆ«
        group1 = categorize_feature(feat1)
        group2 = categorize_feature(feat2)
        
        # ç”¨äºå›¾è¡¨æ˜¾ç¤ºçš„æ›´æ¸…æ™°ç‰¹å¾åç§° - ä½¿ç”¨ä¸å…¶ä»–å›¾è¡¨ä¸€è‡´çš„ç®€åŒ–åç§°
        feat1_display = simplify_feature_name_for_plot(feat1, max_length=4)
        feat2_display = simplify_feature_name_for_plot(feat2, max_length=4)
        
        # è®¾ç½®æ ‡é¢˜å’Œè½´æ ‡ç­¾
        if resolution:
            title = f"PDP Interaction: {feat1_display} Ã— {feat2_display}"
        else:
            title = f"PDP Interaction: {feat1_display} Ã— {feat2_display}"
        
        # è®¾ç½®æ ‡é¢˜å’Œè½´æ ‡ç­¾
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.set_xlabel(feat1_display, fontsize=12, fontweight='bold')
        ax.set_ylabel(feat2_display, fontsize=12, fontweight='bold')
        
        # æ·»åŠ é¢œè‰²æ¡
        cbar = plt.colorbar(contour, ax=ax)
        cbar.set_label('Predicted VHI', fontsize=12, fontweight='bold')
        
        # åº”ç”¨å¢å¼ºæ ·å¼
        enhance_plot_style(ax, xlabel=feat1_display, ylabel=feat2_display)
        
        # ä¿å­˜å›¾è¡¨
        if output_dir:
            # åˆ›å»ºå®‰å…¨æ–‡ä»¶å
            safe_feat1 = re.sub(r'[\\/*?:"<>|]', "_", feat1)
            safe_feat2 = re.sub(r'[\\/*?:"<>|]', "_", feat2)
            
            if resolution:
                fig_path = os.path.join(output_dir, f"{resolution}_pdp_interaction_{safe_feat1}_{safe_feat2}.png")
            else:
                fig_path = os.path.join(output_dir, f"pdp_interaction_{safe_feat1}_{safe_feat2}.png")
            
            plt.savefig(fig_path, dpi=300, bbox_inches='tight')
            print(f"Interaction PDP saved to: {fig_path}")
            
            plt.close(fig)
            return fig_path
        
        return fig
    
    except Exception as e:
        print(f"Error generating PDP for {feat1} Ã— {feat2}: {e}")
        return None 